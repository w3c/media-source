<!DOCTYPE html SYSTEM "about:legacy-compat">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Media Source Extensions</title>
    <script src="respec-w3c-common.js" class="remove"></script>
    <script src="media-source.js" class="remove"></script>
    <script class="remove">
      var respecConfig = {
      // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
      specStatus: "ED",

      // the specification's short name, as in http://www.w3.org/TR/short-name/
      shortName: "media-source",

      // if there a publicly available Editor's Draft, this is the link
      edDraftURI:           "http://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html",

      // if this is a LCWD, uncomment and set the end of its review period
      // lcEnd: "2009-08-05",

      //publishDate: "2014-07-17",
      previousMaturity: "CR",
      previousPublishDate: "2014-01-09",

      // editors, add as many as you like
      // only "name" is required
      editors:  [
      { name: "Aaron Colwell",  url: "",
      company: "Google Inc.", companyURL: "http://www.google.com/" },
      { name: "Adrian Bateman", url: "",
      company: "Microsoft Corporation", companyURL: "http://www.microsoft.com/" },
      { name: "Mark Watson", url: "",
      company: "Netflix Inc.", companyURL: "http://www.netflix.com/" },
      ],

      mseDefGroupName: "media-source",
      mseContributors: [
        "Bob Lund",
        "Alex Giladi",
        "Duncan Rowden",
        "Mark Vickers",
        "Glenn Adams",
        "Frank Galligan",
        "Steven Robertson",
        "Matt Ward",
        "David Dorwin",
        "Kevin Streeter",
        "Joe Steele",
        "Michael Thornburgh",
        "Philip JÃ¤genstedt",
        "John Simmons",
        "Jerry Smith",
        "Pierre Lemieux",
        "Cyril Concolato",
        "Ralph Giles",
        "David Singer",
        "Tatsuya Igarashi",
        "Chris Poole",
        "Jer Noble",
        "Matthew Gregan",
        "Matt Wolenetz"
      ],

      // name of the WG
      wg:           "HTML Working Group",

      // URI of the public WG page
      wgURI:        "http://www.w3.org/html/wg/",

      // name (without the @w3c.org) of the public mailing to which comments are due
      wgPublicList: "public-html-media",

      // URI of the patent status for this WG, for Rec-track documents
      // !!!! IMPORTANT !!!!
      // This is important for Rec-track documents, do not copy a patent URI from a random
      // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
      // Team Contact.
      wgPatentURI: "http://www.w3.org/2004/01/pp-impl/40318/status",

      noIDLIn: true,

      scheme: "https",

      preProcess: [ mediaSourcePreProcessor ],

      // Empty definitions for objects declared in the document are here to
      // prevent error messages from being displayed for references to these objects.
      definitionMap: {
          MediaSource: function() {},
          SourceBuffer: function() {},
          SourceBufferList: function() {},
          AppendMode: function() {},
          VideoPlaybackQuality: function() {},
          Stream: function() {},
          ArrayBuffer: function() {},
          ArrayBufferView: function() {},
      },
      postProcess: [ mediaSourcePostProcessor ],

      localBiblio: {
          "STREAMS-API": {
            title: "Streams API",
            href: "http://www.w3.org/TR/2013/WD-streams-api-20131105/",
            authors: ["Feras Moussa", "Takeshi Yoshino"],
            status: "WD",
            publisher: "W3C",
          },
          "MSE-REGISTRY": {
              title: "Media Source Extensions Byte Stream Format Registry",
              href: "byte-stream-format-registry.html",
              //href: "http://www.w3.org/2013/12/byte-stream-format-registry/",
              authors: ["Aaron Colwell"],
              publisher: "W3C",
          }
       }
      };
    </script>

    <!-- script to register bugs -->
    <script src="https://dvcs.w3.org/hg/webcomponents/raw-file/tip/assets/scripts/bug-assist.js"></script>
    <meta name="bug.short_desc" content="[MSE] ">
    <meta name="bug.product" content="HTML WG">
    <meta name="bug.component" content="Media Source Extensions">

    <link rel="stylesheet" href="mse.css">
  </head>
  <body>

    <section id="sotd">
        <p>The working groups maintains <a href="http://w3.org/brief/Mjcw">a list of all bug reports that the editors have not yet tried to address</a>. This draft highlights some of the pending issues that are still to be discussed in the working group. No decision has been taken on the outcome of these issues including whether they are valid.</p>
        <p>Implementors should be aware that this specification is not stable. <strong>Implementors who are not taking part in the discussions are likely to find the specification changing out from under them in incompatible ways.</strong> Vendors interested in implementing this specification before it eventually reaches the Candidate Recommendation stage should join the mailing list mentioned below and take part in the discussions.</p>

        <p>The following features are <strong>at risk</strong> and may be removed due to lack of implementation.
        </p>
        <ul>
          <li><a def-id="totalFrameDelay"></a></li>
        </ul>

    </section>

    <section id="abstract">
      This specification extends HTMLMediaElement to allow
      JavaScript to generate media streams for playback.
      Allowing JavaScript to generate streams facilitates a variety of use
      cases like adaptive streaming and time shifting live streams.

      <p>If you wish to make comments or file bugs regarding this document in a manner that is tracked by the W3C, please submit them via
        <a href="https://www.w3.org/Bugs/Public/enter_bug.cgi?product=HTML%20WG&component=Media%20Source%20Extensions&short_desc=%5BMSE%5D%20">our public bug database</a>.
      </p>
    </section>


    <section id="introduction">
      <h2>Introduction</h2>
      <p>This specification allows JavaScript to dynamically construct media streams for &lt;audio&gt; and &lt;video&gt;.
        It defines objects that allow JavaScript to pass media segments to an <a def-id="videoref" name="htmlmediaelement">HTMLMediaElement</a> [[!HTML5]].
        A buffering model is also included to describe how the user agent acts when different media segments are
        appended at different times. Byte stream specifications used with these extensions are available in the byte stream format registry [[MSE-REGISTRY]].</p>
      <img src="pipeline_model.png" alt="Media Source Pipeline Model Diagram">

      <section id="goals">
        <h3>Goals</h3>
        <p>This specification was designed with the following goals in mind:</p>
        <ul>
          <li>Allow JavaScript to construct media streams independent of how the media is fetched.</li>
          <li>Define a splicing and buffering model that facilitates use cases like adaptive streaming, ad-insertion, time-shifting, and video editing.</li>
          <li>Minimize the need for media parsing in JavaScript.</li>
          <li>Leverage the browser cache as much as possible.</li>
          <li>Provide requirements for byte stream format specifications.</li>
          <li>Not require support for any particular media format or codec.</li>
        </ul>
        <p>This specification defines:</p>
        <ul>
          <li>Normative behavior for user agents to enable interoperability between user agents and web applications when processing media data.</li>
          <li>Normative requirements to enable other specifications to define media formats to be used within this specification.</li>
        </ul>
      </section>

      <section id="definitions">
        <h3>Definitions</h3>

        <dl>
          <dt id="active-track-buffers">Active Track Buffers</dt>
          <dd><p>The <a def-id="track-buffers"></a> that provide <a def-id="coded-frames"></a> for the <a def-id="audiotrack-enabled"></a>
              <a def-id="audiotracks"></a>, the <a def-id="videotrack-selected"></a> <a def-id="videotracks"></a>, and the
              <a def-id="texttrack-showing"></a> or <a def-id="texttrack-hidden"></a> <a def-id="texttracks"></a>. All these tracks are associated with
            <a>SourceBuffer</a> objects in the <a def-id="activeSourceBuffers"></a> list.</p>
          </dd>

          <dt id="append-window">Append Window</dt>
          <dd><p>A <a def-id="presentation-timestamp"></a> range used to filter out <a def-id="coded-frames"></a> while appending. The append window represents a single
            continuous time range with a single start time and end time. Coded frames with <a def-id="presentation-timestamp"></a> within this range are allowed to be appended
            to the <a>SourceBuffer</a> while coded frames outside this range are filtered out. The append window start and end times are controlled by
            the <a def-id="appendWindowStart"></a> and <a def-id="appendWindowEnd"></a> attributes respectively.</p></dd>

          <dt id="coded-frame">Coded Frame</dt>
          <dd><p>A unit of media data that has a <a def-id="presentation-timestamp"></a>, a <a def-id="decode-timestamp"></a>, and a <a def-id="coded-frame-duration"></a>.</p></dd>

          <dt id="coded-frame-duration">Coded Frame Duration</dt>
          <dd>
            <p>The duration of a <a def-id="coded-frame"></a>. For video and text, the duration indicates how long the video frame or text should be displayed. For audio, the duration represents the sum of all the samples contained within the coded frame. For example, if an audio frame contained 441 samples @44100Hz the frame duration would be 10 milliseconds.</p>
          </dd>

          <dt id="coded-frame-end-timestamp">Coded Frame End Timestamp</dt>
          <dd>
            <p>The sum of a <a def-id="coded-frame"></a> <a def-id="presentation-timestamp"></a> and its
                <a def-id="coded-frame-duration"></a>. It represents the <a def-id="presentation-timestamp"></a> that immediately follows the coded frame.</p>
          </dd>

          <dt id="coded-frame-group">Coded Frame Group</dt>
          <dd><p>A group of <a def-id="coded-frames"></a> that are adjacent and have monotonically increasing <a def-id="decode-timestamps"></a> without any gaps. Discontinuities detected by the
              <a def-id="coded-frame-processing-algorithm"></a> and <a def-id="abort"></a> calls trigger the start of a new coded frame group.</p>
          </dd>

          <dt id="decode-timestamp">Decode Timestamp</dt>
          <dd>
            <p> The decode timestamp indicates the latest time at which the frame needs to be decoded assuming instantaneous decoding and rendering of this and any dependant frames (this is equal to the <a def-id="presentation-timestamp"></a> of the earliest frame, in <a def-id="presentation-order"></a>, that is dependant on this frame). If frames can be decoded out of <a def-id="presentation-order"></a>, then the decode timestamp must be present in or derivable from the byte stream. The user agent must run the <a def-id="eos-decode"></a> if this is not the case. If frames cannot be decoded out of  <a def-id="presentation-order"></a> and a decode timestamp is not present in the byte stream, then the decode timestamp is equal to the <a def-id="presentation-timestamp"></a>.</dt>
          </dd>

          <dt id="displayed-frame-delay">Displayed Frame Delay</dt>
          <dd>
            <p>The delay between a frame's presentation time and the actual time it was displayed, in a double-precision value in seconds & rounded to the nearest display refresh interval. This
              delay is always greater than or equal to zero since frames must never be displayed before their presentation time. Non-zero delays are a sign of playback jitter
              and possible loss of A/V sync.</p>
          </dd>

          <dt id="init-segment">Initialization Segment</dt>
          <dd>
	    <p>A sequence of bytes that contain all of the initialization information required to decode a sequence of <a def-id="media-segments"></a>. This includes codec initialization data, <a def-id="track-id"></a> mappings for multiplexed segments, and timestamp offsets (e.g. edit lists).</p>
            <p class="note">The <a def-id="byte-stream-format-specs"></a> in the byte stream format registry [[MSE-REGISTRY]] contain format specific examples.</p>

          <dt id="media-segment">Media Segment</dt>
          <dd>
	    <p>A sequence of bytes that contain packetized &amp; timestamped media data for a portion of the <a def-id="media-timeline"></a>. Media segments are always associated with the most recently appended <a def-id="init-segment"></a>.</p>
            <p class="note">The <a def-id="byte-stream-format-specs"></a> in the byte stream format registry [[MSE-REGISTRY]] contain format specific examples.</p>
          </dd>

          <dt id="mediasource-object-url">MediaSource object URL</dt>
          <dd>
            <p>A MediaSource object URL is a unique <a def-id="blob-uri"></a> [[!FILE-API]] created by <a def-id="createObjectURL"></a>. It is used to attach a <a>MediaSource</a> object to an HTMLMediaElement.</p>
            <p>These URLs are the same as a <a def-id="blob-uri"></a>, except that anything in the definition of that feature that refers to <a def-id="File"></a> and <a def-id="Blob"></a> objects is hereby extended to also apply to <a>MediaSource</a> objects.</p>
            <p>The <a def-id="origin">origin</a> of the MediaSource object URL is the <a def-id="effective-script-origin"></a> of the document that called <a def-id="createObjectURL"></a>.</p>
            <p class="note">For example, the <a def-id="origin"></a> of the MediaSource object URL affects the way that the media element is <a href="http://www.w3.org/TR/html5/embedded-content-0.html#security-with-canvas-elements">consumed by canvas</a>.</p>
          </dd>

          <dt id="parent-media-source">Parent Media Source</dt>
          <dd><p>The parent media source of a <a>SourceBuffer</a> object is the <a>MediaSource</a> object that created it.</p></dd>

          <dt id="presentation-start-time">Presentation Start Time</dt>
          <dd><p>The presentation start time is the earliest time point in the presentation and specifies the <a def-id="videoref" name="initial-playback-position">initial playback position</a> and <a def-id="videoref" name="earliest-possible-position">earliest possible position</a>. All presentations created using this specification have a presentation start time of 0.</dd>

          <dt id="presentation-interval">Presentation Interval</dt>
          <dd>
            <p>The presentation interval of a <a def-id="coded-frame"></a> is the time interval from its <a def-id="presentation-timestamp"></a> to the <a def-id="presentation-timestamp"></a> plus the <a def-id="coded-frames-duration"></a>. For example, if a coded frame has a presentation timestamp of 10 seconds and a <a def-id="coded-frame-duration"></a> of 100 milliseconds, then the presentation interval would be [10-10.1). Note that the start of the range is inclusive, but the end of the range is exclusive.</p>
          </dd>

          <dt id="presentation-order">Presentation Order</dt>
          <dd>
            <p>The order that <a def-id="coded-frames"></a> are rendered in the presentation. The presentation order is achieved by ordering <a def-id="coded-frames"></a> in monotonically increasing order by their <a def-id="presentation-timestamps"></a>.</p>
          </dd>

          <dt id="presentation-timestamp">Presentation Timestamp</dt>
          <dd>
             <p>A reference to a specific time in the presentation. The presentation timestamp in a <a def-id="coded-frame"></a> indicates when the frame must be rendered.</p>
          </dd>

          <dt id="random-access-point">Random Access Point</dt>
          <dd><p>A position in a <a def-id="media-segment"></a> where decoding and continuous playback can begin without relying on any previous data in the segment. For video this tends to be the location of I-frames. In the case of audio, most audio frames can be treated as a random access point. Since video tracks tend to have a more sparse distribution of random access points, the location of these points are usually considered the random access points for multiplexed streams.</p></dd>

          <dt id="sourcebuffer-byte-stream-format-spec">SourceBuffer byte stream format specification</dt>
          <dd><p>The specific <a def-id="byte-stream-format-spec"></a> that describes the format of the byte stream accepted by a <a>SourceBuffer</a> instance. The
              <a def-id="byte-stream-format-spec"></a>, for a <a>SourceBuffer</a> object, is selected based on the <var>type</var> passed to the
              <a def-id="addSourceBuffer"></a> call that created the object.</p></dd>

          <dt id="sourcebuffer-configuration">SourceBuffer configuration</dt>
          <dd><p>A specific set of tracks distributed across one or more <a>SourceBuffer</a>
              objects owned by a single <a>MediaSource</a> instance.</p>
            <p>Implementations must support at least 1 <a>MediaSource</a> object with the following
            configurations:</p>
            <ul>
              <li>A single SourceBuffer with 1 audio track and/or 1 video track.</li>
              <li>Two SourceBuffers with one handling a single audio track and the other handling a single video track.</li>
            </ul>
            <p>MediaSource objects must support each of the configurations above, but they are only
              required to support one configuration at a time. Supporting multiple configurations at once
              or additional configurations is a quality of implementation issue.</p>
          </dd>

          <dt id="track-description">Track Description</dt>
          <dd><p>A byte stream format specific structure that provides the <a def-id="track-id"></a>, codec configuration, and other metadata for a single track. Each track description inside a single <a def-id="init-segment"></a> has a unique <a def-id="track-id"></a>. The user agent must run the <a def-id="eos-decode"></a> if the <a def-id="track-id"></a> is not unique within the <a def-id="init-segment"></a> .</p></dd>

          <dt id="track-id">Track ID</dt>
          <dd><p>A Track ID is a byte stream format specific identifier that marks sections of the byte stream as being part of a specific track. The Track ID in a <a def-id="track-description"></a> identifies which sections of a <a def-id="media-segment"></a> belong to that track.</p></dd>

        </dl>
      </section>
    </section>

    <section id="mediasource">
      <h2>MediaSource Object</h2>
      <p>The MediaSource object represents a source of media data for an HTMLMediaElement. It keeps track of the <a def-id="readyState"></a> for this source as well as a list of <a>SourceBuffer</a> objects that can be used to add media data to the presentation. MediaSource objects are created by the web application and then attached to an HTMLMediaElement. The application uses the <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a> to add media data to this source. The HTMLMediaElement fetches this media data from the <a>MediaSource</a> object when it is needed during playback.</p>

      <dl title="enum ReadyState" class="idl">
        <dt>closed</dt>
        <dd>
          Indicates the source is not currently attached to a media element.
        </dd>
        <dt>open</dt>
        <dd>
          The source has been opened by a media element and is ready for data to be appended to the <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>.
        </dd>
        <dt>ended</dt>
        <dd>
          The source is still attached to a media element, but <a def-id="endOfStream"></a> has been called.
        </dd>
      </dl>

      <dl title="enum EndOfStreamError" class="idl">
        <dt>network</dt>
        <dd>
          <p>Terminates playback and signals that a network error has occured.</p>
          <p class="note">JavaScript applications should use this status code to terminate playback with a network error. For example, if a network error occurs while fetching media data.</p>
        </dd>
        <dt>decode</dt>
        <dd>
          <p>Terminates playback and signals that a decoding error has occured.</p>
          <p class="note">JavaScript applications should use this status code to terminate playback with a decode error. For example, if a parsing error occurs while processing out-of-band media data.</p>
        </dd>
      </dl>

      <dl title="[Constructor] interface MediaSource : EventTarget" class='idl'>
        <dt>readonly attribute SourceBufferList sourceBuffers</dt>
        <dd>
          Contains the list of <a>SourceBuffer</a> objects associated with this <a>MediaSource</a>. When <a def-id="readyState"></a> equals <a def-id="closed"></a> this list will be empty. Once <a def-id="readyState"></a> transitions to <a def-id="open"></a> SourceBuffer objects can be added to this list by using <a def-id="addSourceBuffer"></a>.
        </dd>

        <dt>readonly attribute SourceBufferList activeSourceBuffers</dt>
        <dd>
          <p>Contains the subset of <a def-id="sourceBuffers"></a> that are providing the
            <a def-id="videoref" name="dom-videotrack-selected">selected video track</a>, the
            <a def-id="videoref" name="dom-audiotrack-enabled">enabled audio track(s)</a>, and the
            <a def-id="videoref" name="dom-texttrack-showing">"showing"</a> or <a def-id="videoref" name="dom-texttrack-hidden">"hidden"</a> text track(s).
          </p>
          <p><a>SourceBuffer</a> objects in this list must appear in the same order as they appear in
            the <a def-id="sourceBuffers"></a> attribute. (e.g., If only sourceBuffers[0] and
            sourceBuffers[3] are in <a def-id="activeSourceBuffers"></a>, then activeSourceBuffers[0] must
            equal sourceBuffers[0] and activeSourceBuffers[1] must equal sourceBuffers[3].)
          </p>
          <p class="note">The <a href="#active-source-buffer-changes">Changes to selected/enabled track state</a> section describes how this attribute gets
            updated.</p>
        </dd>

        <dt>readonly attribute ReadyState readyState</dt>
        <dd>
          <p>Indicates the current state of the <a>MediaSource</a> object. When the <a>MediaSource</a> is created <a def-id="readyState"></a> must be set to <a def-id="closed"></a>.
        </dd>

        <dt>attribute unrestricted double duration</dt>
        <dd>
          <p>Allows the web application to set the presentation duration. The duration is initially set to NaN when the <a>MediaSource</a> object is created.</p>
          <p>On getting, run the following steps:</p>
          <ol>
            <li>If the <a def-id="readyState"></a> attribute is <a def-id="closed"></a> then return NaN and abort these steps.</li>
            <li>Return the current value of the attribute.</li>
          </ol>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being set is negative or NaN then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="readyState"></a> attribute is not <a def-id="open"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true on any <a>SourceBuffer</a> in <a def-id="sourceBuffers"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the value being assigned to this attribute.
	      <p class="note"><a def-id="appendBuffer"></a>, <a def-id="appendStream"></a> and <a def-id="endOfStream"></a> can update the duration under certain circumstances.</p>
            </li>
          </ol>
        </dd>

        <dt>SourceBuffer addSourceBuffer(DOMString type)</dt>
        <dd>
          <p>Adds a new <a>SourceBuffer</a> to <a def-id="sourceBuffers"></a>.</p>
          <ol class="method-algorithm">
            <li>If <var>type</var> is an empty string then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>type</var> contains a MIME type that is not supported or contains a MIME type that is not supported with the types specified for the other <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>, then throw a <a def-id="not-supported-err"></a> exception and abort these steps.</li>
            <li>If the user agent can't handle any more SourceBuffer objects or if creating a SourceBuffer
              based on <var>type</var> would result in an unsupported <a def-id="sourcebuffer-configuration"></a>,
              then throw a <a def-id="quota-exceeded-err"></a> exception and abort these steps.
              <p class="note">For example, a user agent may throw a <a def-id="quota-exceeded-err"></a> exception if the media element has reached the
                <a def-id="have-metadata"></a> readyState. This can occur if the user agent's media engine does not support adding more tracks during
                playback.
              </p>
            </li>
            <li>If the <a def-id="readyState"></a> attribute is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Create a new <a>SourceBuffer</a> object and associated resources.</li>
            <li>Set the <a def-id="generate-timestamps-flag"></a> on the new object to the value in the
               "Generate Timestamps Flag" column of the byte stream format registry [[MSE-REGISTRY]] entry 
              that is associated with <var>type</var>.
            <li>
              <dl class="switch">
                <dt>If the <a def-id="generate-timestamps-flag"></a> equals true:</dt>
                <dd>
                  Set the <a def-id="mode"></a> attribute on the new object to
                  <a def-id="AppendMode-sequence"></a>.
                </dd>
                <dt>Otherwise:</dt>
                <dd>
                  Set the <a def-id="mode"></a> attribute on the new object to
                  <a def-id="AppendMode-segments"></a>.
                </dd>
            </li>
            <li>Add the new object to <a def-id="sourceBuffers"></a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="sourceBuffers"></a>.</li>
            <li>Return the new object.</li>
          </ol>
        </dd>

        <dt>void removeSourceBuffer(SourceBuffer sourceBuffer)</dt>
        <dd>
          <p>Removes a <a>SourceBuffer</a> from <a def-id="sourceBuffers"></a>.</p>

          <ol class="method-algorithm">
            <li>If <var>sourceBuffer</var> specifies an object that is not in <a def-id="sourceBuffers"></a> then throw a <a def-id="not-found-err"></a> exception and abort these steps.</li>
            <li>If the <var>sourceBuffer</var>.<a def-id="updating"></a> attribute equals true, then run the following steps:
              <ol>
                <li>Abort the <a def-id="buffer-append"></a> and <a def-id="stream-append-loop"></a> algorithms if they are running.</li>
                <li>Set the <var>sourceBuffer</var>.<a def-id="updating"></a> attribute to false.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateabort"></a> at <var>sourceBuffer</var>.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at <var>sourceBuffer</var>.</li>
              </ol>
            </li>

            <li>Let <var>SourceBuffer audioTracks list</var> equal the <a def-id="audio-track-list"></a> object returned by <var>sourceBuffer</var>.<a def-id="sourcebuffer-audioTracks"></a>.</li>
            <li>If the <var>SourceBuffer audioTracks list</var> is not empty, then run the following steps:
              <ol>
                <li>Let <var>HTMLMediaElement audioTracks list</var> equal the <a def-id="audio-track-list"></a> object returned by the <a def-id="audiotracks"></a> attribute on the HTMLMediaElement.</li>
                <li>Let the <var>removed enabled audio track flag</var> equal false.</li>
                <li>For each <a def-id="audio-track"></a> object in the <var>SourceBuffer audioTracks list</var>, run the following steps:
                  <ol>
                    <li>Set the <a def-id="audiotrack-sourceBuffer"></a> attribute on the <a def-id="audio-track"></a> object to null.</li>
                    <li>If the <a def-id="audiotrack-enabled"></a> attribute on the <a def-id="audio-track"></a> object is true, then
                      set the <var>removed enabled audio track flag</var> to true.</li>
                    <li>Remove the <a def-id="audio-track"></a> object from the <var>HTMLMediaElement audioTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>HTMLMediaElement audioTracks list</var>.</li>
                    <li>Remove the <a def-id="audio-track"></a> object from the <var>SourceBuffer audioTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>SourceBuffer audioTracks list</var>.</li>
                  </ol>
                </li>
                <li>If the <var>removed enabled audio track flag</var> equals true, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the
                  <var>HTMLMediaElement audioTracks list</var>.</li>
              </ol>
            </li>

            <li>Let <var>SourceBuffer videoTracks list</var> equal the <a def-id="video-track-list"></a> object returned by <var>sourceBuffer</var>.<a def-id="sourcebuffer-videoTracks"></a>.</li>
            <li>If the <var>SourceBuffer videoTracks list</var> is not empty, then run the following steps:
              <ol>
                <li>Let <var>HTMLMediaElement videoTracks list</var> equal the <a def-id="video-track-list"></a> object returned by the <a def-id="videotracks"></a> attribute on the HTMLMediaElement.</li>
                <li>Let the <var>removed selected video track flag</var> equal false.</li>
                <li>For each <a def-id="video-track"></a> object in the <var>SourceBuffer videoTracks list</var>, run the following steps:
                  <ol>
                    <li>Set the <a def-id="videotrack-sourceBuffer"></a> attribute on the <a def-id="video-track"></a> object to null.</li>
                    <li>If the <a def-id="videotrack-selected"></a> attribute on the <a def-id="video-track"></a> object is true, then
                      set the <var>removed selected video track flag</var> to true.</li>
                    <li>Remove the <a def-id="video-track"></a> object from the <var>HTMLMediaElement videoTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>HTMLMediaElement videoTracks list</var>.</li>
                    <li>Remove the <a def-id="video-track"></a> object from the <var>SourceBuffer videoTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>SourceBuffer videoTracks list</var>.</li>
                  </ol>
                </li>
                <li>If the <var>removed selected video track flag</var> equals true, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the
                  <var>HTMLMediaElement videoTracks list</var>.</li>
              </ol>
            </li>


            <li>Let <var>SourceBuffer textTracks list</var> equal the <a def-id="text-track-list"></a> object returned by <var>sourceBuffer</var>.<a def-id="sourcebuffer-textTracks"></a>.</li>
            <li>If the <var>SourceBuffer textTracks list</var> is not empty, then run the following steps:
              <ol>
                <li>Let <var>HTMLMediaElement textTracks list</var> equal the <a def-id="text-track-list"></a> object returned by the <a def-id="texttracks"></a> attribute on the HTMLMediaElement.</li>
                <li>Let the <var>removed enabled text track flag</var> equal false.</li>
                <li>For each <a def-id="text-track"></a> object in the <var>SourceBuffer textTracks list</var>, run the following steps:
                  <ol>
                    <li>Set the <a def-id="texttrack-sourceBuffer"></a> attribute on the <a def-id="text-track"></a> object to null.</li>
                    <li>If the <a def-id="texttrack-mode"></a> attribute on the <a def-id="text-track"></a> object is set to  <a def-id="texttrack-showing"></a> or
                      <a def-id="texttrack-hidden"></a> , then set the <var>removed enabled text track flag</var> to true.</li>
                    <li>Remove the <a def-id="text-track"></a> object from the <var>HTMLMediaElement textTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>HTMLMediaElement textTracks list</var>.</li>
                    <li>Remove the <a def-id="text-track"></a> object from the <var>SourceBuffer textTracks list</var>.</li>
                    <li><a def-id="Queue-and-fire-removetrack"></a> at the <var>SourceBuffer textTracks list</var>.</li>
                  </ol>
                </li>
                <li>If the <var>removed enabled text track flag</var> equals true, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the
                  <var>HTMLMediaElement textTracks list</var>.</li>
              </ol>
            </li>

            <li>If <var>sourceBuffer</var> is in <a def-id="activeSourceBuffers"></a>, then remove <var>sourceBuffer</var> from <a def-id="activeSourceBuffers"></a> and
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at the <a>SourceBufferList</a> returned by <a def-id="activeSourceBuffers"></a>.</li>
            <li>Remove <var>sourceBuffer</var> from <a def-id="sourceBuffers"></a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at 
              the <a>SourceBufferList</a> returned by <a def-id="sourceBuffers"></a>.</li>
            <li>Destroy all resources for <var>sourceBuffer</var>.</li>
          </ol>
        </dd>

        <dt>void endOfStream(optional EndOfStreamError error)</dt>
        <dd>
          <p>Signals the end of the stream.</p>

          <ol class="method-algorithm">
            <li>If the <a def-id="readyState"></a> attribute is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true on any <a>SourceBuffer</a> in <a def-id="sourceBuffers"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Run the <a def-id="end-of-stream-algorithm"></a> with the <var>error</var> parameter set to <var>error</var>.</li>
          </ol>
        </dd>

        <dt>static boolean isTypeSupported(DOMString type)</dt>
        <dd>
          <p>Check to see whether the <a>MediaSource</a> is capable of creating <a>SourceBuffer</a> objects for the specified MIME type.</p>

          <ol class="method-algorithm">
            <li>If <var>type</var> is an empty string, then return false.</li>
            <li>If <var>type</var> does not contain a valid MIME type string, then return false.</li>
            <li>If <var>type</var> contains a media type or media subtype that the MediaSource does not support, then return false.</li>
            <li>If <var>type</var> contains a codec that the MediaSource does not support, then return false.</li>
            <li>If the MediaSource does not support the specified combination of media type, media subtype, and codecs then return false.</li>
            <li>Return true.</li>
          </ol>
          <p class="note">
            If true is returned from this method, it only indicates that the <a>MediaSource</a> implementation is capable of creating <a>SourceBuffer</a> objects for the specified MIME type. An <a def-id="addSourceBuffer"></a> call may still fail if sufficient resources are not available to support the addition of a new <a>SourceBuffer</a>.
          </p>
          <p class="note">
            This method returning true implies that HTMLMediaElement.canPlayType() will return "maybe" or "probably" since it does not make sense for a <a>MediaSource</a> to support a type the HTMLMediaElement knows it cannot play.
          </p>
        </dd>
      </dl>

      <section id="mediasource-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">sourceopen</a></td>
              <td><code>Event</code></td>
              <td><a def-id="readyState"></a> transitions from <a def-id="closed"></a> to <a def-id="open"></a> or from <a def-id="ended"></a> to <a def-id="open"></a>.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">sourceended</a></td>
              <td><code>Event</code></td>
              <td><a def-id="readyState"></a> transitions from <a def-id="open"></a> to <a def-id="ended"></a>.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">sourceclose</a></td>
              <td><code>Event</code></td>
	      <td><a def-id="readyState"></a> transitions from <a def-id="open"></a> to <a def-id="closed"></a> or <a def-id="ended"></a> to <a def-id="closed"></a>.</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section id="mediasource-algorithms">
        <h3>Algorithms</h3>

        <section id="mediasource-attach">
          <h4>Attaching to a media element</h4>
          <p> A <a>MediaSource</a> object can be attached to a media element by assigning a <a def-id="MediaSource-object-URL"></a> to the media element <a def-id="media-src"></a> attribute or the src attribute of a &lt;source&gt; inside a media element. A <a def-id="MediaSource-object-URL"></a> is created by passing a MediaSource object to <a def-id="createObjectURL"></a>.</p>
          <p>If the <a def-id="resource-fetch-algorithm"></a> absolute URL matches the MediaSource object URL, run the following steps right before the <a def-id="perform-potentially-cors-enabled-fetch"></a>
            step in the <a def-id="resource-fetch-algorithm"></a>.</p>

          <dl class="switch">
            <dt>If <a def-id="readyState"></a> is NOT set to <a def-id="closed"></a></dt>
            <dd>Run the <a def-id="media-data-cannot-be-fetched"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
            <dt>Otherwise</dt>
            <dd>
              <ol>
                <li>Set the <a def-id="readyState"></a> attribute to <a def-id="open"></a>.</li>
                <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a>MediaSource</a>.</li>
                <li>Continue the <a def-id="resource-fetch-algorithm"></a> by running the <a def-id="perform-potentially-cors-enabled-fetch"></a> step. Text in the <a def-id="resource-fetch-algorithm"></a>
                  that refers to &quot;the download&quot; or &quot;bytes received&quot; refer to data passed in via <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a>. References to
                  HTTP in the <a def-id="resource-fetch-algorithm"></a> do not apply because the HTMLMediaElement does not fetch media data via HTTP when a <a>MediaSource</a> is attached.</li>
              </ol>
            </dd>
          </dl>
        </section>

        <section id="mediasource-detach">
          <h4>Detaching from a media element</h4>
          <p>The following steps are run in any case where the media element is going to transition to <a def-id="videoref" name="dom-media-network_empty">NETWORK_EMPTY</a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="videoref" name="event-mediacontroller-emptied">emptied</a> at the media element. These steps must be run right before the transition.</p>
          <ol>
            <li>Set the <a def-id="readyState"></a> attribute to <a def-id="closed"></a>.</li>
            <li>Set the <a def-id="duration"></a> attribute to NaN.</li>
            <li>Remove all the <a>SourceBuffer</a> objects from <a def-id="activeSourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>.</li>
            <li>Remove all the <a>SourceBuffer</a> objects from <a def-id="sourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="sourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceclose"></a> at the <a>MediaSource</a>.</li>
          </ol>
        </section>

        <section id="mediasource-seeking">
          <h4>Seeking</h4>
          <p>Run the following steps as part of the "<i>Wait until the user agent has established whether or not the media data for the new playback position is available, and, if it is, until it has decoded enough data to play back that position"</i> step of the <a def-id="hme-seek-algorithm"></a>:</p>
          <ol>
            <li>The media element looks for <a def-id="media-segments"></a> containing the <var>new playback position</var> in each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a>.
              <dl class="switch">
	        <dt>If one or more of the objects in <a def-id="activeSourceBuffers"></a> is missing <a def-id="media-segments"></a> for the <var>new playback position</var>
                </dt>
	        <dd>
	          <ol>
	            <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	            <li>The media element waits until an <a def-id="appendBuffer"></a> or an <a def-id="appendStream"></a> call causes the <a def-id="coded-frame-processing-algorithm"></a> to set
                      the <a def-id="ready-state"></a> attribute to a value greater than <a def-id="have-metadata"></a>.
                      <p class="note">The web application can use <a def-id="buffered"></a> to determine what the media element needs to resume playback.</p>
                    </li>
	          </ol>
	        </dd>
	        <dt>Otherwise</dt>
	        <dd>Continue</dd>
              </dl>
            </li>
            <li>The media element resets all decoders and initializes each one with data from the appropriate <a def-id="init-segment"></a>.</li>
            <li>The media element feeds <a def-id="coded-frames"></a> from the <a def-id="active-track-buffers"></a> into the decoders starting with the
              closest <a def-id="random-access-point"></a> before the <var>new playback position</var>.</li>
            <li>Resume the <a def-id="hme-seek-algorithm"></a> at the "<i>Await a stable state</i>" step.</li>
          </ol>
        </section>

        <section id="buffer-monitoring">
          <h4>SourceBuffer Monitoring</h4>
          <p>The following steps are periodically run during playback to make sure that all of the <a>SourceBuffer</a> objects in <a def-id="activeSourceBuffers"></a> have <a def-id="enough-data"></a>. Appending new segments and changes to <a def-id="activeSourceBuffers"></a> also cause these steps to run because they affect the conditions that trigger state transitions.</p>

          <p>Having <dfn id="enough-data">enough data to ensure uninterrupted playback</dfn> is an implementation specific condition where the user agent
          determines that it currently has enough data to play the presentation without stalling for a meaningful period of time. This condition is
          constantly evaluated to determine when to transition the media element into and out of the <a def-id="have-enough-data"></a> ready state.
          These transitions indicate when the user agent believes it has enough data buffered or it needs more data respectively.</p>

          <p class="note">An implementation may choose to use bytes buffered, time buffered, the append rate, or any other metric it sees fit to
            determine when it has enough data. The metrics used may change during playback so web applications should only rely on the value of
            <a def-id="ready-state"></a> to determine whether more data is needed or not.</p>

          <p class="note">When the media element needs more data, the user agent should transition it from <a def-id="have-enough-data"></a> to
            <a def-id="have-future-data"></a> early enough for a web application to be able to respond without causing an interruption in playback.
            For example, transitioning when the current playback position is 500ms before the end of the buffered data gives the application roughly
            500ms to append more data before playback stalls.</p>

          <dl class="switch">
            <dt>If <a def-id="hme-buffered"></a> does not contain a <a def-id="timerange"></a> for the current playback position:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-metadata"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadedmetadata"></a> at the media element.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="hme-buffered"></a> contains a <a def-id="timerange"></a> that includes the current playback position and <a def-id="enough-data"></a>:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-enough-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplaythrough"></a> at the media element.</li>
	        <li>Playback may resume at this point if it was previously suspended by a transition to <a def-id="have-current-data"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="hme-buffered"></a> contains a <a def-id="timerange"></a> that includes the current playback position and some time beyond the current playback position, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-future-data"></a>.</li>
	        <li>If the previous value of <a def-id="ready-state"></a> was less than <a def-id="have-future-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="canplay"></a> at the media element.</li>
	        <li>Playback may resume at this point if it was previously suspended by a transition to <a def-id="have-current-data"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="hme-buffered"></a> contains a <a def-id="timerange"></a> that ends at the current playback position and does not have a range covering the time immediately after the current position:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-current-data"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-current-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadeddata"></a> at the media element.</li>
	        <li>Playback is suspended at this point since the media element doesn't have enough data to advance the <a def-id="media-timeline"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
          </dl>
        </section>

        <section id="active-source-buffer-changes">
          <h4>Changes to selected/enabled track state</h4>
          <p>During playback <a def-id="activeSourceBuffers"></a> needs to be updated if the <a def-id="videoref" name="dom-videotrack-selected">selected video track</a>, the <a def-id="videoref" name="dom-audiotrack-enabled">enabled audio track(s)</a>, or a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> changes. When one or more of these changes occur the following steps need to be followed.</p>
          <dl class="switch">
            <dt>If the selected video track changes, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>If the <a>SourceBuffer</a> associated with the previously selected video track is not associated with any other enabled tracks, run the following steps:
  	          <ol>
	            <li>Remove the <a>SourceBuffer</a> from <a def-id="activeSourceBuffers"></a>.</li>
	            <li>
                      <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                    </li>
	          </ol>
	        </li>
	        <li>If the <a>SourceBuffer</a> associated with the newly selected video track is not already in <a def-id="activeSourceBuffers"></a>, run the following steps:
	          <ol>
	            <li>Add the <a>SourceBuffer</a> to <a def-id="activeSourceBuffers"></a>.</li>
	            <li>
                      <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                    </li>
	          </ol>
	        </li>
	      </ol>
            </dd>
            <dt>If an audio track becomes disabled and the <a>SourceBuffer</a> associated with this track is not associated with any other enabled or selected track, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>Remove the <a>SourceBuffer</a> associated with the audio track from <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If an audio track becomes enabled and the <a>SourceBuffer</a> associated with this track is not already in <a def-id="activeSourceBuffers"></a>, then run the following steps:
            </dt>
            <dd>
	      <ol>
	        <li>Add the <a>SourceBuffer</a> associated with the audio track to <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> becomes <a def-id="videoref" name="dom-texttrack-disabled">"disabled"</a> and the <a>SourceBuffer</a> associated with this track is not associated with any other enabled or selected track, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>Remove the <a>SourceBuffer</a> associated with the text track from <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> becomes <a def-id="videoref" name="dom-texttrack-showing">"showing"</a> or <a def-id="videoref" name="dom-texttrack-hidden">"hidden"</a> and the <a>SourceBuffer</a> associated with this track is not already in <a def-id="activeSourceBuffers"></a>, then run the following steps:
            </dt>
            <dd>
	      <ol>
	        <li>Add the <a>SourceBuffer</a> associated with the text track to <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
          </dl>
        </section>

        <section id="duration-change-algorithm">
          <h4>Duration change</h4>
          <p>Follow these steps when <a def-id="duration"></a> needs to change to a <var>new duration</var>.</p>
          <ol>
            <li>If the current value of <a def-id="duration"></a> is equal to <var>new duration</var>, then return.</li>
            <li>Set <var>old duration</var> to the current value of <a def-id="duration"></a>.
            <li>Update <a def-id="duration"></a> to <var>new duration</var>.</li>
            <li>If the <var>new duration</var> is less than <var>old duration</var>, then run the
              <a def-id="range-removal"></a> algorithm with <var>new duration</var> and
              <var>old duration</var> as the start and end of the removal range.</li>
              <p class="note">This preserves audio frames and text cues that start before and end after the <a def-id="duration"></a>.</p></li>
            <li>If a user agent is unable to partially render audio frames or text cues that start before and end after the <a def-id="duration"></a>, then run the following steps:
              <ol>
                <li>Update <var>new duration</var> to the highest end time reported by the <a def-id="buffered"></a> attribute across all <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>.</li>
                <li>Update <a def-id="duration"></a> to <var>new duration</var>.</li>
              </ol>
            </li>
            <li>Update the <a def-id="hme-duration"></a> to <var>new duration</var> and run the <a def-id="hme-duration-change-algorithm"></a>.</li>
          </ol>
        </section>

        <section id="end-of-stream-algorithm">
          <h4>End of stream algorithm</h4>
          <p>This algorithm gets called when the application signals the end of stream via an <a def-id="endOfStream"></a> call or an algorithm needs to
            signal a decode error. This algorithm takes an <var>error</var> parameter that indicates whether an error will be signalled.</p>
          <ol>
            <li>Change the <a def-id="readyState"></a> attribute value to <a def-id="ended"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceended"></a> at the <a>MediaSource</a>.</li>
            <li><dl class="switch">
                <dt>If <var>error</var> is not set</dt>
                <dd>
	          <ol>
	            <li>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the highest end time reported by the <a def-id="buffered"></a> attribute across all <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>.<br>
		      <p class="note">This allows the duration to properly reflect the end of the appended media segments. For example, if the duration was explicitly set to 10 seconds and only media segments for 0 to 5 seconds were appended before endOfStream() was called, then the duration will get updated to 5 seconds.</p>
	            </li>
	            <li>Notify the media element that it now has all of the media data.</li>
	          </ol>
	        </dd>
                <dt>If <var>error</var> is set to <a def-id="network"></a>
                </dt>
                <dd>
	          <dl class="switch">
	            <dt>If the <a def-id="ready-state"></a> attribute equals <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the <a def-id="media-data-cannot-be-fetched"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	            <dt>If the <a def-id="ready-state"></a> attribute is greater than <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the "<i>If the connection is interrupted after some media data has been received, causing the user agent to give up trying to fetch the resource</i>" steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	          </dl>
	        </dd>
                <dt>If <var>error</var> is set to <a def-id="decode"></a>
                </dt>
                <dd>
                  <ol>
                    <li>If <a def-id="updating"></a> equals true, then run the <a def-id="append-error-algorithm"></a>.</li>
                    <li>
	              <dl class="switch">
	                <dt>If the <a def-id="ready-state"></a> attribute equals <a def-id="have-nothing"></a>
                        </dt>
	                <dd>Run the "<i>If the media data can be fetched but is found by inspection to be in an unsupported format, or can otherwise not be rendered at all</i>" steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	                <dt>If the <a def-id="ready-state"></a> attribute is greater than <a def-id="have-nothing"></a>
                        </dt>
	                <dd>Run the <a def-id="media-data-is-corrupted"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	              </dl>
                    </li>
                  </ol>
	        </dd>
              </dl>
            </li>
          </ol>
        </section>
      </section>
    </section>

    <section id="sourcebuffer">
      <h2>SourceBuffer Object</h2>


      <dl title="enum AppendMode" class="idl">
        <dt>segments</dt>
        <dd>
          <p>The timestamps in the media segment determine where the <a def-id="coded-frames"></a> are placed in the presentation. Media segments can be appended in any order.</p>
        </dd>
        <dt>sequence</dt>
        <dd>
          <p>Media segments will be treated as adjacent in time independent of the timestamps in the media segment. Coded frames in a new media segment will be placed immediately after the coded
            frames in the previous media segment. The <a def-id="timestampOffset"></a> attribute will be updated if a new offset is needed to make the new media segments adjacent to the previous media segment.
            Setting the <a def-id="timestampOffset"></a> attribute in <a def-id="AppendMode-sequence"></a> mode allows a media segment to be placed at a specific position in the timeline without any knowledge
            of the timestamps in the media segment.
          </p>
        </dd>
      </dl>

      <dl title="interface SourceBuffer : EventTarget" class="idl">
        <dt>attribute AppendMode mode</dt>
        <dd>
          <p>Controls how a sequence of <a def-id="media-segments"></a> are handled.  This attribute is initially set by <a def-id="addSourceBuffer"></a> after the object is created.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>Let <var>new mode</var> equal the new value being assigned to this attribute.</li>
            <li>If <a def-id="generate-timestamps-flag"></a> equals true and <var>new mode</var> equals
              <a def-id="AppendMode-segments"></a>, then throw an <a def-id="invalid-access-err"></a>
              exception and abort these steps.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an <a def-id="invalid-state-err"></a> exception and
              abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a></li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a>.</li>
              </ol>
            </li>
            <li>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a>, then throw an <a def-id="invalid-state-err"></a> and abort these steps.</li>
            <li>If the <var>new mode</var> equals <a def-id="AppendMode-sequence"></a>, then set the <a def-id="group-start-timestamp"></a> to the <a def-id="group-end-timestamp"></a>.</li>
            <li>Update the attribute to <var>new mode</var>.</li>
          </ol>
        </dd>

        <dt>readonly attribute boolean updating</dt>
        <dd>
          <p>Indicates whether the asynchronous continuation of an <a def-id="appendBuffer"></a>, <a def-id="appendStream"></a>, or <a def-id="remove"></a>
            operation is still being processed. This attribute is initially set to false when the object is created.</p>
        </dd>

        <dt>readonly attribute TimeRanges buffered</dt>
        <dd>
          <p>Indicates what <a def-id="timeranges"></a> are buffered in the <a>SourceBuffer</a>.</p>
          <p>When the attribute is read the following steps must occur:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Let <var>highest end time</var> be the largest <a def-id="track-buffer-ranges"></a> end time across all the <a def-id="track-buffers"></a> managed by this <a>SourceBuffer</a> object.</li>
            <li>Let <var>intersection ranges</var> equal a <a def-id="timerange"></a> object containing a single range from 0 to <var>highest end time</var>.</li>
            <li>For each <a def-id="track-buffer"></a> managed by this <a>SourceBuffer</a>, run the following steps:
              <ol>
                <li>Let <var>track ranges</var> equal the <a def-id="track-buffer-ranges"></a> for the current <a def-id="track-buffer"></a>.</li>
                <li>If <a def-id="readyState"></a> is <a def-id="ended"></a>, then set the end time on the last range in <var>track ranges</var> to <var>highest end time</var>.</li>
                <li>Let <var>new intersection ranges</var> equal the intersection between the <var>intersection ranges</var> and the <var>track ranges</var>.</li>
                <li>Replace the ranges in <var>intersection ranges</var> with the <var>new intersection ranges</var>.</li>
              </ol>
            </li>
            <li>Return the <var>intersection ranges</var>.</li>
          </ol>
        </dd>

        <dt>attribute double timestampOffset</dt>
        <dd>
          <p>Controls the offset applied to timestamps inside subsequent <a def-id="media-segments"></a> that are appended to this <a>SourceBuffer</a>. The <a def-id="timestampOffset"></a> is initially set to 0 which indicates that no offset is being applied.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>Let <var>new timestamp offset</var> equal the new value being assigned to this attribute.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a></li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a>.</li>
              </ol>
            </li>
            <li>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a>, then throw an <a def-id="invalid-state-err"></a> and abort these steps.</li>
            <li>If the <a def-id="mode"></a> attribute equals <a def-id="AppendMode-sequence"></a>, then set the <a def-id="group-start-timestamp"></a> to <var>new timestamp offset</var>.</li>
            <li>Update the attribute to <var>new timestamp offset</var>.</li>
          </ol>
        </dd>

        <dt>readonly attribute AudioTrackList audioTracks</dt>
        <dd>
          The list of <a def-id="audio-track"></a> objects created by this object.
        </dd>

        <dt>readonly attribute VideoTrackList videoTracks</dt>
        <dd>
          The list of <a def-id="video-track"></a> objects created by this object.
        </dd>

        <dt>readonly attribute TextTrackList textTracks</dt>
        <dd>
          The list of <a def-id="text-track"></a> objects created by this object.
        </dd>

        <dt>attribute double appendWindowStart</dt>
        <dd>
          <p>The <a def-id="presentation-timestamp"></a> for the start of the <a def-id="append-window"></a>. This attribute is initially set to the <a def-id="presentation-start-time"></a>.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an
              <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the new value is less than 0 or greater than or equal to <a def-id="appendWindowEnd"></a> then throw an <a def-id="invalid-access-err"></a> exception
              and abort these steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>

        <dt>attribute unrestricted double appendWindowEnd</dt>
        <dd>
          <p>The <a def-id="presentation-timestamp"></a> for the end of the <a def-id="append-window"></a>. This attribute is initially set to positive Infinity.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an
              <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the new value equals NaN, then throw an <a def-id="invalid-access-err"></a> and abort these steps.</li>
            <li>If the new value is less than or equal to <a def-id="appendWindowStart"></a> then throw an <a def-id="invalid-access-err"></a> exception and abort these
              steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>

        <dt>void appendBuffer(ArrayBuffer data)</dt>
        <dd>
          <p>Appends the segment data in an <a>ArrayBuffer</a>[[!TYPED-ARRAYS]] to the source buffer.</p>
          <p>The steps for this method are the same as the ArrayBufferView version of <a def-id="appendBuffer"></a>.</p>
        </dd>

        <dt>void appendBuffer(ArrayBufferView data)</dt>
        <dd>
          <p>Appends the segment data in an <a>ArrayBufferView</a>[[!TYPED-ARRAYS]] to the source buffer.</p>

          <ol class="method-algorithm">
            <li>Run the <a def-id="prepare-append"></a> algorithm.</li>
            <li>Add <var>data</var> to the end of the <a def-id="input-buffer"></a>.</li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Asynchronously run the <a def-id="buffer-append"></a> algorithm.</li>
          </ol>
        </dd>

        <dt>void appendStream(Stream stream, [EnforceRange] optional unsigned long long maxSize)</dt>
        <dd>
          <p>Appends segment data to the source buffer from a <a class="externalDFN">Stream</a>[[!STREAMS-API]].</p>

          <ol class="method-algorithm">
            <li>Run the <a def-id="prepare-append"></a> algorithm.</li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Asynchronously run the <a def-id="stream-append-loop"></a> algorithm with <var>stream</var> and <var>maxSize</var>.</li>
          </ol>
        </dd>

        <dt>void abort()</dt>
        <dd>
          <p>Aborts the current segment and resets the segment parser.</p>

          <ol class="method-algorithm">
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then run the following steps:
              <ol>
                <li>Abort the <a def-id="buffer-append"></a> and <a def-id="stream-append-loop"></a> algorithms if they are running.</li>
                <li>Set the <a def-id="updating"></a> attribute to false.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateabort"></a> at this <a>SourceBuffer</a> object.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
              </ol>
            </li>
            <li>Run the <a def-id="reset-parser-state-algorithm"></a>.</li>
            <li>Set <a def-id="appendWindowStart"></a> to the <a def-id="presentation-start-time"></a>.</li>
            <li>Set <a def-id="appendWindowEnd"></a> to positive Infinity.</li>
          </ol>
        </dd>

        <dt>void remove(double start, unrestricted double end)</dt>
        <dd>
          <p>Removes media for a specific time range.</p>

          <ol class="method-algorithm">
            <li>If <a def-id="duration"></a> equals NaN, then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>start</var> is negative or greater than <a def-id="duration"></a>, then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>end</var> is less than or equal to <var>start</var> or <var>end</var> equals NaN, then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run
                the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a></li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a> .</li>
              </ol>
            </li>
            <li>Run the <a def-id="range-removal"></a> algorithm with <var>start</var> and <var>end</var> as the start and end of the removal range.</li>
       </ol>

        </dd>
        <dt>attribute TrackDefaultList trackDefaults</dt>
        <dd>
          <p>Specifies the default values to use if kind, label, and/or language information is not available in the
            <a def-id="init-segment"></a> when the <a def-id="init-segment-received-algorithm"></a> needs
            to create track objects. This attribute is initially set to an empty <a>TrackDefaultList</a> object.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an
              <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>
      </dl>

      <section id="track-buffers">
        <h3>Track Buffers</h3>
        <p>A <dfn id="track-buffer">track buffer</dfn> stores the <a def-id="track-descriptions"></a> and <a def-id="coded-frames"></a> for an individual
          track. The track buffer is updated as <a def-id="init-segments"></a> and <a def-id="media-segments"></a> are appended to the
          <a>SourceBuffer</a>.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="last-decode-timestamp">last decode timestamp</dfn> variable that stores
          the decode timestamp of the last <a def-id="coded-frame"></a> appended in the current <a def-id="coded-frame-group"></a>. The variable is initially
          unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="last-frame-duration">last frame duration</dfn> variable that stores
          the <a def-id="coded-frame-duration"></a> of the last <a def-id="coded-frame"></a> appended in the current <a def-id="coded-frame-group"></a>. The variable is initially
          unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="highest-presentation-timestamp">highest presentation timestamp</dfn> variable that stores
          the highest <a def-id="presentation-timestamp"></a> encountered in a <a def-id="coded-frame"></a> appended in the current <a def-id="coded-frame-group"></a>.
          The variable is initially unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="need-RAP-flag">need random access point flag</dfn> variable that keeps track of whether
          the track buffer is waiting for a <a def-id="random-access-point"></a> <a def-id="coded-frame"></a>. The variable is initially set to true to
          indicate that <a def-id="random-access-point"></a> <a def-id="coded-frame"></a> is needed before anything can be added to the
          <a def-id="track-buffer"></a>.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="track-buffer-ranges">track buffer ranges</dfn> variable that represents the presentation time ranges occupied by the <a def-id="coded-frames"></a>
          currently stored in the track buffer. For specification purposes, this information is treated as if it were stored in a <a def-id="normalized-timeranges-object"></a>.</p>
      </section>

      <section id="sourcebuffer-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">updatestart</a></td>
              <td><code>Event</code></td>
              <td><a def-id="updating"></a> transitions from false to true.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">update</a></td>
              <td><code>Event</code></td>
              <td>The append or remove has successfully completed. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">updateend</a></td>
              <td><code>Event</code></td>
              <td>The append or remove has ended.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">error</a></td>
              <td><code>Event</code></td>
              <td>An error occurred during the append. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">abort</a></td>
              <td><code>Event</code></td>
              <td>The append or remove was aborted by an <a def-id="abort"></a> call. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section id="sourcebuffer-algorithms">
        <h3>Algorithms</h3>

        <section id="sourcebuffer-segment-parser-loop">
          <h4>Segment Parser Loop</h4>
          <p>All SourceBuffer objects have an internal <dfn id="sourcebuffer-append-state">append state</dfn> variable that keeps track of the high-level segment parsing state. It is initially set to <a def-id="waiting-for-segment"></a> and can transition to the following states as data is appended.</p>
          <table class="old-table">
            <thead>
	      <tr>
                <th>Append state name</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><dfn id="sourcebuffer-waiting-for-segment">WAITING_FOR_SEGMENT</dfn></td>
                <td>Waiting for the start of an <a def-id="init-segment"></a> or <a def-id="media-segment"></a> to be appended.</td>
              </tr>
              <tr>
                <td><dfn id="sourcebuffer-parsing-init-segment">PARSING_INIT_SEGMENT</dfn></td>
                <td>Currently parsing an <a def-id="init-segment"></a>.</td>
              </tr>
	      <tr>
	        <td><dfn id="sourcebuffer-parsing-media-segment">PARSING_MEDIA_SEGMENT</dfn></td>
                <td>Currently parsing a <a def-id="media-segment"></a>.</td>
              </tr>
            </tbody>
          </table>

          <p>The <dfn id="sourcebuffer-input-buffer">input buffer</dfn> is a byte buffer that is used to hold unparsed bytes across <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a> calls. The buffer is empty when the SourceBuffer object is created.</p>

          <p>The <dfn id="sourcebuffer-buffer-full-flag">buffer full flag</dfn> keeps track of whether <a def-id="appendBuffer"></a> or
            <a def-id="appendStream"></a> is allowed to accept more bytes. It is set to false when the SourceBuffer object is created and gets updated
            as data is appended and removed.</p>

          <p>The <dfn id="sourcebuffer-group-start-timestamp">group start timestamp</dfn> variable keeps track of the starting timestamp for a new
            <a def-id="coded-frame-group"></a> in the <a def-id="AppendMode-sequence"></a> mode.
            It is unset when the SourceBuffer object is created and gets updated when the <a def-id="mode"></a> attribute equals <a def-id="AppendMode-sequence"></a> and the
            <a def-id="timestampOffset"></a> attribute is set, or the <a def-id="coded-frame-processing-algorithm"></a> runs.
          </p>

          <p>The <dfn id="sourcebuffer-group-end-timestamp">group end timestamp</dfn> variable stores the
            highest <a def-id="coded-frame-end-timestamp"></a> across all <a def-id="coded-frames"></a> in
            the current <a def-id="coded-frame-group"></a>. It is set to 0 when the SourceBuffer object is created and gets updated
            by the <a def-id="coded-frame-processing-algorithm"></a>.
          </p>
          <p class="note">The <a def-id="group-end-timestamp"></a> stores the highest <a def-id="coded-frame-end-timestamp"></a> across all <a def-id="track-buffers"></a> in a <a>SourceBuffer</a>. Therefore, care should be taken in setting the <a def-id="mode"></a> attribute when appending multiplexed segments in which the timestamps are not aligned across tracks.
          </p>

          <p>The <dfn id="sourcebuffer-generate-timestamps-flag">generate timestamps flag</dfn> is a
            boolean variable that keeps track of whether timestamps need to be generated for the
            <a def-id="coded-frames"></a> passed to the <a def-id="coded-frame-processing-algorithm"></a>.
            This flag is set by <a def-id="addSourceBuffer"></a> when the SourceBuffer object is created.
          </p>
          <p>When the segment parser loop algorithm is invoked, run the following steps:</p>

          <ol>
            <li><i>Loop Top:</i> If the <a def-id="input-buffer"></a> is empty, then jump to the <i>need more data</i> step below.</li>
            <li>If the <a def-id="input-buffer"></a> contains bytes that violate the <a def-id="sourcebuffer-byte-stream-format-spec"></a>, then run the
              <a def-id="eos-decode"></a> and abort this algorithm.</li>
            <li>Remove any bytes that the <a def-id="byte-stream-format-specs"></a> say must be ignored from the start of the <a def-id="input-buffer"></a>.</li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="waiting-for-segment"></a>, then run the following steps:</p>
	      <ol>
	        <li>If the beginning of the <a def-id="input-buffer"></a> indicates the start of an <a def-id="init-segment"></a>, set the <a def-id="append-state"></a> to <a def-id="parsing-init-segment"></a>.</li>
	        <li>If the beginning of the <a def-id="input-buffer"></a> indicates the start of a <a def-id="media-segment"></a>, set <a def-id="append-state"></a> to <a def-id="parsing-media-segment"></a>.</li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="parsing-init-segment"></a>, then run the following steps:</p>
	      <ol>
	        <li>If the <a def-id="input-buffer"></a> does not contain a complete <a def-id="init-segment"></a> yet, then jump to the <i>need more data</i> step below.</li>
	        <li>Run the <a def-id="init-segment-received-algorithm"></a>.</li>
	        <li>Remove the <a def-id="init-segment"></a> bytes from the beginning of the <a def-id="input-buffer"></a>.</li>
	        <li>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a>, then run the following steps:</p>
	      <ol>
                <li>If the <a def-id="first-init-segment-received-flag"></a> is false, then run the <a def-id="eos-decode"></a> and abort this algorithm.</li>
	        <li>If the <a def-id="input-buffer"></a> does not contain a complete <a def-id="media-segment"></a> header yet, then jump to the <i>need more data</i> step below.</li>
	        <li>If the <a def-id="input-buffer"></a> contains one or more complete <a def-id="coded-frames"></a>, then run the
                  <a def-id="coded-frame-processing-algorithm"></a>.
                  <p class="note">
                    The frequency at which the coded frame processing algorithm is run is implementation-specific. The coded frame processing algorithm may
                    be called when the input buffer contains the complete media segment or it may be called multiple times as complete coded frames are
                    added to the input buffer.
                  </p>
                </li>
	        <li>If this <a>SourceBuffer</a> is full and cannot accept more media data, then set the <a def-id="buffer-full-flag"></a> to true.</li>
	        <li>If the <a def-id="input-buffer"></a> does not contain a complete <a def-id="media-segment"></a>, then jump to the <i>need more data</i> step below.</p>
	        <li>Remove the <a def-id="media-segment"></a> bytes from the beginning of the <a def-id="input-buffer"></a>.</li>
	        <li>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li><i>Need more data:</i> Return control to the calling algorithm.</li>
          </ol>
        </section>

        <section id="sourcebuffer-reset-parser-state">
          <h4>Reset Parser State</h4>
          <p>When the parser state needs to be reset, run the following steps:</p>
          <ol>
            <li>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a> and the <a def-id="input-buffer"></a> contains some
              complete <a def-id="coded-frames"></a>, then run the <a def-id="coded-frame-processing-algorithm"></a> until all of these complete
              <a def-id="coded-frames"></a> have been processed.</li>
            <li>Unset the <a def-id="last-decode-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Unset the <a def-id="last-frame-duration"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Unset the <a def-id="highest-presentation-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Set the <a def-id="need-RAP-flag"></a> on all <a def-id="track-buffers"></a> to true.</li>
            <li>Remove all bytes from the <a def-id="input-buffer"></a>.</li>
            <li>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</li>
          </ol>
        </section>

        <section id="sourcebuffer-append-error">
          <h4>Append Error Algorithm</h4>
          <p>When an error occurs during an append, run the following steps:</p>
          <ol>
            <li>Run the <a def-id="reset-parser-state-algorithm"></a>.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateerror"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section id="sourcebuffer-prepare-append">
            <h4>Prepare Append Algorithm</h4>
            <p>When an append operation begins, the follow steps are run to validate and prepare the <a>SourceBuffer</a>.</p>
            <ol>
            <li>If the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a> .</li>
              </ol>
            </li>
            <li>Run the <a def-id="coded-frame-eviction-algorithm"></a>.</li>
            <li>
              <p>If the <a def-id="buffer-full-flag"></a> equals true, then throw a <a def-id="quota-exceeded-err"></a> exception and abort these step.</p>
              <p class="note">This is the signal that the implementation was unable to evict enough data to accomodate the append or the append is too big. The web
                application should use <a def-id="remove"></a> to explicitly free up space and/or reduce the size of the append.</p>
            </li>
            </ol>
        </section>

        <section id="sourcebuffer-buffer-append">
          <h4>Buffer Append Algorithm</h4>
          <p>When <a def-id="appendBuffer"></a> is called, the following steps are run to process the appended data.</p>
          <ol>
            <li>Run the <a def-id="segment-parser-loop"></a> algorithm.</li>
            <li>If the <a def-id="segment-parser-loop"></a> algorithm in the previous step was aborted, then abort this algorithm.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section id="sourcebuffer-stream-append-loop">
          <h4>Stream Append Loop</h4>
          <p>When a <a class="externalDFN">Stream</a>[[!STREAMS-API]] is passed to <a def-id="appendStream"></a>, the following steps are run to transfer data from the
            <a class="externalDFN">Stream</a> to the <a>SourceBuffer</a>. This algorithm is initialized with the  <var>stream</var> and <var>maxSize</var> parameters
            from the <a def-id="appendStream"></a> call.
          </p>
          <ol>
            <li>If <var>maxSize</var> is set, then let <var>bytesLeft</var> equal <var>maxSize</var>.</li>
            <li><i>Loop Top: </i>If <var>maxSize</var> is set and <var>bytesLeft</var> equals 0, then jump to the <i>loop done</i> step below.</li>
            <li>If <var>stream</var> has been closed, then jump to the <i>loop done</i> step below.</li>
            <li>Read data from <var>stream</var> into <var>data</var>:
              <dl class="switch">
                <dt>If <var>maxSize</var> is set:</dt>
                <dd>
                  <ol>
                    <li>Read up to <var>bytesLeft</var> bytes from <var>stream</var> into <var>data</var>.</li>
                    <li>Subtract the number of bytes in <var>data</var> from <var>bytesLeft</var>.</li>
                </dd>
                <dt>Otherwise:</dt>
                <dd>Read all available bytes in <var>stream</var> into <var>data</var>.</dd>
              </dl>
            </li>
            <li>If an error occured while reading from <var>stream</var>, then run the <a def-id="append-error-algorithm"></a> and abort this algorithm.</li>
            <li>Run the <a def-id="coded-frame-eviction-algorithm"></a>.</li>
            <li>
              <p>If the <a def-id="buffer-full-flag"></a> equals true, then run the <a def-id="append-error-algorithm"></a> and abort this algorithm.</p>
              <p class="note">The web application should use <a def-id="remove"></a> to free up space in the <a>SourceBuffer</a>.</p>
            </li>
            <li>Add <var>data</var> to the end of the <a def-id="input-buffer"></a>.</li>
            <li>Run the <a def-id="segment-parser-loop"></a> algorithm.</li>
            <li>If the <a def-id="segment-parser-loop"></a> algorithm in the previous step was aborted, then abort this algorithm.</li>
            <li>Jump to the <i>loop top</i> step above.</li>
            <li><i>Loop Done: </i>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section  id="sourcebuffer-range-removal">
          <h4>Range Removal</h4>
          <p>Follow these steps when a caller needs to initiate a JavaScript visible range removal
            operation that blocks other SourceBuffer updates:</p>
          <ol>
            <li>Let <var>start</var> equal the starting <a def-id="presentation-timestamp"></a> for the removal range.</li>
            <li>Let <var>end</var> equal the end <a def-id="presentation-timestamp"></a> for the removal range.</li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Return control to the caller and run the rest of the steps asynchronously.</li>
            <li>Run the <a def-id="coded-frame-removal-algorithm"></a> with <var>start</var> and <var>end</var> as the start and end of the removal range.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>
        <section id="sourcebuffer-init-segment-received">
          <h4>Initialization Segment Received</h4>
          <p>The following steps are run when the <a def-id="segment-parser-loop"></a> successfully parses a complete <a def-id="init-segment"></a>:</p>
          <p>Each SourceBuffer object has an internal <dfn id="first-init-segment-received-flag">first initialization segment received flag</dfn> that tracks whether the first <a def-id="init-segment"></a> has been appended and received by this algorithm. This flag is set to false when the SourceBuffer is created and updated by the algorithm below.</p>
          <ol>
            <li>Update the <a def-id="duration"></a> attribute if it currently equals NaN:
              <dl class="switch">
	        <dt>If the initialization segment contains a duration:</dt>
	        <dd>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the duration in the initialization segment.</dd>
	        <dt>Otherwise:</dt>
	        <dd>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to positive Infinity.</dd>
              </dl>
            </li>
            <li>If the <a def-id="init-segment"></a> has no audio, video, or text tracks, then run the <a def-id="eos-decode"></a> and abort these steps.</li>
            <li>If the <a def-id="first-init-segment-received-flag"></a> is true, then run the following steps:
              <ol>
                <li>Verify the following properties. If any of the checks fail then run the <a def-id="eos-decode"></a> and abort these steps.
                  <ul>
                    <li>The number of audio, video, and text tracks match what was in the first <a def-id="init-segment"></a>.</li>
                    <li>The codecs for each track, match what was specified in the first <a def-id="init-segment"></a>.</li>
                    <li>If more than one track for a single type are present (ie 2 audio tracks), then the <a def-id="track-ids"></a> match the ones in the
                      first <a def-id="init-segment"></a>.</li>
                  </ul>
                </li>
                <li>Add the appropriate <a def-id="track-descriptions"></a> from this <a def-id="init-segment"></a> to each of the 
                  <a def-id="track-buffers"></a>.</li>
                <li>Set the <a def-id="need-RAP-flag"></a> on all track buffers to true.</li>
              </ol>
            </li>
            <li>Let <var>active track flag</var> equal false.</li>
            <li>
              <p>If the <a def-id="first-init-segment-received-flag"></a> is false, then run the following steps:</p>
              <ol>
                <li>If the <a def-id="init-segment"></a> contains tracks with codecs the user agent does not support, then run the <a def-id="eos-decode"></a>
                  and abort these steps.
                  <p class="note">User agents may consider codecs, that would otherwise be supported, as &quot;not supported&quot; here if the codecs were not
                    specified in the <var>type</var> parameter passed to <a def-id="addSourceBuffer"></a>. <br>
                    For example, MediaSource.isTypeSupported('video/webm;codecs=&quot;vp8,vorbis&quot;') may return true, but if
                    <a def-id="addSourceBuffer"></a> was called with 'video/webm;codecs=&quot;vp8&quot;' and a Vorbis track appears in the
                    <a def-id="init-segment"></a>, then the user agent may use this step to trigger a decode error.
                  </p>
                </li>
                <li>
                  <p>For each audio track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>Let <var>audio byte stream track ID</var> be the
                      <a def-id="track-id"></a> for the current track being processed.</li>
                    <li>Let <var>audio language</var> be a BCP 47 language tag for the language
                      specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      language info is present.</li>
                    <li>If <var>audio language</var> equals an empty string or the 'und' BCP 47 value, then run the
                      <a def-id="default-track-language-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>audio byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-audio"></a> and assign the value returned by the
                      algorithm to <var>audio language</var>.</li>
                    <li>Let <var>audio label</var> be a label specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      label info is present.</li>
                    <li>If <var>audio label</var> equals an empty string, then run the
                      <a def-id="default-track-label-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>audio byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-audio"></a> and assign the value returned by the
                      algorithm to <var>audio label</var>.</li>
                    <li>Let <var>audio kinds</var> be an array of kind strings specified in the
                      <a def-id="init-segment"></a> for this track or an empty array if no kind information
                      is provided.</li>
                    <li>If <var>audio kinds</var> equals an empty array, then run the
                      <a def-id="default-track-kinds-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>audio byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-audio"></a> and assign the value returned by the
                      algorithm to <var>audio kinds</var>.</li>
                    <li>For each value in <var>audio kinds</var>, run the following steps:
                      <ol>
                        <li>Let <var>current audio kind</var> equal the value from <var>audio kinds</var>
                          for this iteration of the loop.</li>
                        <li>Let <var>new audio track</var> be a new <a def-id="audio-track"></a> object.</li>
                        <li>Generate a unique ID and assign it to the <a def-id="audiotrack-id"></a> property on <var>new audio track</var>.</li>
                        <li>Assign <var>audio language</var> to the <a def-id="audiotrack-language"></a>
                          property on <var>new audio track</var>.</li>
                        <li>Assign <var>audio label</var> to the <a def-id="audiotrack-label"></a>
                          property on <var>new audio track</var>.</li>
                        <li>Assign <var>current audio kind</var> to the <a def-id="audiotrack-kind"></a>
                          property on <var>new audio track</var>.</li>
                        <li>
                          <p>
                            If <a def-id="audiotracks"></a>.<a def-id="audiotracklist-length"></a> equals 0, then run
                            the following steps:
                          </p>
                          <ol>
                            <li>Set the <a def-id="audiotrack-enabled"></a> property on <var>new audio track</var> to true.</li>
                            <li>Set <var>active track flag</var> to true.</li>
                          </ol>
                        </li>
                        <li>Add <var>new audio track</var> to the <a def-id="sourcebuffer-audioTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at the <a def-id="audio-track-list"></a> object referenced by the
                          <a def-id="sourcebuffer-audioTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                        <li>Add <var>new audio track</var> to the <a def-id="audiotracks"></a> attribute on the HTMLMediaElement.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at the <a def-id="audio-track-list"></a> object referenced by the <a def-id="audiotracks"></a>
                          attribute on the HTMLMediaElement.</li>
                      </ol>
                    </li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>
                  <p>For each video track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>Let <var>video byte stream track ID</var> be the
                      <a def-id="track-id"></a> for the current track being processed.</li>
                    <li>Let <var>video language</var> be a BCP 47 language tag for the language
                      specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      language info is present.</li>
                    <li>If <var>video language</var> equals an empty string or the 'und' BCP 47 value, then run the
                      <a def-id="default-track-language-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>video byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-video"></a> and assign the value returned by the
                      algorithm to <var>video language</var>.</li>
                    <li>Let <var>video label</var> be a label specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      label info is present.</li>
                    <li>If <var>video label</var> equals an empty string, then run the
                      <a def-id="default-track-label-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>video byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-video"></a> and assign the value returned by the
                      algorithm to <var>video label</var>.</li>
                    <li>Let <var>video kinds</var> be an array of kind strings specified in the
                      <a def-id="init-segment"></a> for this track or an empty array if no kind information
                      is provided.</li>
                    <li>If <var>video kinds</var> equals an empty array, then run the
                      <a def-id="default-track-kinds-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>video byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-video"></a> and assign the value returned by the
                      algorithm to <var>video kinds</var>.</li>
                    <li>For each value in <var>video kinds</var>, run the following steps:
                      <ol>
                        <li>Let <var>current video kind</var> equal the value from <var>video kinds</var>
                          for this iteration of the loop.</li>
                        <li>Let <var>new video track</var> be a new <a def-id="video-track"></a> object.</li>
                        <li>Generate a unique ID and assign it to the <a def-id="videotrack-id"></a> property on <var>new video track</var>.</li>
                        <li>Assign <var>video language</var> to the <a def-id="videotrack-language"></a>
                          property on <var>new video track</var>.</li>
                        <li>Assign <var>video label</var> to the <a def-id="videotrack-label"></a>
                          property on <var>new video track</var>.</li>
                        <li>Assign <var>current video kind</var> to the <a def-id="videotrack-kind"></a>
                          property on <var>new video track</var>.</li>
                        <li>
                          <p>
                            If <a def-id="videotracks"></a>.<a def-id="videotracklist-length"></a> equals 0, then run
                            the following steps:
                          </p>
                          <ol>
                            <li>Set the <a def-id="videotrack-selected"></a> property on <var>new video track</var> to true.</li>
                            <li>Set <var>active track flag</var> to true.</li>
                          </ol>
                        </li>
                        <li>Add <var>new video track</var> to the <a def-id="sourcebuffer-videoTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at the <a def-id="video-track-list"></a> object referenced by the <a def-id="sourcebuffer-videoTracks"></a> attribute
                          on this <a>SourceBuffer</a> object.</li>
                        <li>Add <var>new video track</var> to the <a def-id="videotracks"></a> attribute on the HTMLMediaElement.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at the <a def-id="video-track-list"></a> object referenced by the <a def-id="videotracks"></a> attribute on the
                          HTMLMediaElement.</li>
                      </ol>
                    </li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>
                  <p>For each text track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>Let <var>text byte stream track ID</var> be the 
                      <a def-id="track-id"></a> for the current track being processed.</li>
                    <li>Let <var>text language</var> be a BCP 47 language tag for the language
                      specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      language info is present.</li>
                    <li>If <var>text language</var> equals an empty string or the 'und' BCP 47 value, then run the
                      <a def-id="default-track-language-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>text byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-text"></a> and assign the value returned by the
                      algorithm to <var>text language</var>.</li>
                    <li>Let <var>text label</var> be a label specified in the <a def-id="init-segment"></a> for this track or an empty string if no
                      label info is present.</li>
                    <li>If <var>text label</var> equals an empty string, then run the
                      <a def-id="default-track-label-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>text byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-text"></a> and assign the value returned by the
                      algorithm to <var>text label</var>.</li>
                    <li>Let <var>text kinds</var> be an array of kind strings specified in the
                      <a def-id="init-segment"></a> for this track or an empty array if no kind information
                      is provided.</li>
                    <li>If <var>text kinds</var> equals an empty array, then run the
                      <a def-id="default-track-kinds-algorithm"></a> with <var>byteStreamTrackID</var>
                      set to <var>text byte stream track ID</var> and <var>type</var> set to
                      <a def-id="TrackDefaultType-text"></a> and assign the value returned by the
                      algorithm to <var>text kinds</var>.</li>
                    <li>For each value in <var>text kinds</var>, run the following steps:
                      <ol>
                        <li>Let <var>current text kind</var> equal the value from <var>text kinds</var>
                          for this iteration of the loop.</li>
                        <li>
                          Let <var>new text track</var> be a new <a def-id="text-track"></a> object.</li>
                        <li>Generate a unique ID and assign it to the <a def-id="texttrack-id"></a> property on <var>new text track</var>.</li>
                        <li>Assign <var>text language</var> to the <a def-id="texttrack-language"></a>
                          property on <var>new text track</var>.</li>
                        <li>Assign <var>text label</var> to the <a def-id="texttrack-label"></a>
                          property on <var>new text track</var>.</li>
                        <li>Assign <var>current text kind</var> to the <a def-id="texttrack-kind"></a>
                          property on <var>new text track</var>.</li>
                        <li>Populate the remaining properties on <var>new text track</var> with the
                          appropriate information from the <a def-id="init-segment"></a>.
                        <li>
                          If the <a def-id="texttrack-mode"></a> property on <var>new text track</var> equals <a def-id="texttrack-showing"></a> or
                          <a def-id="texttrack-hidden"></a>, then set <var>active track flag</var> to true.
                        </li>
                        <li>Add <var>new text track</var> to the <a def-id="sourcebuffer-textTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at <a def-id="sourcebuffer-textTracks"></a> attribute
                          on this <a>SourceBuffer</a> object.</li>
                        <li>Add <var>new text track</var> to the <a def-id="texttracks"></a> attribute on the HTMLMediaElement.</li>
                        <li><a def-id="Queue-and-fire-addtrack"></a> at the <a def-id="text-track-list"></a> object referenced by the <a def-id="texttracks"></a> attribute on the
                          HTMLMediaElement.</li>
                      </ol>
                    </li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>If <var>active track flag</var> equals true, then run the following steps:
                  <ol>
                    <li>Add this <a>SourceBuffer</a> to <a def-id="activeSourceBuffers"></a>.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a></li>
                  </ol>
                </li>
                <li>Set <a def-id="first-init-segment-received-flag"></a> to true.</li>
              </ol>
            </li>
            <li>
              <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-nothing"></a>, then run the following steps:</p>
              <ol>
                <li>
                  If one or more objects in <a def-id="sourceBuffers"></a> have <a def-id="first-init-segment-received-flag"></a> set to false, then abort
                  these steps.</li>
                <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a>  <a def-id="loadedmetadata"></a> at the media element.</li>
              </ol>
            </li>
            <li>
              If the <var>active track flag</var> equals true and the <a def-id="ready-state"></a> attribute is greater than
              <a def-id="have-current-data"></a>, then set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.
            </li>
          </ol>
        </section>

        <section id="sourcebuffer-default-track-language">
          <h4>Default track language</h4>
          <p>The following steps are run when the <a def-id="init-segment-received-algorithm"></a> needs
            to determine what the default language for a new track should be. This algorithm is initialized
            with <var>byteStreamTrackID</var> and <var>type</var> parameters when invoked by the
            <a def-id="init-segment-received-algorithm"></a>.</p>
          <ol>
            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              <var>byteStreamTrackID</var>, then return the value of the
              <a def-id="TrackDefault-language"></a> attribute on this matching object and abort these
              steps.</li>

            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              an empty string, then return the value of the
              <a def-id="TrackDefault-language"></a> attribute on this matching object and abort these
              steps.</li>

            <li>Return an empty string to the caller.</li>
          </ol>
        </section>

        <section id="sourcebuffer-default-track-label">
          <h4>Default track label</h4>
          <p>The following steps are run when the <a def-id="init-segment-received-algorithm"></a> needs
            to determine what the default label for a new track should be. This algorithm is initialized
            with <var>byteStreamTrackID</var> and <var>type</var> parameters when invoked by the
            <a def-id="init-segment-received-algorithm"></a>.</p>
          <ol>
            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              <var>byteStreamTrackID</var>, then return the value of the
              <a def-id="TrackDefault-label"></a> attribute on this matching object and abort these
              steps.</li>

            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              an empty string, then return the value of the
              <a def-id="TrackDefault-label"></a> attribute on this matching object and abort these
              steps.</li>

            <li>Return an empty string to the caller.</li>
          </ol>
        </section>

        <section id="sourcebuffer-default-track-kinds">
          <h4>Default track kinds</h4>
          <p>The following steps are run when the <a def-id="init-segment-received-algorithm"></a> needs
            to determine what the default kinds for a new track should be. This algorithm is initialized
            with <var>byteStreamTrackID</var> and <var>type</var> parameters when invoked by the
            <a def-id="init-segment-received-algorithm"></a>.</p>
          <ol>
            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              <var>byteStreamTrackID</var>, then return the value of the
              <a def-id="TrackDefault-kinds"></a> attribute on this matching object and abort these
              steps.</li>

            <li>If <a def-id="trackDefaults"></a> contains a <a>TrackDefault</a> object with a
              <a def-id="TrackDefault-type"></a> attribute equal to <var>type</var> and a
              <a def-id="TrackDefault-byteStreamTrackID"></a> attribute equal to
              an empty string, then return the value of the
              <a def-id="TrackDefault-kinds"></a> attribute on this matching object and abort these
              steps.</li>

            <li>Return an array with a single empty string element in it to the caller.</li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-processing">
          <h4>Coded Frame Processing</h4>
          <p>When complete <a def-id="coded-frames"></a> have been parsed by the <a def-id="segment-parser-loop"></a> then the following steps are run:</p>
          <ol>
            <li>
	      <p>For each <a def-id="coded-frame"></a> in the <a def-id="media-segment"></a> run the following steps:</p>
	      <ol>
	        <li><i>Loop Top: </i><dl class="switch">
                    <dt>If <a def-id="generate-timestamps-flag"></a> equals true:</dt>
                    <dd>
                      <ol>
                        <li>Let <var>presentation timestamp</var> equal 0.</li>
                        <li>Let <var>decode timestamp</var> equal 0.</li>
                      </ol>
                    </dd>
                    <dt>Otherwise:</dt>
                    <dd>
                      <ol>
                        <li>Let <var>presentation timestamp</var> be a double precision floating point representation of the coded frame's <a def-id="presentation-timestamp"></a> in seconds.
                          <p class="note">Special processing may be needed to determine the presentation and decode timestamps for timed text frames since this information may not be explicitly
                            present in the underlying format or may be dependent on the order of the frames. Some metadata text tracks, like MPEG2-TS PSI data, may only have implied timestamps.
                            Format specific rules for these situations should be in the <a def-id="byte-stream-format-specs"></a> or in separate extension specifications.</p>
                        </li>
	                <li>Let <var>decode timestamp</var> be a double precision floating point representation of the coded frame's decode timestamp in seconds.
                          <p class="note">Implementations don't have to internally store timestamps in a double precision floating point representation. This
                            representation is used here because it is the represention for timestamps in the HTML spec. The intention here is to make the
                            behavior clear without adding unnecessary complexity to the algorithm to deal with the fact that adding a timestampOffset may
                            cause a timestamp rollover in the underlying timestamp representation used by the byte stream format. Implementations can use any
                            internal timestamp representation they wish, but the addition of timestampOffset should behave in a similar manner to what would happen
                            if a double precision floating point representation was used.
                          </p>
                        </li>
                    </ol>
                    </dd>
                  </dl>
                </li>
                <li>Let <var>frame duration</var> be a double precision floating point representation of the <a def-id="coded-frames-duration"></a> in seconds.</li>
                <li>If <a def-id="mode"></a> equals <a def-id="AppendMode-sequence"></a> and <a def-id="group-start-timestamp"></a> is set, then run the following steps:
                  <ol>
                    <li>Set <a def-id="timestampOffset"></a> equal to <a def-id="group-start-timestamp"></a> - <var>presentation timestamp</var>.</li>
                    <li>Set <a def-id="group-end-timestamp"></a> equal to <a def-id="group-start-timestamp"></a>.</li>
                    <li>Set the <a def-id="need-RAP-flag"></a> on all <a def-id="track-buffers"></a> to true.</li>
                    <li>Unset <a def-id="group-start-timestamp"></a>.</li>
                  </ol>
                </li>
	        <li>
	          <p>If <a def-id="timestampOffset"></a> is not 0, then run the following steps:</p>
	          <ol>
	            <li>Add <a def-id="timestampOffset"></a> to the <var>presentation timestamp</var>.</li>
	            <li>Add <a def-id="timestampOffset"></a> to the <var>decode timestamp</var>.</li>
	          </ol>
	        </li>
                <li>Let <var>track buffer</var> equal the <a def-id="track-buffer"></a> that the coded frame will be added to.</li>
                <li>
                  <dl class="switch">
                    <dt>If <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> is set and <var>decode timestamp</var> is less than
                      <a def-id="last-decode-timestamp"></a>:</dt>
                    <dd>OR</dd>
                    <dt>If <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> is set and the difference between <var>decode timestamp</var> and <a def-id="last-decode-timestamp"></a>
                      is greater than 2 times <a def-id="last-frame-duration"></a>:</dt>
                    <dd>
                      <ol>
                        <li>
                          <dl class="switch">
                            <dt>If <a def-id="mode"></a> equals <a def-id="AppendMode-segments"></a>:</dt>
                            <dd>Set <a def-id="group-end-timestamp"></a> to <var>presentation timestamp</var>.</dd>
                            <dt>If <a def-id="mode"></a> equals <a def-id="AppendMode-sequence"></a>:</dt>
                            <dd>Set <a def-id="group-start-timestamp"></a> equal to the <a def-id="group-end-timestamp"></a>.</dd>
                          </dl>
                        </li>
                        <li>Unset the <a def-id="last-decode-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
                        <li>Unset the <a def-id="last-frame-duration"></a> on all <a def-id="track-buffers"></a>.</li>
                        <li>Unset the <a def-id="highest-presentation-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
                        <li>Set the <a def-id="need-RAP-flag"></a> on all <a def-id="track-buffers"></a> to true.</li>
                        <li>Jump to the <i>Loop Top</i> step above to restart processing of the current <a def-id="coded-frame"></a>.</li>
                      </ol>
                    </dd>
                    <dt>Otherwise:</dt>
                    <dd>Continue.</dd>
                  </dl>
                </li>
                <li>Let <var>frame end timestamp</var> equal the sum of <var>presentation timestamp</var> and <var>frame duration</var>.</li>
                <li>If <var>presentation timestamp</var> is less than <a def-id="appendWindowStart"></a>, then set the <a def-id="need-RAP-flag"></a> to true, drop the
                  coded frame, and jump to the top of the loop to start processing the next coded frame.
                  <p class="note">Some implementations may choose to collect some of these coded frames that are outside the <a def-id="append-window"></a> and use them
                    to generate a splice at the first coded frame that has a <a def-id="presentation-timestamp"></a> greater than or equal to <a def-id="appendWindowStart"></a> even if
                    that frame is not a <a def-id="random-access-point"></a>. Supporting this requires multiple decoders or faster than real-time decoding so for now
                    this behavior will not be a normative requirement.
                  </p>
                </li>
                <li>If <var>frame end timestamp</var> is greater than <a def-id="appendWindowEnd"></a>, then set the <a def-id="need-RAP-flag"></a> to true, drop the
                  coded frame, and jump to the top of the loop to start processing the next coded frame.
	        <li>If the <var>decode timestamp</var> is less than the <a def-id="presentation-start-time"></a>,
                  then run the <a def-id="eos-decode"></a>, and abort these steps.</li>
                <li>If the <a def-id="need-RAP-flag"></a> on <var>track buffer</var> equals true, then run the following steps:
                  <ol>
                    <li>If the coded frame is not a <a def-id="random-access-point"></a>, then drop the coded frame and jump to the top of the loop to start
                      processing the next coded frame.</li>
                    <li>Set the <a def-id="need-RAP-flag"></a> on <var>track buffer</var> to false.</li>
                  </ol>
                </li>
                <li>Let <var>spliced audio frame</var> be an unset variable for holding audio splice information</li>
                <li>Let <var>spliced timed text frame</var> be an unset variable for holding timed text splice information</li>
                <li>If <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> is unset and <var>presentation timestamp</var> falls within the <a def-id="presentation-interval"></a> of a <a def-id="coded-frame"></a> in <var>track buffer</var>,then run the following steps:
                  <ol>
                    <li>Let <var>overlapped frame</var> be the <a def-id="coded-frame"></a> in <var>track buffer</var> that matches the condition above.</li>
                    <li>
                      <dl class="switch">
                        <dt>If <var>track buffer</var> contains audio <a def-id="coded-frames"></a>:</dt>
                        <dd>Run the <a def-id="audio-splice-frame-algorithm"></a> and if a splice frame is returned, assign it to <var>spliced audio frame</var>.</dd>
                        <dt>If <var>track buffer</var> contains video <a def-id="coded-frames"></a>:</dt>
                        <dd>
                          <ol>
                            <li>Let <var>overlapped frame presentation timestamp</var> equal the <a def-id="presentation-timestamp"></a> of <var>overlapped frame</var>.</li>
                            <li>Let <var>remove window timestamp</var> equal <var>overlapped frame presentation timestamp</var> plus 1 microsecond.</li>
                            <li>If the <var>presentation timestamp</var> is less than the <var>remove window timestamp</var>, then remove <var>overlapped frame</var> and any
                              <a def-id="coded-frames"></a> that depend on it from <var>track buffer</var>.
                              <p class="note">
                                This is to compensate for minor errors in frame timestamp computations that can appear when converting back and forth between double precision
                                floating point numbers and rationals. This tolerance allows a frame to replace an existing one as long as it is within 1 microsecond of the existing
                                frame's start time. Frames that come slightly before an existing frame are handled by the removal step below.
                              </p>
                            </li>
                          </ol>
                        </dd>
                        <dt>If <var>track buffer</var> contains timed text <a def-id="coded-frames"></a>:</dt>
                        <dd>Run the <a def-id="text-splice-frame-algorithm"></a> and if a splice frame is returned, assign it to <var>spliced timed text frame</var>.</dd>
                      </dl>
                    </li>
                  </ol>
                </li>
                <li>Remove existing coded frames in <var>track buffer</var>:
                  <dl class="switch">
                    <dt>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is not set:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have a <a def-id="presentation-timestamp"></a> greater than or equal to
                      <var>presentation timestamp</var> and less than <var>frame end timestamp</var>.</dd>
                    <dt>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is set and less than or equal to <var>presentation timestamp</var>:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have a <a def-id="presentation-timestamp"></a> greater than
                      or equal to <a def-id="highest-presentation-timestamp"></a> and less than <var>frame end timestamp</var></dd>
                  </dl>
                </li>
                <li>Remove decoding dependencies of the coded frames removed in the previous step:
                  <dl class="switch">
                    <dt>If detailed information about decoding dependencies is available:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have decoding dependencies on the coded frames removed in
                      the previous step.
                      <p class="note">For example if an I-frame is removed in the previous step, then all P-frames & B-frames that depend on that I-frame
                        should be removed from <var>track buffer</var>. This makes sure that decode dependencies are properly maintained during overlaps.
                      </p>
                    </dd>
                    <dt>Otherwise:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> between the coded frames removed in the previous step and the next
                      <a def-id="random-access-point"></a> after those removed frames.
                      <p class="note">Removing all <a def-id="coded-frames"></a> until the next <a def-id="random-access-point"></a> is a conservative
                        estimate of the decoding dependencies since it assumes all frames between the removed frames and the next random access point
                        depended on the frames that were removed.
                      </p>
                    </dd>
                </li>
                <li>
                  <dl class="switch">
                    <dt>If <var>spliced audio frame</var> is set:</dt>
                    <dd>Add <var>spliced audio frame</var> to the <var>track buffer</var>.</dd>
                    <dt>If <var>spliced timed text frame</var> is set:</dt>
                    <dd>Add <var>spliced timed text frame</var> to the <var>track buffer</var>.</dd>
                    <dt>Otherwise:</dt>
                    <dd>Add the <a def-id="coded-frame"></a> with the <var>presentation timestamp</var>, <var>decode timestamp</var>, and <var>frame duration</var> to the
                      <var>track buffer</var>.</dd>
                  </dl>
                <li>Set <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> to <var>decode timestamp</var>.</li>
                <li>Set <a def-id="last-frame-duration"></a> for <var>track buffer</var> to <var>frame duration</var>.</li>
                <li>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is unset or <var>frame end timestamp</var> is greater
                  than <a def-id="highest-presentation-timestamp"></a>, then set <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var>
                  to <var>frame end timestamp</var>.
                  <p class="note">The greater than check is needed because bidirectional prediction between coded frames can cause
                    <var>presentation timestamp</var> to not be monotonically increasing eventhough the decode timestamps are monotonically increasing.</p>
                </li>
                <li>If <var>frame end timestamp</var> is greater than <a def-id="group-end-timestamp"></a>,
                  then set <a def-id="group-end-timestamp"></a> equal to <var>frame end timestamp</var>.</li>
                <li>If <a def-id="generate-timestamps-flag"></a> equals true, then set
                  <a def-id="timestampOffset"></a> equal to <var>frame end timestamp</var>.</li>
	      </ol>
            </li>
            <li>
              <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-metadata"></a> and the new <a def-id="coded-frames"></a> cause <a def-id="hme-buffered"></a> to have a <a def-id="timerange"></a> for the current playback position, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-current-data"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-current-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadeddata"></a> at the media element.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-current-data"></a> and the new <a def-id="coded-frames"></a> cause <a def-id="hme-buffered"></a> to have a <a def-id="timerange"></a> that includes the current playback position and some time beyond the current playback position, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-future-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplay"></a> at the media element.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-future-data"></a> and the new <a def-id="coded-frames"></a> cause <a def-id="hme-buffered"></a> to have a <a def-id="timerange"></a> that includes the current playback position and <a def-id="enough-data"></a>, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-enough-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplaythrough"></a> at the media element.</li>
	      </ol>
            </li>
            <li>If the <a def-id="media-segment"></a> contains data beyond the current <a def-id="duration"></a>, then run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the maximum of the current duration and the <a def-id="group-end-timestamp"></a>.</li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-removal">
          <h4>Coded Frame Removal Algorithm</h4>
          <p>Follow these steps when <a def-id="coded-frames"></a> for a specific time range need to be removed from the SourceBuffer:</p>
          <ol>
            <li>Let <var>start</var> be the starting <a def-id="presentation-timestamp"></a> for the removal range.</li>
            <li>Let <var>end</var> be the end <a def-id="presentation-timestamp"></a> for the removal range. </li>
            <li><p>For each <a def-id="track-buffer"></a> in this source buffer, run the following steps:</p>
              <ol>
	        <li>Let <var>remove end timestamp</var> be the current value of <a def-id="duration"></a></li>
                <li>
                  <p>If this <a def-id="track-buffer"></a> has a <a def-id="random-access-point"></a> timestamp that is greater than or equal to
                    <var>end</var>, then update <var>remove end timestamp</var> to that random access point timestamp.</p>
	          <p class="note">Random access point timestamps can be different across tracks because the dependencies between <a def-id="coded-frames"></a> within a
                    track are usually different than the dependencies in another track.</p>
                </li>
	        <li>Remove all media data, from this <a def-id="track-buffer"></a>, that contain starting timestamps greater than or equal to
                  <var>start</var> and less than the <var>remove end timestamp</var>.</li>
                <li>Remove decoding dependencies of the coded frames removed in the previous step:
                  <dl class="switch">
                    <dt>If detailed information about decoding dependencies is available:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from this <a def-id="track-buffer"></a> that have decoding dependencies on the coded frames removed in
                      the previous step.
                      <p class="note">For example if an I-frame is removed in the previous step, then all P-frames & B-frames that depend on that I-frame
                        should be removed from this <a def-id="track-buffer"></a>.
                      </p>
                    </dd>
                    <dt>Otherwise:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> between the coded frames removed in the previous step and the next
                      <a def-id="random-access-point"></a> after those removed frames.
                      <p class="note">Removing all <a def-id="coded-frames"></a> until the next <a def-id="random-access-point"></a> is a conservative
                        estimate of the decoding dependencies since it assumes all frames between the removed frames and the next random access point
                        depended on the frames that were removed.
                      </p>
                    </dd>
                </li>
                <li>
                  <p>If this object is in <a def-id="activeSourceBuffers"></a>, the <a def-id="current-playback-position"></a> is greater than or equal to
                    <var>start</var> and less than the <var>remove end timestamp</var>, and <a def-id="ready-state"></a> is greater than
                    <a def-id="have-metadata"></a>, then set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a> and stall playback.</p>
                  <p class="note">This transition occurs because media data for the current position has been removed. Playback cannot progress until media for the
                    <a def-id="current-playback-position"></a> is appended or the <a href="#active-source-buffer-changes">selected/enabled tracks change</a>.</p>
                </li>
	      </ol>
            </li>
            <li>If <a def-id="buffer-full-flag"></a> equals true and this object is ready to accept more bytes, then set
              the <a def-id="buffer-full-flag"></a> to false.</li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-eviction">
          <h4>Coded Frame Eviction Algorithm</h4>
          <p>This algorithm is run to free up space in this source buffer when new data is appended.</p>
          <ol>
            <li>Let <var>new data</var> equal the data that is about to be appended to this SourceBuffer.</li>
            <li>If the <a def-id="buffer-full-flag"></a> equals false, then abort these steps.</li>
            <li>Let <var>removal ranges</var> equal a list of presentation time ranges that can be evicted from the presentation to make room for the
              <var>new data</var>.
              <p class="note">Implementations may use different methods for selecting <var>removal ranges</var> so web applications should not depend on a
                specific behavior. The web application can use the <a def-id="buffered"></a> attribute to observe whether portions of the buffered data have been evicted.
              </p>
            </li>
            <li>For each range in <var>removal ranges</var>, run the <a def-id="coded-frame-removal-algorithm"></a> with <var>start</var> and <var>end</var> equal to
              the removal range start and end timestamp respectively.</li>
          </ol>
        </section>

        <section id="sourcebuffer-audio-splice-frame-algorithm">
          <h4>Audio Splice Frame Algorithm</h4>
          <p>Follow these steps when the <a def-id="coded-frame-processing-algorithm"></a> needs to generate a splice frame for two overlapping audio
            <a def-id="coded-frames"></a>:</p>
          <ol>
            <li>Let <var>track buffer</var> be the <a def-id="track-buffer"></a> that will contain the splice.</li>
            <li>Let <var>new coded frame</var> be the new <a def-id="coded-frame"></a>, that is being added to <var>track buffer</var>, which triggered the need for a splice.</li>
            <li>Let <var>presentation timestamp</var> be the <a def-id="presentation-timestamp"></a> for <var>new coded frame</var></li>
            <li>Let <var>decode timestamp</var> be the decode timestamp for <var>new coded frame</var>.</li>
            <li>Let <var>frame duration</var> be the <a def-id="coded-frame-duration"></a> of <var>new coded frame</var>.</li>
            <li>Let <var>overlapped frame</var> be the <a def-id="coded-frame"></a> in <var>track buffer</var> with a <a def-id="presentation-interval"></a> that contains <var>presentation timestamp</var>.
            </li>
            <li>Update <var>presentation timestamp</var> and <var>decode timestamp</var> to the nearest audio sample timestamp based on sample rate of the 
              audio in <var>overlapped frame</var>. If a timestamp is equidistant from both audio sample timestamps, then use the higher timestamp. (eg.
              floor(x * sample_rate + 0.5) / sample_rate).
              <div class="note">
                <p>For example, given the following values:</p>
                <ul>
                  <li>The <a def-id="presentation-timestamp"></a> of <var>overlapped frame</var> equals 10.</li>
                  <li>The sample rate of <var>overlapped frame</var> equals 8000 Hz</li>
                  <li><var>presentation timestamp</var> equals 10.01255</li>
                  <li><var>decode timestamp</var> equals 10.01255</li>
                </ul>
                <p><var>presentation timestamp</var> and <var>decode timestamp</var> are updated to 10.0125 since 10.01255 is closer to
                10 + 100/8000 (10.0125) than 10 + 101/8000 (10.012625)</p>
              </div>
            </li>
            <li>If the user agent does not support crossfading then run the following steps:
              <ol>
                <li>Remove <var>overlapped frame</var> from <var>track buffer</var>.</li>
                <li>Add a silence frame to <var>track buffer</var> with the following properties:
                  <ul>
                    <li>The <a def-id="presentation-timestamp"></a> set to the <var>overlapped frame</var> <a def-id="presentation-timestamp"></a>.</li>
                    <li>The <a def-id="decode-timestamp"></a> set to the <var>overlapped frame</var> <a def-id="decode-timestamp"></a>.</li>
                    <li>The <a def-id="coded-frame-duration"></a> set to difference between <var>presentation timestamp</var> and the <var>overlapped frame</var> <a def-id="presentation-timestamp"></a>.</li>
                  </ul>
                  <p class="note">
                    Some implementations may apply fades to/from silence to coded frames on either side of the inserted silence to make the transition less
                    jarring.
                  </p>
                </li>
                <li>Return to caller without providing a splice frame.
                  <p class="note">
                    This is intended to allow <var>new coded frame</var> to be added to the <var>track buffer</var> as if
                    <var>overlapped frame</var> had not been in the <var>track buffer</var> to begin with.
                  </p>
                </li>
              </ol>
            </li>
            <li>Let <var>frame end timestamp</var> equal the sum of <var>presentation timestamp</var> and <var>frame duration</var>.</li>
            <li>Let <var>splice end timestamp</var> equal the sum of <var>presentation timestamp</var> and the splice duration of 5 milliseconds.</li>
            <li>Let <var>fade out coded frames</var> equal <var>overlapped frame</var> as well as any additional frames in <var>track buffer</var> that
              have a <a def-id="presentation-timestamp"></a> greater than <var>presentation timestamp</var> and less than <var>splice end timestamp</var>.</li>
            <li>Remove all the frames included in <var>fade out coded frames</var> from <var>track buffer</var>.
            <li>Return a splice frame with the following properties:
              <ul>
                <li>The <a def-id="presentation-timestamp"></a> set to the <var>overlapped frame</var> <a def-id="presentation-timestamp"></a>.</li>
                <li>The <a def-id="decode-timestamp"></a> set to the <var>overlapped frame</var> <a def-id="decode-timestamp"></a>.</li>
                <li>The <a def-id="coded-frame-duration"></a> set to difference between <var>frame end timestamp</var> and the <var>overlapped frame</var> <a def-id="presentation-timestamp"></a>.</li>
                <li>The fade out coded frames equals <var>fade-out coded frames</var>.</li>
                <li>The fade in coded frame equal <var>new coded frame</var>.
                  <p class="note">If the <var>new coded frame</var> is less than 5 milliseconds in duration, then coded frames that are appended after the
                    <var>new coded frame</var> will be needed to properly render the splice.</p>
                </li>
                <li>The splice timestamp equals <var>presentation timestamp</var>.</li>
              </ul>
              <p class="note">See the <a def-id="audio-splice-rendering-algorithm"></a> for details on how this splice frame is rendered.</p>
            </li>
          </ol>
        </section>
        <section id="sourcebuffer-audio-splice-rendering-algorithm">
          <h4>Audio Splice Rendering Algorithm</h4>
          <p>The following steps are run when a spliced frame, generated by the <a def-id="audio-splice-frame-algorithm"></a>, needs to be rendered by the
            media element:</p>
          <ol>
            <li>Let <var>fade out coded frames</var> be the <a def-id="coded-frames"></a> that are faded out during the splice.</li>
            <li>Let <var>fade in coded frames</var> be the <a def-id="coded-frames"></a> that are faded in during the splice.</li>
            <li>Let <var>presentation timestamp</var> be the <a def-id="presentation-timestamp"></a> of the first coded frame in <var>fade out coded frames</var>.</li>
            <li>Let <var>end timestamp</var> be the sum of the <a def-id="presentation-timestamp"></a> and the <a def-id="coded-frame-duration"></a> of the last frame in <var>fade in coded frames</var>.</li>
            <li>Let <var>splice timestamp</var> be the <a def-id="presentation-timestamp"></a> where the splice starts. This corresponds with the <a def-id="presentation-timestamp"></a> of the first frame in
              <var>fade in coded frames</var>.</li>
            <li>Let <var>splice end timestamp</var> equal <var>splice timestamp</var> plus five milliseconds.</li>
            <li>Let <var>fade out samples</var> be the samples generated by decoding <var>fade out coded frames</var>.</li>
            <li>Trim <var>fade out samples</var> so that it only contains samples between <var>presentation timestamp</var> and <var>splice end timestamp</var>.</li>
            <li>Let <var>fade in samples</var> be the samples generated by decoding <var>fade in coded frames</var>.</li>
            <li>If <var>fade out samples</var> and <var>fade in samples</var> do not have a common sample rate and channel layout, then convert
              <var>fade out samples</var> and <var>fade in samples</var> to a common sample rate and channel layout.</li>
            <li>Let <var>output samples</var> be a buffer to hold the output samples.</li>
            <li>Apply a linear gain fade out with a starting gain of 1 and an ending gain of 0 to the samples between
              <var>splice timestamp</var> and <var>splice end timestamp</var> in <var>fade out samples</var>.</li>
            <li>Apply a linear gain fade in with a starting gain of 0 and an ending gain of 1 to the samples between <var>splice timestamp</var> and
              <var>splice end timestamp</var> in <var>fade in samples</var>.</li>
            <li>Copy samples between <var>presentation timestamp</var> to <var>splice timestamp</var> from <var>fade out samples</var> into <var>output samples</var>.</li>
            <li>For each sample between <var>splice timestamp</var> and <var>splice end timestamp</var>, compute the sum of a sample from <var>fade out samples</var> and the
              corresponding sample in <var>fade in samples</var> and store the result in <var>output samples</var>.</li>
            <li>Copy samples between <var>splice end timestamp</var> to <var>end timestamp</var> from <var>fade in samples</var> into <var>output samples</var>.</li>
            <li>Render <var>output samples</var>.</li>
          </ol>
          <div class="note">
            <p>Here is a graphical representation of this algorithm.</p>
            <img src="audio_splice.png" alt="Audio splice diagram">
          </div>
        </section>
        <section id="sourcebuffer-text-splice-frame-algorithm">
          <h4>Text Splice Frame Algorithm</h4>
          <p>Follow these steps when the <a def-id="coded-frame-processing-algorithm"></a> needs to generate a splice frame for two overlapping timed text
            <a def-id="coded-frames"></a>:</p>
          <ol>
            <li>Let <var>track buffer</var> be the <a def-id="track-buffer"></a> that will contain the splice.</li>
            <li>Let <var>new coded frame</var> be the new <a def-id="coded-frame"></a>, that is being added to <var>track buffer</var>, which triggered the need for a splice.</li>
            <li>Let <var>presentation timestamp</var> be the <a def-id="presentation-timestamp"></a> for <var>new coded frame</var></li>
            <li>Let <var>decode timestamp</var> be the decode timestamp for <var>new coded frame</var>.</li>
            <li>Let <var>frame duration</var> be the <a def-id="coded-frame-duration"></a> of <var>new coded frame</var>.</li>
            <li>Let <var>frame end timestamp</var> equal the sum of <var>presentation timestamp</var> and <var>frame duration</var>.</li>
            <li>Let <var>first overlapped frame</var> be the <a def-id="coded-frame"></a> in <var>track buffer</var> with a <a def-id="presentation-interval"></a> that contains <var>presentation timestamp</var>.
            </li>
            <li>Let <var>overlapped presentation timestamp</var> be the <a def-id="presentation-timestamp"></a> of the <var>first overlapped frame</var>.</li>
            <li>Let <var>overlapped frames</var> equal <var>first overlapped frame</var> as well as any additional frames in <var>track buffer</var> that
              have a <a def-id="presentation-timestamp"></a> greater than <var>presentation timestamp</var> and less than <var>frame end timestamp</var>.</li>
            <li>Remove all the frames included in <var>overlapped frames</var> from <var>track buffer</var>.
            <li>Update the <a def-id="coded-frame-duration"></a> of the <var>first overlapped frame</var> to <var>presentation timestamp</var> - <var>overlapped presentation timestamp</var>.</li>
            <li>Add <var>first overlapped frame</var> to the <var>track buffer</var>.
            <li>Return to caller without providing a splice frame.
              <p class="note">This is intended to allow <var>new coded frame</var> to be added to the <var>track buffer</var> as if
                it hadn't overlapped any frames in <var>track buffer</var> to begin with.</p>
            </li>
          </ol>
        </section>
      </section>
    </section>

    <section id="sourcebufferlist">
      <h2>SourceBufferList Object</h2>
      <p>SourceBufferList is a simple container object for <a>SourceBuffer</a> objects. It provides read-only array access and fires events when the list is modified.</p>

      <dl title="interface SourceBufferList : EventTarget" class="idl">
        <dt>readonly attribute unsigned long length</dt>
        <dd>
          <p>Indicates the number of <a>SourceBuffer</a> objects in the list.</p>
        </dd>
        <dt>getter SourceBuffer (unsigned long index)</dt>
        <dd>
          <p>Allows the SourceBuffer objects in the list to be accessed with an array operator (i.e. []).</p>

          <ol class="method-algorithm">
            <li>If <var>index</var> is greater than or equal to the <a def-id="length"></a> attribute then return undefined and abort these steps.</li>
            <li>Return the <var>index</var>'th <a>SourceBuffer</a> object in the list.</li>
          </ol>
        </dd>
      </dl>

      <section id="sourcebufferlist-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">addsourcebuffer</a></td>
              <td><code>Event</code></td>
              <td>When a <a>SourceBuffer</a> is added to the list.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">removesourcebuffer</a></td>
              <td><code>Event</code></td>
              <td>When a <a>SourceBuffer</a> is removed from the list.</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>

    <section id="videoplaybackquality">
      <h2>VideoPlaybackQuality Object</h2>
      <dl title="interface VideoPlaybackQuality" class="idl">
        <dt>readonly attribute DOMHighResTimeStamp creationTime</dt>
        <dd>
          <p>The timestamp returned by <a def-id="performance-now"></a> when this object was created.</p>
        </dd>

        <dt>readonly attribute unsigned long totalVideoFrames</dt>
        <dd>
          <p>The total number of frames that would have been displayed if no frames are dropped.</p>
        </dd>

        <dt>readonly attribute unsigned long droppedVideoFrames</dt>
        <dd>
          <p>The total number of frames dropped predecode or dropped because the frame missed
            its display deadline.</p>
        </dd>

        <dt>readonly attribute unsigned long corruptedVideoFrames</dt>
        <dd>
          <p>The total number of corrupted frames that have been detected.</p>
        </dd>

        <dt>readonly attribute double totalFrameDelay</dt>
        <dd>
          <p>The sum of all <a def-id="displayed-frame-delays"></a> for all displayed frames. (i.e., Frames included in the <a def-id="totalVideoFrames"></a> count, but not in the <a def-id="droppedVideoFrames"></a>
            count.</p>
        </dd>
      </dl>
    </section>

    <section id="trackdefault">
      <h2>TrackDefault Object</h2>
      <p>The TrackDefault object is used to provide kind, label, and language information for tracks that do not
        contain this information in the <a def-id="init-segments"></a>. This information is only consulted
        when the <a def-id="init-segment-received-algorithm"></a> creates track objects.</p>

      <dl title="enum TrackDefaultType" class="idl">
        <dt>audio</dt>
        <dd>
          Indicates that the information in the <a>TrackDefault</a> object should only be used when
          creating <a>AudioTrack</a> objects.
        </dd>
        <dt>video</dt>
        <dd>
          Indicates that the information in the  <a>TrackDefault</a> object should only be used when
          creating <a>VideoTrack</a> objects.
        </dd>
        <dt>text</dt>
        <dd>
          Indicates that the  information in the <a>TrackDefault</a> object should only be used when
          creating <a>TextTrack</a> objects.
        </dd>
      </dl>

      <dl title="interface TrackDefault" class="idl">
        <dt class="extended-attribute">
          Constructor(TrackDefaultType type, DOMString language, DOMString label, sequence&lt;DOMString&gt; kinds, optional DOMString byteStreamTrackID = "")
        </dt>
        <dd>
          <ol class="method-algorithm">
            <li>If <var>language</var> is not an empty string and <var>language</var> is not a BCP 47
              language tag, then throw an <a def-id="invalid-access-err"></a> and abort these steps.</li>
            <li>
              <dl class="switch">
                <dt>If <var>type</var> equals <a def-id="TrackDefaultType-audio"></a>:</dt>
                <dd>
                  If any string in <var>kinds</var> contains a value that is not listed as applying to
                  audio in the <a def-id="av-kind-categories-table"></a>, then throw an
                  <a def-id="invalid-access-err"></a> and abort these steps.
                </dd>
                <dt>If <var>type</var> equals <a def-id="TrackDefaultType-video"></a>:</dt>
                <dd>
                  If any string in <var>kinds</var> contains a value that is not listed as applying to
                  video in the <a def-id="av-kind-categories-table"></a>, then throw an
                  <a def-id="invalid-access-err"></a> and abort these steps.
                </dd>

                <dt>If <var>type</var> equals <a def-id="TrackDefaultType-text"></a>:</dt>
                <dd>
                  If any string in <var>kinds</var> contains a value that is not listed in the
                  <a def-id="text-track-kind-list"></a>, then throw an <a def-id="invalid-access-err"></a>
                  and abort these steps.
                </dd>
              </dl>
            </li>
            <li>Set the <a def-id="TrackDefault-type"></a> attribute on this new object to <var>type</var>.</li>
            <li>Set the <a def-id="TrackDefault-language"></a> attribute on this new object to <var>language</var>.</li>
            <li>Set the <a def-id="TrackDefault-label"></a> attribute on this new object to <var>label</var>.</li>
            <li>Set the <a def-id="TrackDefault-kinds"></a> attribute to on this new object <var>kinds</var>.</li>
            <li>Set the <a def-id="TrackDefault-byteStreamTrackID"></a> attribute on this new object to <var>byteStreamTrackID</var>.</li>
          </ol>
        </dd>
        <dt>readonly attribute TrackDefaultType type</dt>
        <dd>
          <p>The type of track that can be constructed using the information in this object.</p>
        </dd>
        <dt>readonly attribute DOMString byteStreamTrackID</dt>
        <dd>
          <p>The decimal string representation of the <a def-id="track-id"></a> that identifies the specific
            track that this object should apply to. An empty string indicates that this object can be
            used for any track of the appropriate type. (i.e. any <a>AudioTrack</a> if
            <a def-id="TrackDefault-type"></a> equals <a def-id="TrackDefaultType-audio"></a>).</p>
        </dd>
        <dt>readonly attribute DOMString language</dt>
        <dd>
          <p>The default language to use when an <a def-id="init-segment"></a> does not contain language
          information for a new track. See <a def-id="init-segment-received-algorithm"></a> for details.</p>
        </dd>
        <dt>readonly attribute DOMString label</dt>
        <dd>
          <p>The default label to use when an <a def-id="init-segment"></a> does not contain label
          information for a new track. See <a def-id="init-segment-received-algorithm"></a> for details.</p>
        </dd>
        <dt>readonly attribute DOMString[] kinds</dt>
        <dd>
          <p>The default kinds used when an <a def-id="init-segment"></a> does not contain kind
          information for a new track. See <a def-id="init-segment-received-algorithm"></a> for details.</p>
        </dd>
      </dl>
    </section>

    <section id="trackdefaultlist">
      <h2>TrackDefaultList Object</h2>
      <p>TrackDefaultList is a simple container object for <a>TrackDefault</a> objects. It provides read-only array access.</p>

      <dl title="interface TrackDefaultList" class="idl">
        <dt class="extended-attribute">
          Constructor(sequence&lt;TrackDefault&gt; trackDefaults)
        </dt>
        <dd>
          <ol class="method-algorithm">
            <li>If <var>trackDefaults</var> contains two or more <a>TrackDefault</a> objects with
              the same <a def-id="TrackDefault-type"></a> and the same
              <a def-id="TrackDefault-byteStreamTrackID"></a>, then throw an
              <a def-id="invalid-access-err"></a> and abort these steps.
              <p class="note">This also applies when <a def-id="TrackDefault-byteStreamTrackID"></a> contains
                an empty string and ensures that there is only one "byteStreamTrackID independent" default
                for each <a>TrackDefaultType</a> value.</p></li>
            <li>Store a copy of <var>trackDefaults</var> in this new object so the values can be returned
              by the accessor methods.</li>
          </ol>
        </dd>
        <dt>readonly attribute unsigned long length</dt>
        <dd>
          <p>Indicates the number of <a>TrackDefault</a> objects in the list.</p>
        </dd>
        <dt>getter TrackDefault (unsigned long index)</dt>
        <dd>
          <p>Allows the TrackDefault objects in the list to be accessed with an array operator (i.e. []).</p>

          <ol class="method-algorithm">
            <li>If <var>index</var> is greater than or equal to the <a def-id="length"></a> attribute then return undefined and abort these steps.</li>
            <li>Return the <var>index</var>'th <a>TrackDefault</a> object in the list.</li>
          </ol>
        </dd>
      </dl>
    </section>

    <section id="url">
      <h2>URL Object Extensions</h2>
      <p>This section specifies extensions to the <a def-id="URL"></a>[[!FILE-API]] object definition.</p>

      <dl title="partial interface URL" class="idl">
        <dt>static DOMString createObjectURL(MediaSource mediaSource)</dt>
        <dd>
          <p>Creates URLs for <a>MediaSource</a> objects.</p>

          <ol class="method-algorithm">
            <li>Return a unique <a def-id="MediaSource-object-URL"></a> that can be used to dereference the <var>mediaSource</var> argument, and run the rest of the algorithm asynchronously.</li>
            <li><a def-id="provide-a-stable-state"></a></li>
            <li>Revoke the <a def-id="MediaSource-object-URL"></a> by calling <a def-id="file-revokeObjectURL"></a> on it.</li>
          </ol>
          <p class="note">This algorithm is intended to mirror the behavior of the <a def-id="file-createObjectURL"></a>[[!FILE-API]] method with autoRevoke set to true.</p>
        </dd>
      </dl>
    </section>

    <section id="htmlmediaelement-extensions">
      <h2>HTMLMediaElement Extensions</h2>
      <p>This section specifies what existing attributes on the <a def-id="htmlmediaelement"></a> must return when a <a>MediaSource</a> is attached to the element.</p>

      <p>The <a def-id="videoref" name="dom-media-seekable">HTMLMediaElement.seekable</a> attribute returns a new static <a def-id="normalized-timeranges-object"></a> created based on the following steps:</p>
      <dl class="switch">
        <dt>If <a def-id="duration"></a> equals NaN:</dt>
        <dd>Return an empty <a def-id="timeranges"></a> object.</dd>
        <dt>If <a def-id="duration"></a> equals positive Infinity:</dt>
        <dd>
          <ol>
            <li>If the <a def-id="hme-buffered"></a> attribute returns an empty <a def-id="timeranges"></a>
              object, then return an empty <a def-id="timeranges"></a> object and abort these steps.</li>
            <li>Return a single range with a start time of 0 and an end time equal to the highest end time reported by the <a def-id="hme-buffered"></a> attribute.
        </ol></dd>
        <dt>Otherwise:</dt>
        <dd>Return a single range with a start time of 0 and an end time equal to <a def-id="duration"></a>.</dd>
      </dl>

      <p id="dom-htmlmediaelement.buffered">The <a def-id="hme-buffered"></a> attribute returns a new static <a def-id="normalized-timeranges-object"></a> created based on the following steps:</p>
      <ol>
        <li>If <a def-id="activeSourceBuffers"></a>.length equals 0 then return an empty <a def-id="timeranges"></a> object and abort these steps.</li>
        <li>Let <var>active ranges</var> be the ranges returned by <a def-id="buffered"></a> for each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a>.</li>
        <li>Let <var>highest end time</var> be the largest range end time in the <var>active ranges</var>.</li>
        <li>Let <var>intersection ranges</var> equal a <a def-id="timerange"></a> object containing a single range from 0 to <var>highest end time</var>.</li>
        <li>For each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a> run the following steps:
          <ol>
            <li>Let <var>source ranges</var> equal the ranges returned by the <a def-id="buffered"></a> attribute on the current <a>SourceBuffer</a>.</li>
            <li>If <a def-id="readyState"></a> is <a def-id="ended"></a>, then set the end time on the last range in <var>source ranges</var> to
              <var>highest end time</var>.</li>
            <li>Let <var>new intersection ranges</var> equal the intersection between the <var>intersection ranges</var> and the <var>source ranges</var>.</li>
            <li>Replace the ranges in <var>intersection ranges</var> with the <var>new intersection ranges</var>.</li>
          </ol>
        </li>
        <li>Return the <var>intersection ranges</var>.</li>
      </ol>
    </section>

    <section id="htmlvideoelement-extensions">
      <h2>HTMLVideoElement Extensions</h2>
      <p>This section specifies new attributes and internal state that are being added to the <a def-id="htmlvideoelement"></a>.</p>

      <p>Each <a def-id="htmlvideoelement"></a> will maintain a <dfn id="total-video-frame-count">total video frame count</dfn> variable that keeps
        track of the total number of frames that have been displayed and dropped. This variable is initialized to 0 when the
        element is created and whenever the <a def-id="media-element-load-algorithm"></a> is invoked. It is incremented when a video frame is displayed
        or when the <a def-id="dropped-video-frame-count"></a> is incremented.</p>

      <p>Each <a def-id="htmlvideoelement"></a> will maintain a <dfn id="dropped-video-frame-count">dropped video frame count</dfn> variable that keeps
        track of the total number of frames that have been dropped. This variable is initialized to 0 when the
        element is created and whenever the <a def-id="media-element-load-algorithm"></a> is invoked. It is incremented when a video frame is dropped
        predecode or when a frame is decoded but dropped because it missed a display deadline.</p>

      <p>Each <a def-id="htmlvideoelement"></a> will maintain a <dfn id="corrupted-video-frame-count">corrupted video frame count</dfn> variable that keeps
        track of the total number of corrupted frames detected. This variable is initialized to 0 when the element is created and whenever the
        <a def-id="media-element-load-algorithm"></a> is invoked. It is incremented when a corrupted video frame is detected by the decoder. It is up to
        the implementation to determine whether to display or drop a corrupted frame. Whichever choice is made, the <a def-id="total-video-frame-count"></a>
        and <a def-id="dropped-video-frame-count"></a> must be updated appropriately.
      </p>

      <p>Each <a def-id="htmlvideoelement"></a> will maintain a <dfn id="displayed-frame-delay-sum">displayed frame delay sum</dfn> variable that keeps
        track of the sum of all <a def-id="displayed-frame-delays"></a>. This variable is initialized to 0 when the element is created and whenever the
        <a def-id="media-element-load-algorithm"></a> is invoked. When a frame is displayed, its <a def-id="displayed-frame-delay"></a> is computed and added
        to this variable.
      </p>

      <dl title="partial interface HTMLVideoElement" class="idl">
        <dt>VideoPlaybackQuality getVideoPlaybackQuality()</dt>
        <dd>
          <p>Provides the current the playback quality metrics.</p>
          <ol class="method-algorithm">
            <li>Let <var>playbackQuality</var> be a new instance of <a>VideoPlaybackQuality</a>.</li>
            <li>Set <var>playbackQuality</var>.<a def-id="creationTime"></a> to the value returned by a call to <a def-id="performance-now"></a>.</li>
            <li>Set <var>playbackQuality</var>.<a def-id="totalVideoFrames"></a> to the current value of the <a def-id="total-video-frame-count"></a>.</li>
            <li>Set <var>playbackQuality</var>.<a def-id="droppedVideoFrames"></a> to the current value of the <a def-id="dropped-video-frame-count"></a>.</li>
            <li>Set <var>playbackQuality</var>.<a def-id="corruptedVideoFrames"></a> to the current value of the <a def-id="corrupted-video-frame-count"></a>.</li>
            <li>Set <var>playbackQuality</var>.<a def-id="totalFrameDelay"></a> to the current value of the <a def-id="displayed-frame-delay-sum"></a>.</li>
            <li>Return <var>playbackQuality</var>.</li>
          </ol>
        </dd>
      </dl>
    </section>

    <section id="audio-track-extensions">
      <h2>AudioTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="audio-track"></a> definition.</p>

      <dl title="partial interface AudioTrack" class="idl">
        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
      </dl>
    </section>

    <section id="video-track-extensions">
      <h2>VideoTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="video-track"></a> definition.</p>

      <dl title="partial interface VideoTrack" class="idl">
        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
      </dl>
    </section>

    <section id="text-track-extensions">
      <h2>TextTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="text-track"></a> definition.</p>

      <dl title="partial interface TextTrack" class="idl">
        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
      </dl>
    </section>

    <section id="byte-stream-formats">
      <h2>Byte Stream Formats</h2>
      <p>The bytes provided through <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a> for a <a>SourceBuffer</a> form a logical byte stream. The format and
        semantics of these byte streams are defined in <dfn id="byte-stream-format-specs">byte stream format specifications</dfn>. 
        The byte stream format registry [[MSE-REGISTRY]] provides mappings between a MIME type that may be passed to <a def-id="addSourceBuffer"></a> or
        <a def-id="isTypeSupported"></a> and the byte stream format expected by a <a>SourceBuffer</a> created with that MIME type. Implementations are encouraged to register
        mappings for byte stream formats they support to facilitate interoperability. The byte stream format registry [[MSE-REGISTRY]] is the authoritative source for these
        mappings. If an implementation claims to support a MIME type listed in the registry, its <a>SourceBuffer</a> implementation must conform to the
        <a def-id="byte-stream-format-spec"></a> listed in the registry entry.</p>
      <p class="note">The byte stream format specifications in the registry are not intended to define new storage formats. They simply outline the subset of
        existing storage format structures that implementations of this specification will accept.</p>
      <p class="note">Byte stream format parsing and validation is implemented in the <a def-id="segment-parser-loop"></a> algorithm.</p>

      <p>This section provides general requirements for all byte stream format specifications:</p>
      <ul>
        <li>A byte stream format specification must define <a def-id="init-segments"></a> and <a def-id="media-segments"></a>.</li>
        <li>It must be possible to identify segment boundaries and segment type (initialization or media) by examining the byte stream alone.</li>
        <li>The user agent must run the <a def-id="eos-decode"></a> when any of the following conditions are met:
          <ol>
            <li>
              <p>The number and type of tracks are not consistent.</p>
              <p class="note">For example, if the first <a def-id="init-segment"></a> has 2 audio tracks and 1 video track, then all <a def-id="init-segments"></a> that follow it in the byte stream must describe 2 audio tracks and 1 video track.</p>
            </li>
            <li><a def-id="track-ids"></a> are not the same across <a def-id="init-segments"></a>, for segments describing multiple tracks of a single type. (e.g. 2 audio tracks).</li>
	    <li>
              <p>Codecs changes across <a def-id="init-segments"></a>.</p>
              <p class="note">For example, a byte stream that starts with an <a def-id="init-segment"></a> that specifies a single AAC track and later contains an <a def-id="init-segment"></a> that specifies a single AMR-WB track is not allowed. Support for multiple codecs is handled with multiple <a>SourceBuffer</a> objects.</p>
            </li>
          </ol>
        </li>
        <li>The user agent must support the following:
          <ol>
            <li><a def-id="track-ids"></a> changing across <a def-id="init-segments"></a> if the segments describes only one track of each type.</li>
	    <li>
              <p>Video frame size changes. The user agent must support seamless playback.</p>
              <p class="note">This will cause the &lt;video&gt; display region to change size if the web application does not use CSS or HTML attributes (width/height) to constrain the element size.</p>
            </li>
	    <li>
              <p>Audio channel count changes. The user agent may support this seamlessly and could trigger downmixing.</p>
              <p class="note">This is a quality of implementation issue because changing the channel count may require reinitializing the audio device, resamplers, and channel mixers which tends to be audible.</p>
            </li>
          </ol>
        </li>
        <li>The following rules apply to all <a def-id="media-segments"></a> within a byte stream. A user agent must:
          <ol>
            <li>Map all timestamps to the same <a def-id="media-timeline"></a>.</li>
            <li>Support seamless playback of <a def-id="media-segments"></a> having a timestamp gap smaller than the audio frame size. User agent must not reflect these gaps in the <a def-id="buffered"></a> attribute.
	      <p class="note">This is intended to simplify switching between audio streams where the frame boundaries don't always line up across encodings (e.g. Vorbis).</p>
            </li>
          </ol>
        </li>
        <li>The user agent must run the <a def-id="eos-decode"></a> when any combination of an <a def-id="init-segment"></a> and any contiguous sequence of <a def-id="media-segments"></a> satisfies the
          following conditions:
	  <ol>
            <li>The number and type (audio, video, text, etc.) of all tracks in the <a def-id="media-segments"></a> are not identified.</li>
            <li>The decoding capabilities needed to decode each track (i.e. codec and codec parameters) are not provided.</li>
            <li>Encryption parameters necessary to decrypt the content (except the encryption key itself) are not provided for all encrypted tracks.</li>
            <li>All information necessary to decode and render the earliest <a def-id="random-access-point"></a> in the sequence of <a def-id="media-segments"></a> and all subsequence samples in the sequence
              (in presentation time) are not provided. This includes in particular,
	      <ul>
	        <li>Information that determines the <a def-id="intrinsic-width-and-height"></a> of the video (specifically, this requires either the picture or pixel aspect ratio, together with the encoded
                  resolution).</li>
	        <li>Information necessary to convert the video decoder output to a format suitable for display</li>
	      </ul>
	    </li>
	    <li>Information necessary to compute the global <a def-id="presentation-timestamp"></a> of every sample in the sequence of <a def-id="media-segments"></a> is not provided.</li>
	  </ol>
	  <p>For example, if I1 is associated with M1, M2, M3 then the above must hold for all the combinations I1+M1, I1+M2, I1+M1+M2, I1+M2+M3, etc.</p>
        </li>
      </ul>
      <p>Byte stream specifications must at a minimum define constraints which ensure that the above requirements hold. Additional constraints may be defined, for example to simplify implementation.</p>

    </section>

    <section id="examples">
      <h2>Examples</h2>
      <p>Example use of the Media Source Extensions</p>
      <div class="block">
        <div class="blockContent">
          <pre class="code">
&lt;script&gt;
  function onSourceOpen(videoTag, e) {
    var mediaSource = e.target;

    if (mediaSource.sourceBuffers.length > 0)
        return;

    var sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vorbis,vp8"');

    videoTag.addEventListener('seeking', onSeeking.bind(videoTag, mediaSource));
    videoTag.addEventListener('progress', onProgress.bind(videoTag, mediaSource));

    var initSegment = GetInitializationSegment();

    if (initSegment == null) {
      // Error fetching the initialization segment. Signal end of stream with an error.
      mediaSource.endOfStream("network");
      return;
    }

    // Append the initialization segment.
    var firstAppendHandler = function(e) {
      var sourceBuffer = e.target;
      sourceBuffer.removeEventListener('updateend', firstAppendHandler);

      // Append some initial media data.
      appendNextMediaSegment(mediaSource);
    };
    sourceBuffer.addEventListener('updateend', firstAppendHandler);
    sourceBuffer.appendBuffer(initSegment);
  }

  function appendNextMediaSegment(mediaSource) {
    if (mediaSource.readyState == "closed")
      return;

    // If we have run out of stream data, then signal end of stream.
    if (!HaveMoreMediaSegments()) {
      mediaSource.endOfStream();
      return;
    }

    // Make sure the previous append is not still pending.
    if (mediaSource.sourceBuffers[0].updating)
        return;

    var mediaSegment = GetNextMediaSegment();

    if (!mediaSegment) {
      // Error fetching the next media segment.
      mediaSource.endOfStream("network");
      return;
    }

    // NOTE: If mediaSource.readyState == âendedâ, this appendBuffer() call will
    // cause mediaSource.readyState to transition to "open". The web application
    // should be prepared to handle multiple âsourceopenâ events.
    mediaSource.sourceBuffers[0].appendBuffer(mediaSegment);
  }

  function onSeeking(mediaSource, e) {
    var video = e.target;

    if (mediaSource.readyState == "open") {
      // Abort current segment append.
      mediaSource.sourceBuffers[0].abort();
    }

    // Notify the media segment loading code to start fetching data at the
    // new playback position.
    SeekToMediaSegmentAt(video.currentTime);

    // Append a media segment from the new playback position.
    appendNextMediaSegment(mediaSource);
  }

  function onProgress(mediaSource, e) {
    appendNextMediaSegment(mediaSource);
  }
&lt;/script&gt;

&lt;video id="v" autoplay&gt; &lt;/video&gt;

&lt;script&gt;
  var video = document.getElementById('v');
  var mediaSource = new MediaSource();
  mediaSource.addEventListener('sourceopen', onSourceOpen.bind(this, video));
  video.src = window.URL.createObjectURL(mediaSource);
&lt;/script&gt;
          </pre>
        </div>
      </div>
    </section>

    <section id="acknowledgements">
      <h2>Acknowledgments</h2>
      The editors would like to thank <a def-id="contributors"></a> for their contributions to this specification.
    </section>

    <section id="revision-history">
      <h2>Revision History</h2>
      <table class="old-table">
        <thead>
          <tr>
            <th>Version</th>
            <th>Comment</th>
          </tr>
        </thead>
        <tbody>
        <tbody>
          <tr>
            <td>11 November 2014</td>
            <td>
              <ul>
                <li>Bug 27296 - Clarify .seekable when duration is Infinity and .buffered is empty.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/af052af0dd5f/media-source/media-source.html">04 November 2014</a></td>
            <td>
              <ul>
                <li>Bug 27241 - Fixed step 1 of the TrackDefault constructor so it doesn't always throw an exception.</li>
                <li>Bug 27240 - Make TrackDefaultList contructor throw an exception on any duplicate (type, byteStreamTrackID) pair.</li>
                <li>Bug 27174 - Added SourceBuffer configuration definition to clarify addSourceBuffer() behavior.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/567b8e0764f8/media-source/media-source.html">06 October 2014</a></td>
            <td>
              <ul>
                <li>Bug 26924 - Run default language algorithm if 'und' BCP 47 value is present in the init segment.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/567b8e0764f8/media-source/media-source.html">29 September 2014</a></td>
            <td>
              <ul>
                <li>Bug 26932 - Fix TrackDefault constructor kinds parameter type.</li>
                <li>Update to ReSpec 3.2.20.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/df74aa427173/media-source/media-source.html">10 September 2014</a></td>
            <td>
              <ul>
                <li>Bug 26777 - Rename 'first initialization segment flag' to 'first initialization segment received flag'.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/9066cfb5ad1d/media-source/media-source.html">09 September 2014</a></td>
            <td>
              <ul>
                <li>Bug 26721 - Add label attribute to TrackDefault object.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/856c321c7a6b/media-source/media-source.html">12 August 2014</a></td>
            <td>
              <ul>
                <li>Bug 26436 - Use HTMLMediaElement.buffered for HTMLMediaElement.readyState transitions instead of individual SourceBuffer.buffered attributes.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/c63fe313d13a/media-source/media-source.html">24 July 2014</a></td>
            <td>
              <ul>
                <li>Bug 26345 - Make activeSourceBuffers order match sourceBuffers order.</li>
                <li>Bug 26316 - Changed duration change algorithm to avoid open transition on endOfStream().</li>
                <li>Bug 26314 - Fixed coded frame removal algorithm to remove dependencies that may lie outside the removal range.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/9b4db0f089bf/media-source/media-source.html">20 June 2014</a></td>
            <td>
              <ul>
                <li>Bug 26032 - Set need random access point flag on all track buffers when a new init
                  segment is received.</li>
                <li>Bug 25845 - Clarify SourceBuffer.buffered getter behavior.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/a38529a7910d/media-source/media-source.html">13 June 2014</a></td>
            <td>
              <ul>
                <li>Bug 25995 - Fix conditions in "remove existing coded frames" step.</li>
                <li>Bug 25999 - Change appendWindowStart assignments to reference presentation start time.</li>
                <li>Bug 26000 - Make it explicit that SourceBuffer.remove() throws an exception if duration equals NaN.</li>
                <li>Bug 25846 - Update end of stream algorithm to invoke the append error algorithm on decode errors.</li>
                <li>Bug 25850 - Specify SourceBuffer.trackDefaults initial value and setter/getter behavior.</li>
                <li>Bug 25998 - Move presentation & decode timestamp checks after append window filtering steps.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/01c9e30d71b0/media-source/media-source.html">21 May 2014</a></td>
            <td>
              <ul>
                <li>Bug 24370 - Add TrackDefault object and remove kind/language overloads.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/3e8dfccbfded/media-source/media-source.html">20 May 2014</a></td>
            <td>
              <ul>
                <li>Bug 25518 - Make remove() end parameter an unrestricted double.</li>
                <li>Bug 25580 - Add informative reference to byte stream format registry.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/29f17705b5c2/media-source/media-source.html">29 April 2014</a></td>
            <td>
              <ul>
                <li>Bug 25347 - Remove unnecessary null & invalid enum value checks.</li>
                <li>Bug 25505 - Introduce "generate timestamps flag" to handle MPEG audio timestamp
                  generation.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/d471a4412040/media-source/media-source.html">01 April 2014</a></td>
            <td>
              <ul>
                <li>Bug 25157 - Fix typo in coded frame duration example.</li>
                <li>Bug 24854 - Moved negative timestamp checking to allow "sequence" mode to handle
                  appending coded frames in reverse order</li>
                <li>Bug 24820 - Renamed highest presentation end timestamp to group end timestamp and
                  fixed a few related issues.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/cad94fce3b90/media-source/media-source.html">03 March 2014</a></td>
            <td>
              <ul>
                <li>Bug 24347 - Fix HAVE_FUTURE_DATA transition condition in SourceBuffer monitoring algorithm.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/d8ad50e85da3/media-source/media-source.html">10 December 2013</a></td>
            <td>
              <ul>
                <li>Bug 23169 - Restore totalFrameDelay units to seconds.</li>
                <li>Bug 23989 - Update blob URL origin text to remove stale File API reference.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/7c96c97306ce/media-source/media-source.html">02 December 2013</a></td>
            <td>
              <ul>
                <li>Bug 23818 - Make external spec references normative.</li>
                <li>Bug 23441 - Update byte stream format registry text.</li>
                <li>Bug 23169 - Update totalFrameDelay text.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/306bb395f94e/media-source/media-source.html">14 November 2013</a></td>
            <td>
              <ul>
                <li>Bug 23663 - Clarify seeking behavior in Section 2.4.3.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/47e74f565722/media-source/media-source.html">04 November 2013</a></td>
            <td>
              <ul>
                <li>Bug 23441 - Established MSE byte stream format registry and extracted byte stream format text into separate documents.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/15e7e8f7eecd/media-source/media-source.html">29 October 2013</a></td>
            <td>
              <ul>
                <li>Bug 23553 - Fixed segment parser loop so it doesn't appear to prematurely remove the media segment header.</li>
                <li>Bug 23557 - Update SPS/PPS note to not explicitly recommend specific avc versions.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/bed8606bd0a7/media-source/media-source.html">28 October 2013</a></td>
            <td>
              <ul>
                <li>Bug 23549 - Add definitions for decode timestamp, presentation timestamp, an presentation order.</li>
                <li>Bug 23552 - Clarify 'this' in section 3.5.1</li>
                <li>Bug 23554 - Introduced presentation interval and coded frame duration terms to clarify text.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/3fda61eb902f/media-source/media-source.html">15 October 2013</a></td>
            <td>
              <ul>
                <li>Bug 23525 - Fix mvex box error behavior.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/56e209741937/media-source/media-source.html">04 October 2013</a></td>
            <td>
              <ul>
                <li>Bug 23442 - Fix example to work when seeking in the 'ended' state.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/9035359fe231/media-source/media-source.html">26 July 2013</a></td>
            <td>
              <ul>
                <li>Bug 22136 - Added text for Inband SPS/PPS support.</li>
                <li>Bug 22776 - Clarified that implementations are only required to support one SourceBuffer configuration at a time.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/2b2d8865de83/media-source/media-source.html">18 July 2013</a></td>
            <td>
              <ul>
                <li>Bug 22117 - Reword byte stream specs in terms of UA behavior.</li>
                <li>Bug 22148 - Replace VideoPlaybackQuality.playbackJitter with VideoPlaybackQuality.totalFrameDelay.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/b98190a4472c/media-source/media-source.html">02 July 2013</a></td>
            <td>
              <ul>
                <li>Bug 22401 - Fix typo</li>
                <li>Bug 22134 - Clarify byte stream format enforcement.</li>
                <li>Bug 22431 - Convert videoPlaybackQuality attribute to getVideoPlaybackQuality() method.</li>
                <li>Bug 22109 - Renamed 'coded frame sequence' to 'coded frame group' to avoid confusion around multiple 'sequence' concepts.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/63675668846c/media-source/media-source.html">05 June 2013</a></td>
            <td>
              <ul>
                <li>Bug 22139 - Added a note clarifying that byte stream specs aren't defining new storage formats.</li>
                <li>Bug 22148 - Added playbackJitter metric.</li>
                <li>Bug 22134 - Added minimal number of SourceBuffers requirements.</li>
                <li>Bug 22115 - Make algorithm abort text consistent.</li>
                <li>Bug 22113 - Address typos.</li>
                <li>Bug 22065 - Fix infinite loop in coded frame processing algorithm.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/1ac9c2205a7b/media-source/media-source.html">01 June 2013</a></td>
            <td>
              <ul>
                <li>Bug 21431 - Updated coded frame processing algorithm for text splicing.</li>
                <li>Bug 22035 - Update addtrack and removetrack event firing text to match HTML5 language.</li>
                <li>Bug 22111 - Remove useless playback sentence from end of stream algorithm.</li>
                <li>Bug 22052 - Add corrupted frame metric.</li>
                <li>Bug 22062 - Added links for filing bugs.</li>
                <li>Bug 22125 - Add "ended" to "open" transition to remove().</li>
                <li>Bug 22143 - Move HTMLMediaElement.playbackQuality to HTMLVideoElement.videoPlaybackQuality.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/71968956733e/media-source/media-source.html">13 May 2013</a></td>
            <td>
              <ul>
                <li>Bug 21954 - Add [EnforceRange] to appendStream's maxSize parameter.</li>
                <li>Bug 21953 - Add NaN handling to appendWindowEnd setter algorithm.</li>
                <li>Alphabetize definitions section.</li>
                <li>Changed endOfStream('decode') references to make it clear that JavaScript can't intercept these calls.</li>
                <li>Fix links for all types in the IDL that are defined in external specifications.</li>
              </ul>
            </td>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/9ff5e42736b6/media-source/media-source.html">06 May 2013</a></td>
            <td>
              <ul>
                <li>Bug 20901 - Remove AbortMode and add AppendMode.</li>
                <li>Bug 21911 - Change MediaPlaybackQuality.creationTime to DOMHighResTimeStamp.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/b60bf8077d9c/media-source/media-source.html">02 May 2013</a></td>
            <td>
              <ul>
                <li>Reworked ambiguous text in a variety of places.</li>
                <li>Added Acknowledgements section.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/ffb76048861e/media-source/media-source.html">30 April 2013</a></td>
            <td>
              <ul>
                <li>Bug 21822 - Fix 'fire ... event ... at the X attribute' text.</li>
                <li>Bug 21819 &amp; 21328 - Remove 'compressed' from coded frame definition.</li>
              </ul>
            </td>
          </tr>
          <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/237133bfdd57/media-source/media-source.html">24 April 2013</a></td>
            <td>
              <ul>
                <li>Bug 21796 - Removed issue box from 'Append Error' algorithm.</li>
                <li>Bug 21703 - Changed appendWindowEnd to 'unrestricted double'.</li>
                <li>Bug 20760 - Adding MediaPlaybackQuality object.</li>
                <li>Bug 21536 - Specify the origin of media data appended.</li>
              </ul>
            </td>
          </tr>
          <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/f7f2b7226543/media-source/media-source.html">08 April 2013</a></td>
            <td>
              <ul>
                <li>Bug 21327 - Crossfade clarifications.</li>
                <li>Bug 21334 - Clarified seeking behavoir.</li>
                <li>Bug 21326 - Add a note stating some implementations may choose to add fades to/from silence.</li>
                <li>Bug 21375 - Clarified decode dependency removal.</li>
                <li>Bug 21376 - Replace 100ms limit with 2x last frame duration limit.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/rev/1e6898152c5b">26 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21301 - Change timeline references to "media timeline" links.</li>
                <li>Bug 19676 - Clarified "fade out coded frames" definition.</li>
                <li>Bug 21276 - Convert a few append error scenarios to endOfStream('decode') errors.</li>
                <li>Bug 21376 - Changed 'time' to 'decode time' to append sequence definition.</li>
                <li>Bug 21374 - Clarify the abort() behavior.</li>
                <li>Bug 21373 - Clarified incremental parsing text in segment parser loop.</li>
                <li>Bug 21364 - Remove redundant condition from remove overlapped frame step.</li>
                <li>Bug 21327 - Clarify what to do with a splice that starts with an audio frame with a duration less than 5ms.</li>
                <li>Update to ReSpec 3.1.48</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/f0fb58d45f96/media-source/media-source.html">12 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21112 - Add appendWindowStart & appendWindowEnd attributes.</li>
                <li>Bug 19676 - Clarify overlapped frame definitions and splice logic.</li>
                <li>Bug 21172 - Added coded frame removal and eviction algorithms.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/dcd406812201/media-source/media-source.html">05 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21170 - Remove 'stream aborted' step from stream append loop algorithm.</li>
                <li>Bug 21171 - Added informative note about when addSourceBuffer() might throw an QUOTA_EXCEEDED_ERR exception.</li>
                <li>Bug 20901 - Add support for 'continuation' and 'timestampOffset' abort modes.</li>
                <li>Bug 21159 - Rename appendArrayBuffer to appendBuffer() and add ArrayBufferView overload.</li>
                <li>Bug 21198 - Remove redundant 'closed' readyState checks.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/668a1c82fb88/media-source/media-source.html">25 February 2013</a></td>
            <td>
              <ul>
                 <li>Remove Source Buffer Model section since all the behavior is covered by the algorithms now.</li>
                 <li>Bug 20899 - Remove media segments must start with a random access point requirement.</li>
                 <li>Bug 21065 - Update example code to use updating attribute instead of old appending attribute.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/d5956e93b991/media-source/media-source.html">19 February 2013</a></td>
            <td>
              <ul>
                 <li>Bug 19676, 20327 - Provide more detail for audio & video splicing.</li>
                 <li>Bug 20900 - Remove complete access unit constraint.</li>
                 <li>Bug 20948 - Setting timestampOffset in 'ended' triggers a transition to 'open'</li>
                 <li>Bug 20952 - Added update event.</li>
                 <li>Bug 20953 - Move end of append event firing out of segment parser loop.</li>
                 <li>Bug 21034 - Add steps to fire addtrack and removetrack events.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/77975abeec41/media-source/media-source.html">05 February 2013</a></td>
            <td>
              <ul>
                <li>Bug 19676 - Added a note clarifying that the internal timestamp representation doesn't have to be a double.</li>
                <li>Added steps to the coded frame processing algorithm to remove old frames when new ones overlap them.</li>
                <li>Fix isTypeSupported() return type.</li>
                <li>Bug 18933 - Clarify what top-level boxes to ignore for ISO-BMFF.</li>
                <li>Bug 18400 - Add a check to avoid creating huge hidden gaps when out-of-order appends occur w/o calling abort().</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/b35722b0cd8f/media-source/media-source.html">31 January 2013</a></td>
            <td>
              <ul>
                <li>Make remove() asynchronous.</li>
                <li>Added steps to various algorithms to throw an INVALID_STATE_ERR exception when async appends or remove() are pending.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/aae26333e7d1/media-source/media-source.html">30 January 2013</a></td>
            <td>
              <ul>
                <li>Remove early abort step on 0-byte appends so the same events fire as a normal append with bytes.</li>
                <li>Added definition for 'enough data to ensure uninterrupted playback'.</li>
                <li>Updated buffered ranges algorithm to properly compute the ranges for Philip's example.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/fd2a58eec443/media-source/media-source.html">15 January 2013</a></td>
            <td>Replace setTrackInfo() and getSourceBuffer() with AudioTrack, VideoTrack, and TextTrack extensions.</td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/52a85235137b/media-source/media-source.html">04 January 2013</a></td>
            <td>
              <ul>
                <li>Renamed append() to appendArrayBuffer() and made appending asynchronous.</li>
                <li>Added SourceBuffer.appendStream().</li>
                <li>Added SourceBuffer.setTrackInfo() methods.</li>
                <li>Added issue boxes to relevant sections for outstanding bugs.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/53ea7c19edd2/media-source/media-source.html">14 December 2012</a></td>
            <td>
              Pubrules, Link Checker, and Markup Validation fixes.
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/e1c91093dfdc/media-source/media-source.html">13 December 2012</a></td>
            <td>
              <ul>
                <li>Added MPEG-2 Transport Stream section.</li>
                <li>Added text to require abort() for out-of-order appends.</li>
                <li>Renamed "track buffer" to "decoder buffer".</li>
                <li>Redefined "track buffer" to mean the per-track buffers that hold the SourceBuffer media data.</li>
                <li>Editorial fixes.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/ee6e8ae9337c/media-source/media-source.html">08 December 2012</a></td>
            <td>
              <ul>
                <li>Added MediaSource.getSourceBuffer() methods.</li>
                <li>Section 2 cleanup.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/43be42e69533/media-source/media-source.html">06 December 2012</a></td>
            <td>
              <ul>
                <li>append() now throws a QUOTA_EXCEEDED_ERR when the SourceBuffer is full.</li>
                <li>Added unique ID generation text to Initialization Segment Received algorithm.</li>
                <li>Remove 2.x subsections that are already covered by algorithm text.</li>
                <li>Rework byte stream format text so it doesn't imply that the MediaSource implementation must support all formats supported by the
                  HTMLMediaElement.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/0c638da9a67a/media-source/media-source.html">28 November 2012</a></td>
            <td>
              <ul>
                <li>Added transition to HAVE_METADATA when current playback position is removed.</li>
                <li>Added remove() calls to duration change algorithm.</li>
                <li>Added MediaSource.isTypeSupported() method.</li>
                <li>Remove initialization segments are optional text.</li>
              </ul>
            </td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/3e4d27b3a98f/media-source/media-source.html">09 November 2012</a></td>
            <td>Converted document to ReSpec.</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/e029f71aafca/media-source/media-source.html">18 October 2012</a></td>
            <td>Refactored SourceBuffer.append() &amp; added SourceBuffer.remove().</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/6d127e69c9f8/media-source/media-source.html">8 October 2012</a></td>
            <td>
	      <ul>
	        <li>Defined what HTMLMediaElement.seekable and HTMLMediaElement.buffered should return.</li>
	        <li>Updated seeking algorithm to run inside Step 10 of the HTMLMediaElement seeking algorithm.</li>
	        <li>Removed transition from "ended" to "open" in the seeking algorithm.</li>
	        <li>Clarified all the event targets.</li>
	      </ul>
	    </td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/7bab66368f2c/media-source/media-source.html">1 October 2012</a></td>
            <td>Fixed various addsourcebuffer &amp; removesourcebuffer bugs and allow append() in ended state.</td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/349559debcc3/media-source/media-source.html">13 September 2012</a></td>
            <td>Updated endOfStream() behavior to change based on the value of HTMLMediaElement.readyState.</td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/ca093bbbbefb/media-source/media-source.html">24 August 2012</a></td>
            <td>
	      <ul>
	        <li>Added early abort on to duration change algorithm.</li>
	        <li>Added createObjectURL() IDL &amp; algorithm.</li>
                <li>Added Track ID &amp; Track description definitions.</li>
                <li>Rewrote start overlap for audio frames text.</li>
                <li>Removed rendering silence requirement from section 2.5.</li>
	      </ul>
	    </td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/340786fcae83/media-source/media-source.html">22 August 2012</a></td>
            <td>
	      <ul>
	        <li>Clarified WebM byte stream requirements.</li>
	        <li>Clarified SourceBuffer.buffered return value.</li>
	        <li>Clarified addsourcebuffer &amp; removesourcebuffer event targets.</li>
	        <li>Clarified when media source attaches to the HTMLMediaElement.</li>
	        <li>Introduced duration change algorithm and update relevant algorithms to use it.</li>
	      </ul>
	    </td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/032f7b8681d1/media-source/media-source.html">17 August 2012</a></td>
            <td>Minor editorial fixes.</td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/29687c019735/media-source/media-source.html">09 August 2012</a></td>
            <td>Change presentation start time to always be 0 instead of using format specific rules about the first media segment appended.</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/087ea42f59c8/media-source/media-source.html">30 July 2012</a></td>
            <td>Added SourceBuffer.timestampOffset and MediaSource.duration.</td>
          </tr>
          <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/ab36e8e882c6/media-source/media-source.html">17 July 2012</a></td>
            <td>Replaced SourceBufferList.remove() with MediaSource.removeSourceBuffer().</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/b499a199e427/media-source/media-source.html">02 July 2012</a></td>
            <td>Converted to the object-oriented API</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/9bbfe09653e4/media-source/media-source.html">26 June 2012</a></td>
            <td>Converted to Editor's draft.</td>
          </tr>
	  <tr>
	    <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/e433598d22a7/media-source/media-source.html">0.5</a></td>
            <td>Minor updates before proposing to W3C HTML-WG.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.4/draft-spec/mediasource-draft-spec.html">0.4</a></td>
            <td>Major revision. Adding source IDs, defining buffer model, and clarifying byte stream formats.</td>
          </tr>
	  <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.3/draft-spec/mediasource-draft-spec.html">0.3</a></td>
            <td>Minor text updates.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.2/draft-spec/mediasource-draft-spec.html">0.2</a></td>
            <td>Updates to reflect initial WebKit implementation.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.1/draft-spec/mediasource-draft-spec.html">0.1</a></td>
            <td>Initial Proposal</td>
          </tr>
        </tbody>
      </table>
    </section>
  </body>
</html>
