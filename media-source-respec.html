<!DOCTYPE html SYSTEM "about:legacy-compat">
<html>
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>Media Source Extensions</title>
    <script src="respec-w3c-common.js" class="remove"></script>
    <script src="media-source.js" class="remove"></script>
    <script class="remove">
      var respecConfig = {
      // specification status (e.g. WD, LCWD, NOTE, etc.). If in doubt use ED.
      specStatus: "ED",

      // the specification's short name, as in http://www.w3.org/TR/short-name/
      shortName: "media-source",

      // if there a publicly available Editor's Draft, this is the link
      edDraftURI:           "http://dvcs.w3.org/hg/html-media/raw-file/default/media-source/media-source.html",

      // if this is a LCWD, uncomment and set the end of its review period
      // lcEnd: "2009-08-05",

      // editors, add as many as you like
      // only "name" is required
      editors:  [
      { name: "Aaron Colwell",  url: "",
      company: "Google Inc.", companyURL: "http://www.google.com/" },
      { name: "Adrian Bateman", url: "",
      company: "Microsoft Corporation", companyURL: "http://www.microsoft.com/" },
      { name: "Mark Watson", url: "",
      company: "Netflix Inc.", companyURL: "http://www.netflix.com/" },
      ],

      // name of the WG
      wg:           "HTML Working Group",

      // URI of the public WG page
      wgURI:        "http://www.w3.org/html/wg/",

      // name (without the @w3c.org) of the public mailing to which comments are due
      wgPublicList: "public-html-media",

      // URI of the patent status for this WG, for Rec-track documents
      // !!!! IMPORTANT !!!!
      // This is important for Rec-track documents, do not copy a patent URI from a random
      // document unless you know what you're doing. If in doubt ask your friendly neighbourhood
      // Team Contact.
      wgPatentURI: "http://www.w3.org/2004/01/pp-impl/40318/status",

      noIDLIn: true,

      scheme: "https",

      preProcess: [ mediaSourcePreProcessor ],

      // Empty definitions for MediaSource, SourceBuffer, and AbortMode are here to
      // prevent error messages from being displayed for references to these objects.
      definitionMap: {
          MediaSource: function() {},
          SourceBuffer: function() {},
          AbortMode: function() {},
          MediaPlaybackQuality: function() {},
      },
      postProcess: [ mediaSourcePostProcessor ]
      };
    </script>

    <style type="text/css">
      .nonnormative { color: green; margin: 2em 0 2em 0em; padding: 0.5em 1em; border: none; background: #DDFFDD; }
      .nonnormative h3 { color: inherit; background: inherit; }
      .nonnormative:before { display: table; margin: -1em -0.5em -0.5em auto; width: auto; content: 'This section is non-normative.'; color: black; font-style: italic; border: solid 2px; background: white; padding: 0 0.25em; }

      .iso-box { font-weight: bold; }
      .iso-var { font-style: italic; }

      table.old-table { border-collapse: collapse; border-style: hidden hidden none hidden; }
      table.old-table thead, table tbody { border-bottom: solid; }
      table.old-table tbody th:first-child { border-left: solid; }
      table.old-table tbody th { text-align: left; }
      table.old-table td, table th { border-left: solid; border-right: solid; border-bottom: solid thin; vertical-align: top; padding: 0.2em; }

      dl.switch { padding-left: 2em; }
      dl.switch > dt { text-indent: -1.5em; }
      dl.switch > dt:before { content: '\21AA'; padding: 0 0.5em 0 0; display: inline-block; width: 1em; text-align: right; line-height: 0.5em; }

      p + * > li, dd li { margin: 1em 0; }

      @media screen { code :link, code :visited { color: inherit; } }
    </style>
  </head>
  <body>
    
    <section id="sotd">
        <p>The working groups maintains <a href="http://w3.org/brief/Mjcw">a list of all bug reports that the editors have not yet tried to address</a>. This draft highlights some of the pending issues that are still to be discussed in the working group. No decision has been taken on the outcome of these issues including whether they are valid.</p>
        <p>Implementors should be aware that this specification is not stable. <strong>Implementors who are not taking part in the discussions are likely to find the specification changing out from under them in incompatible ways.</strong> Vendors interested in implementing this specification before it eventually reaches the Candidate Recommendation stage should join the mailing list mentioned below and take part in the discussions.</p>
    </section>

    <section id="abstract">
      This specification extends HTMLMediaElement to allow 
      JavaScript to generate media streams for playback. 
      Allowing JavaScript to generate streams facilitates a variety of use 
      cases like adaptive streaming and time shifting live streams.
    </section>


    <section id="introduction">
      <h2>Introduction</h2>
      <p>This specification allows JavaScript to dynamically construct media streams for &lt;audio&gt; and &lt;video&gt;. 
        It defines objects that allow JavaScript to pass media segments to an <a def-id="videoref" name="htmlmediaelement">HTMLMediaElement</a>.
        A buffering model is also included to describe how the user agent should act when different media segments are 
        appended at different times. Byte stream specifications for WebM, ISO Base Media File Format, and MPEG-2 Transport Streams are given to specify the
        expected format of byte streams used with these extensions.</p>
      <img src="pipeline_model.png" alt="Media Source Pipeline Model Diagram">

      <section id="goals">
        <h3>Goals</h3>
        <p>This specification was designed with the following goals in mind:</p>
        <ul>
          <li>Allow JavaScript to construct media streams independent of how the media is fetched.</li>
          <li>Define a splicing and buffering model that facilitates use cases like adaptive streaming, ad-insertion, time-shifting, and video editing.</li>
          <li>Minimize the need for media parsing in JavaScript.</li>
          <li>Leverage the browser cache as much as possible.</li>
          <li>Provide byte stream definitions for WebM, the ISO Base Media File Format, and MPEG-2 Transport Streams.</li>
          <li>Not require support for any particular media format or codec.</li>
        </ul>
      </section>

      <section id="definitions">
        <h3>Definitions</h3>

        <dl>
          <dt id="init-segment">Initialization Segment</dt>
          <dd>
	    <p>A sequence of bytes that contain all of the initialization information required to decode a sequence of <a def-id="media-segments"></a>. This includes codec initialization data, <a def-id="track-id"></a> mappings for multiplexed segments, and timestamp offsets (e.g. edit lists).</p>
            <p class="note">The <a def-id="byte-stream-format-specs"></a> contain format specific examples.</p>

          <dt id="media-segment">Media Segment</dt>
          <dd>
	    <p>A sequence of bytes that contain packetized &amp; timestamped media data for a portion of the <a def-id="media-timeline"></a>. Media segments are always associated with the most recently appended <a def-id="init-segment"></a>.</p>
            <p class="note">The <a def-id="byte-stream-format-specs"></a> contain format specific examples.</p>
          </dd>

          <dt id="random-access-point">Random Access Point</dt>
          <dd><p>A position in a <a def-id="media-segment"></a> where decoding and continuous playback can begin without relying on any previous data in the segment. For video this tends to be the location of I-frames. In the case of audio, most audio frames can be treated as a random access point. Since video tracks tend to have a more sparse distribution of random access points, the location of these points are usually considered the random access points for multiplexed streams.</p></dd>

          <dt id="presentation-start-time">Presentation Start Time</dt>
          <dd><p>The presentation start time is the earliest time point in the presentation and specifies the <a def-id="videoref" name="initial-playback-position">initial playback position</a> and <a def-id="videoref" name="earliest-possible-position">earliest possible position</a>. All presentations created using this specification have a presentation start time of 0.</dd>

          <dt id="mediasource-object-url">MediaSource object URL</dt>
          <dd>
            <p>A MediaSource object URL is a unique <a def-id="blob-uri"></a> [[FILE-API]] created by <a def-id="createObjectURL"></a>. It is used to attach a <a>MediaSource</a> object to an HTMLMediaElement.</p>
            <p>These URLs are the same as a <a def-id="blob-uri"></a>, except that anything in the definition of that feature that refers to <a def-id="File"></a> and <a def-id="Blob"></a> objects is hereby extended to also apply to <a>MediaSource</a> objects.</p>
            <p>The <a def-id="origin">origin</a> of the MediaSource object URL is specified by the <a def-id="blob-origin"></a> [[FILE-API]].</p>
            <p class="note">For example, the <a def-id="origin"></a> of the MediaSource object URL affects the way that the media element is <a href="http://www.w3.org/TR/html5/embedded-content-0.html#security-with-canvas-elements">consumed by canvas</a>.</p>
          </dd>

          <dt id="track-id">Track ID</dt>
          <dd><p>A Track ID is a byte stream format specific identifier that marks sections of the byte stream as being part of a specific track. The Track ID in a <a def-id="track-description"></a> identifies which sections of a <a def-id="media-segment"></a> belong to that track.</p></dd>

          <dt id="track-description">Track Description</dt>
          <dd><p>A byte stream format specific structure that provides the <a def-id="track-id"></a>, codec configuration, and other metadata for a single track. Each track description inside a single <a def-id="init-segment"></a> must have a unique <a def-id="track-id"></a>.</p></dd>

          <dt id="coded-frame">Coded Frame</dt>
          <dd><p>A unit of compressed media data that has a presentation timestamp and  decode timestamp. The presentation timestamp indicates when the frame should be rendered. The decode timestamp indicates when the frame needs to be decoded. If frames can be decoded out of order, then the decode timestamp must be present in the bytestream. If frames cannot be decoded out of order and a decode timestamp is not present in the bytestream, then the decode timestamp is equal to the presentation timestamp.</p></dd>

          <dt id="parent-media-source">Parent Media Source</dt>
          <dd><p>The parent media source of a <a>SourceBuffer</a> object is the <a>MediaSource</a> object that created it.</p></dd>

          <dt id="append-sequence">Append Sequence</dt>
          <dd><p>A series of <a def-id="appendBuffer"></a> or <a def-id="appendStream"></a> calls on a <a>SourceBuffer</a> without any intervening <a def-id="abort"></a> calls. The
            <a def-id="media-segments"></a> in an append sequence must be adjacent and monotonically increasing in decode time without any gaps. An
            <a def-id="abort"></a> call starts a new append sequence which allows <a def-id="media-segments"></a> to be appended in non-monotonically
            increasing order.</p>
          </dd>

          <dt id="append-window">Append Window</dt>
          <dd><p>A presentation timestamp range used to filter out <a def-id="coded-frames"></a> while appending. The append window represents a single
            continuous time range with a single start time and end time. Coded frames with presentation timestamps within this range are allowed to be appended
            to the <a>SourceBuffer</a> while coded frames outside this range are filtered out. The append window start and end times are controlled by
            the <a def-id="appendWindowStart"></a> and <a def-id="appendWindowEnd"></a> attributes respectively.</p></dd>

          <dt id="active-track-buffers">Active Track Buffers</dt>
          <dd><p>The <a def-id="track-buffers"></a> that provide <a def-id="coded-frames"></a> for the <a def-id="audiotrack-enabled"></a>
              <a def-id="audiotracks"></a>, the <a def-id="videotrack-selected"></a> <a def-id="videotracks"></a>, and the
              <a def-id="texttrack-showing"></a> or <a def-id="texttrack-hidden"></a> <a def-id="texttracks"></a>. All these tracks are associated with
            <a>SourceBuffer</a> objects in the <a def-id="activeSourceBuffers"></a> list.</p>
          </dd>
        </dl>
      </section>
    </section>

    <section id="mediasource">
      <h2>MediaSource Object</h2>
      <p>The MediaSource object represents a source of media data for an HTMLMediaElement. It keeps track of the <a def-id="readyState"></a> for this source as well as a list of <a>SourceBuffer</a> objects that can be used to add media data to the presentation. MediaSource objects are created by the web application and then attached to an HTMLMediaElement. The application uses the <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a> to add media data to this source. The HTMLMediaElement fetches this media data from the <a>MediaSource</a> object when it is needed during playback.</p>

      <dl title="enum ReadyState" class="idl">
        <dt>closed</dt>
        <dd>
          Indicates the source is not currently attached to a media element.
        </dd>
        <dt>open</dt>
        <dd>
          The source has been opened by a media element and is ready for data to be appended to the <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>.
        </dd>
        <dt>ended</dt>
        <dd>
          The source is still attached to a media element, but <a def-id="endOfStream"></a> has been called.
        </dd>
      </dl>

      <dl title="enum EndOfStreamError" class="idl">
        <dt>network</dt>
        <dd>
          <p>Terminates playback and signals that a network error has occured.</p>
          <p class="note">If the JavaScript fetching media data encounters a network error it should use this status code to terminate playback.</p>
        </dd>
        <dt>decode</dt>
        <dd>
          <p>Terminates playback and signals that a decoding error has occured.</p>
          <p class="note">If the JavaScript code fetching media data has problems parsing the data it should use this status code to terminate playback.</p>
        </dd>
      </dl>

      <dl title="[Constructor] interface MediaSource : EventTarget" class='idl'>
        <dt>readonly attribute SourceBufferList sourceBuffers</dt>
        <dd>
          Contains the list of <a>SourceBuffer</a> objects associated with this <a>MediaSource</a>. When <a def-id="readyState"></a> equals <a def-id="closed"></a> this list will be empty. Once <a def-id="readyState"></a> transitions to <a def-id="open"></a> SourceBuffer objects can be added to this list by using <a def-id="addSourceBuffer"></a>.
        </dd>

        <dt>readonly attribute SourceBufferList activeSourceBuffers</dt>
        <dd>
          <p>Contains the subset of <a def-id="sourceBuffers"></a> that are providing the 
            <a def-id="videoref" name="dom-videotrack-selected">selected video track</a>,  the 
            <a def-id="videoref" name="dom-audiotrack-enabled">enabled audio tracks</a>, and the 
            <a def-id="videoref" name="dom-texttrack-showing">"showing"</a> or <a def-id="videoref" name="dom-texttrack-hidden">"hidden"</a> text tracks.
          </p>
          <p class="note">The <a href="#active-source-buffer-changes">Changes to selected/enabled track state</a> section describes how this attribute gets
            updated.</p>
        </dd>

        <dt>readonly attribute ReadyState readyState</dt>
        <dd>
          <p>Indicates the current state of the <a>MediaSource</a> object. When the <a>MediaSource</a> is created <a def-id="readyState"></a> must be set to <a def-id="closed"></a>.
        </dd>

        <dt>attribute unrestricted double duration</dt>
        <dd>
          <p>Allows the web application to set the presentation duration. The duration is initially set to NaN when the <a>MediaSource</a> object is created.</p>
          <p>On getting, run the following steps:</p>
          <ol>
            <li>If the <a def-id="readyState"></a> attribute is <a def-id="closed"></a> then return NaN and abort these steps.</li>
            <li>Return the current value of the attribute.</li>
          </ol>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being set is negative or NaN then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="readyState"></a> attribute is not <a def-id="open"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true on any <a>SourceBuffer</a> in <a def-id="sourceBuffers"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the value being assigned to this attribute.
	      <p class="note"><a def-id="appendBuffer"></a>, <a def-id="appendStream"></a> and <a def-id="endOfStream"></a> can update the duration under certain circumstances.</p>
            </li>
          </ol>
        </dd>

        <dt>SourceBuffer addSourceBuffer(DOMString type)</dt>
        <dd>
          <p>Adds a new <a>SourceBuffer</a> to <a def-id="sourceBuffers"></a>.</p>

          <ol class="method-algorithm">
            <li>If <var>type</var> is null or an empty string then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>type</var> contains a MIME type that is not supported or contains a MIME type that is not supported with the types specified for the other <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>, then throw a <a def-id="not-supported-err"></a> exception and abort these steps.</li>
            <li>If the user agent can't handle any more SourceBuffer objects then throw a <a def-id="quota-exceeded-err"></a> exception and abort these steps.
              <p class="note">For example, a user agent may throw a <a def-id="quota-exceeded-err"></a> exception if the media element has reached the
                <a def-id="have-metadata"></a> readyState. This can occur if the user agent's media engine does not support adding more tracks during
                playback.
              </p>
            </li>
            <li>If the <a def-id="readyState"></a> attribute is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Create a new <a>SourceBuffer</a> object and associated resources.</li>
            <li>Add the new object to <a def-id="sourceBuffers"></a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="sourceBuffers"></a>.</li>
            <li>Return the new object.</li>
          </ol>
        </dd>

        <dt>void removeSourceBuffer(SourceBuffer sourceBuffer)</dt>
        <dd>
          <p>Removes a <a>SourceBuffer</a> from <a def-id="sourceBuffers"></a>.</p>

          <ol class="method-algorithm">
            <li>If <var>sourceBuffer</var> is null then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>sourceBuffer</var> specifies an object that is not in <a def-id="sourceBuffers"></a> then throw a <a def-id="not-found-err"></a> exception and abort these steps.</li>
            <li>If the <var>sourceBuffer</var>.<a def-id="updating"></a> attribute equals true, then run the following steps:
              <ol>
                <li>Abort the <a def-id="stream-append-loop"></a> algorithm if it is running.</li>
                <li>Set the <var>sourceBuffer</var>.<a def-id="updating"></a> attribute to false.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateabort"></a> at <var>sourceBuffer</var>.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at <var>sourceBuffer</var>.</li>
              </ol>
            </li>
            <li>Set the the sourceBuffer attribute in all tracks in <var>sourceBuffer</var>.<a def-id="sourcebuffer-audioTracks"></a>, <var>sourceBuffer</var>.<a def-id="sourcebuffer-videoTracks"></a>, and <var>sourceBuffer</var>.<a def-id="sourcebuffer-textTracks"></a> to null.</li>
            <li>Remove all the tracks in <var>sourceBuffer</var>.<a def-id="sourcebuffer-audioTracks"></a>, <var>sourceBuffer</var>.<a def-id="sourcebuffer-videoTracks"></a>, and <var>sourceBuffer</var>.<a def-id="sourcebuffer-textTracks"></a> from the respective <a def-id="audiotracks"></a>, <a def-id="videotracks"></a>, and <a def-id="texttracks"></a> attributes on the HTMLMediaElement.</li>
            <li>Remove all the tracks in <var>sourceBuffer</var>.<a def-id="sourcebuffer-audioTracks"></a>, <var>sourceBuffer</var>.<a def-id="sourcebuffer-videoTracks"></a>, and <var>sourceBuffer</var>.<a def-id="sourcebuffer-textTracks"></a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-removetrack"></a> at the modified lists.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-removetrack"></a> at the HTMLMediaElement track lists that were modified.</li>
            <li>If <var>sourceBuffer</var> is in <a def-id="activeSourceBuffers"></a>, then run the following steps:
              <ol>
                <li>Remove <var>sourceBuffer</var> from <a def-id="activeSourceBuffers"></a>.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>.</li>
                <li>If the <a def-id="videoref" name="dom-videotrack-selected">selected video track</a> was removed from the <a def-id="videotracks"></a> 
                  attribute on the HTMLMediaElement in a step above, then <a def-id="queue-a-task-to-fire-an-event-named"></a> 
                  <a def-id="tracklist-change"></a> at the <a def-id="videotracks"></a> attribute.</li>
                <li>If an <a def-id="videoref" name="dom-audiotrack-enabled">enabled audio track</a> was removed from the <a def-id="audiotracks"></a> 
                  attribute on the HTMLMediaElement in a step above, then <a def-id="queue-a-task-to-fire-an-event-named"></a> 
                  <a def-id="tracklist-change"></a> at the <a def-id="audiotracks"></a> attribute.</li>
                <li>If a <a def-id="text-track"></a> with its <a def-id="texttrack-mode"></a> attribute set to 
                  <a def-id="videoref" name="dom-texttrack-showing">"showing"</a> or <a def-id="videoref" name="dom-texttrack-hidden">"hidden"</a> 
                  was removed from the <a def-id="texttracks"></a> attribute on the HTMLMediaElement in a step above, then 
                  <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="texttracks"></a> attribute.</li>
              </ol>
            </li>
            <li>Remove <var>sourceBuffer</var> from <a def-id="sourceBuffers"></a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="sourceBuffers"></a>.</li>
            <li>Destroy all resources for <var>sourceBuffer</var>.</li>
          </ol>
        </dd>

        <dt>void endOfStream(optional EndOfStreamError error)</dt>
        <dd>
          <p>Signals the end of the stream.</p>

          <ol class="method-algorithm">
            <li>If the <a def-id="readyState"></a> attribute is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true on any <a>SourceBuffer</a> in <a def-id="sourceBuffers"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Change the <a def-id="readyState"></a> attribute value to <a def-id="ended"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceended"></a> at the <a>MediaSource</a>.</li>
            <li><dl class="switch">
                <dt>If <var>error</var> is not set, null, or an empty string</dt>
                <dd>
	          <ol>
	            <li>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the highest end timestamp across all <a>SourceBuffer</a> objects in <a def-id="sourceBuffers"></a>.<br>
		      <p class="note">This allows the duration to properly reflect the end of the appended media segments. For example, if the duration was explicitly set to 10 seconds and only media segments for 0 to 5 seconds were appended before endOfStream() was called, then the duration will get updated to 5 seconds.</p>
	            </li>
	            <li>Notify the media element that it now has all of the media data. Playback should continue until all the media passed in via <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a> has been played.</li>
	          </ol>
	        </dd>
                <dt>If <var>error</var> is set to <a def-id="network"></a>
                </dt>
                <dd>
	          <dl class="switch">
	            <dt>If the <a def-id="ready-state"></a> attribute equals <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the <a def-id="media-data-cannot-be-fetched"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	            <dt>If the <a def-id="ready-state"></a> attribute is greater than <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the "<i>If the connection is interrupted after some media data has been received, causing the user agent to give up trying to fetch the resource</i>" steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	          </dl>
	        </dd>
                <dt>If <var>error</var> is set to <a def-id="decode"></a>
                </dt>
                <dd>
	          <dl class="switch">
	            <dt>If the <a def-id="ready-state"></a> attribute equals <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the "<i>If the media data can be fetched but is found by inspection to be in an unsupported format, or can otherwise not be rendered at all</i>" steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	            <dt>If the <a def-id="ready-state"></a> attribute is greater than <a def-id="have-nothing"></a>
                    </dt>
	            <dd>Run the <a def-id="media-data-is-corrupted"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
	          </dl>
	        </dd>
                <dt>Otherwise</dt>
                <dd>Throw an <a def-id="invalid-access-err"></a> exception.</dd>
              </dl>
            </li>
          </ol>
        </dd>

        <dt>static boolean isTypeSupported(DOMString type)</dt>
        <dd>
          <p>Check to see whether the <a>MediaSource</a> is capable of creating <a>SourceBuffer</a> objects for the the specified MIME type.</p>

          <ol class="method-algorithm">
            <li>If <var>type</var> is an empty string, then return false.</li>
            <li>If <var>type</var> does not contain a valid MIME type string, then return false.</li>
            <li>If <var>type</var> contains a media type or media subtype that the MediaSource does not support, then return false.</li>
            <li>If <var>type</var> contains at a codec that the MediaSource does not support, then return false.</li>
            <li>If the MediaSource does not support the specified combination of media type, media subtype, and codecs then return false.</li>
            <li>Return true.</li>
          </ol>
          <p class="note">
            If true is returned from this method, it only indicates that the <a>MediaSource</a> implementation is capable of creating <a>SourceBuffer</a> objects for the specified MIME type. An <a def-id="addSourceBuffer"></a> call may still fail if sufficient resources are not available to support the addition of a new <a>SourceBuffer</a>.
          </p>
          <p class="note">
            This method returning true implies that HTMLMediaElement.canPlayType() will return "maybe" or "probably" since it does not make sense for a <a>MediaSource</a> to support a type the HTMLMediaElement knows it cannot play.
          </p>
        </dd>
      </dl>

      <section id="mediasource-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">sourceopen</a></td>
              <td><code>Event</code></td>
              <td><a def-id="readyState"></a> transitions from <a def-id="closed"></a> to <a def-id="open"></a> or from <a def-id="ended"></a> to <a def-id="open"></a>.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">sourceended</a></td>
              <td><code>Event</code></td>
              <td><a def-id="readyState"></a> transitions from <a def-id="open"></a> to <a def-id="ended"></a>.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">sourceclose</a></td>
              <td><code>Event</code></td>
	      <td><a def-id="readyState"></a> transitions from <a def-id="open"></a> to <a def-id="closed"></a> or <a def-id="ended"></a> to <a def-id="closed"></a>.</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section id="mediasource-algorithms">
        <h3>Algorithms</h3>

        <section id="mediasource-attach">
          <h4>Attaching to a media element</h4>
          <p> A <a>MediaSource</a> object can be attached to a media element by assigning a <a def-id="MediaSource-object-URL"></a> to the media element <a def-id="media-src"></a> attribute or the src attribute of a &lt;source&gt; inside a media element. A <a def-id="MediaSource-object-URL"></a> is created by passing a MediaSource object to <a def-id="createObjectURL"></a>.</p>
          <p>If the <a def-id="resource-fetch-algorithm"></a> absolute URL matches the MediaSource object URL, run the following steps right before the "Perform a potentially
            CORS-enabled fetch" step in the <a def-id="resource-fetch-algorithm"></a>.</p>

          <dl class="switch">
            <dt>If <a def-id="readyState"></a> is NOT set to <a def-id="closed"></a></dt>
            <dd>Run the <a def-id="media-data-cannot-be-fetched"></a> steps of the <a def-id="resource-fetch-algorithm"></a>.</dd>
            <dt>Otherwise</dt>
            <dd>
              <ol>
                <li>Set the <a def-id="readyState"></a> attribute to <a def-id="open"></a>.</li>
                <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a>MediaSource</a>.</li>
                <li>Allow the <a def-id="resource-fetch-algorithm"></a> to progress based on data passed in via <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a>.</li>
              </ol>
            </dd>
          </dl>
        </section>

        <section id="mediasource-detach">
          <h4>Detaching from a media element</h4>
          <p>The following steps are run in any case where the media element is going to transition to <a def-id="videoref" name="dom-media-network_empty">NETWORK_EMPTY</a> and <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="videoref" name="event-mediacontroller-emptied">emptied</a> at the media element. These steps should be run right before the transition.</p>
          <ol>
            <li>Set the <a def-id="readyState"></a> attribute to <a def-id="closed"></a>.</li>
            <li>Set the <a def-id="duration"></a> attribute to NaN.</li>
            <li>Remove all the <a>SourceBuffer</a> objects from <a def-id="activeSourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>.</li>
            <li>Remove all the <a>SourceBuffer</a> objects from <a def-id="sourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="sourceBuffers"></a>.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceclose"></a> at the <a>MediaSource</a>.</li>
          </ol>
        </section>

        <section id="mediasource-seeking">
          <h4>Seeking</h4>
          <p>Run the following steps as part of the "<i>Wait until the user agent has established whether or not the media data for the new playback position is available, and, if it is, until it has decoded enough data to play back that position"</i> step of the <a def-id="hme-seek-algorithm"></a>:</p>
          <ol>
            <li>The media element looks for <a def-id="media-segments"></a> containing the <var>new playback position</var> in each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a>.
              <dl class="switch">
	        <dt>If one or more of the objects in <a def-id="activeSourceBuffers"></a> is missing <a def-id="media-segments"></a> for the <var>new playback position</var>
                </dt>
	        <dd>
	          <ol>
	            <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	            <li>The media element waits for the necessary <a def-id="media-segments"></a> to be passed to <a def-id="appendBuffer"></a> or <a def-id="appendStream"></a>.
                      <p class="note">The web application can use <a def-id="buffered"></a> to determine what the media element needs to resume playback.</p>
                    </li>
	          </ol>
	        </dd>
	        <dt>Otherwise</dt>
	        <dd>Continue</dd>
              </dl>
            </li>
            <li>The media element resets all decoders and initializes each one with data from the appropriate <a def-id="init-segment"></a>.</li>
            <li>The media element feeds <a def-id="coded-frames"></a> from the <a def-id="active-track-buffers"></a> into the decoders starting with the
              closest <a def-id="random-access-point"></a> before the the <var>new playback position</var>.</li>
            <li>Resume the <a def-id="hme-seek-algorithm"></a> at the "<i>Await a stable state</i>" step.</li>
          </ol>
        </section>


        <section id="buffer-monitoring">
          <h4>SourceBuffer Monitoring</h4>
          <p>The following steps are periodically run during playback to make sure that all of the <a>SourceBuffer</a> objects in <a def-id="activeSourceBuffers"></a> have <a def-id="enough-data"></a>. Appending new segments and changes to <a def-id="activeSourceBuffers"></a> also cause these steps to run because they affect the conditions that trigger state transitions.</p>

          <p>Having <dfn id="enough-data">enough data to ensure uninterrupted playback</dfn> is an implementation specific condition where the user agent
          determines that it currently has enough data to play the presentation without stalling for a meaningful period of time. This condition is
          constantly evaluated to determine when to transition the media element into and out of the <a def-id="have-enough-data"></a> ready state.
          These transitions indicate when the user agent believes it has enough data buffered or it needs more data respectively.</p>

          <p class="note">An implementation may choose to use bytes buffered, time buffered, the append rate, or any other metric it sees fit to
            determine when it has enough data. The metrics used may change during playback so web applications should only rely on the value of
            <a def-id="ready-state"></a> to determine whether more data is needed or not.</p>

          <p class="note">When the media element needs more data, it should transition from <a def-id="have-enough-data"></a> to
            <a def-id="have-future-data"></a> early enough for a web application to be able to respond without causing an interruption in playback.
            For example, transitioning when the current playback position is 500ms before the end of the buffered data gives the application roughly
            500ms to append more data before playback stalls.</p>

          <dl class="switch">
            <dt>If <a def-id="buffered"></a> for all objects in <a def-id="activeSourceBuffers"></a> do not contain <a def-id="timeranges"></a> for the current playback position:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-metadata"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadedmetadata"></a> at the media element.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="buffered"></a> for all objects in <a def-id="activeSourceBuffers"></a> contain <a def-id="timeranges"></a> that include the current playback position and <a def-id="enough-data"></a>:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-enough-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplaythrough"></a> at the media element.</li>
	        <li>Playback may resume at this point if it was previously suspended by a transition to <a def-id="have-current-data"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="buffered"></a> for at least one object in <a def-id="activeSourceBuffers"></a> contains a <a def-id="timerange"></a> that includes the current playback position but not <a def-id="enough-data"></a>:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-future-data"></a>.</li>
	        <li>If the previous value of <a def-id="ready-state"></a> was less than <a def-id="have-future-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="canplay"></a> at the media element.</li>
	        <li>Playback may resume at this point if it was previously suspended by a transition to <a def-id="have-current-data"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
            <dt>If <a def-id="buffered"></a> for at least one object in <a def-id="activeSourceBuffers"></a> contains a <a def-id="timerange"></a> that ends at the current playback position and does not have a range covering the time immediately after the current position:</dt>
            <dd>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-current-data"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-current-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadeddata"></a> at the media element.</li>
	        <li>Playback is suspended at this point since the media element doesn't have enough data to advance the <a def-id="media-timeline"></a>.</li>
	        <li>Abort these steps.</li>
	      </ol>
            </dd>
          </dl>
        </section>

        <section id="active-source-buffer-changes">
          <h4>Changes to selected/enabled track state</h4>
          <p>During playback <a def-id="activeSourceBuffers"></a> needs to be updated if the <a def-id="videoref" name="dom-videotrack-selected">selected video track</a>, the <a def-id="videoref" name="dom-audiotrack-enabled">enabled audio tracks</a>, or a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> changes. When one or more of these changes occur the following steps need to be followed.</p>
          <dl class="switch">
            <dt>If the selected video track changes, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>If the <a>SourceBuffer</a> associated with the previously selected video track is not associated with any other enabled tracks, run the following steps:
  	          <ol>
	            <li>Remove the <a>SourceBuffer</a> from <a def-id="activeSourceBuffers"></a>.</li>
	            <li>
                      <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                    </li>
	          </ol>
	        </li>
	        <li>If the <a>SourceBuffer</a> associated with the newly selected video track is not already in <a def-id="activeSourceBuffers"></a>, run the following steps:
	          <ol>
	            <li>Add the <a>SourceBuffer</a> to <a def-id="activeSourceBuffers"></a>.</li>
	            <li>
                      <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                    </li>
	          </ol>
	        </li>
	      </ol>
            </dd>
            <dt>If an audio track becomes disabled and the <a>SourceBuffer</a> associated with this track is not associated with any other enabled or selected track, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>Remove the <a>SourceBuffer</a> associated with the audio track from <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If an audio track becomes enabled and the <a>SourceBuffer</a> associated with this track is not already in <a def-id="activeSourceBuffers"></a>, then run the following steps:
            </dt>
            <dd>
	      <ol>
	        <li>Add the <a>SourceBuffer</a> associated with the audio track to <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> becomes <a def-id="videoref" name="dom-texttrack-disabled">"disabled"</a> and the <a>SourceBuffer</a> associated with this track is not associated with any other enabled or selected track, then run the following steps:</dt>
            <dd>
	      <ol>
	        <li>Remove the <a>SourceBuffer</a> associated with the text track from <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="removesourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
            <dt>If a text track <a def-id="videoref" name="dom-texttrack-mode">mode</a> becomes <a def-id="videoref" name="dom-texttrack-showing">"showing"</a> or <a def-id="videoref" name="dom-texttrack-hidden">"hidden"</a> and the <a>SourceBuffer</a> associated with this track is not already in <a def-id="activeSourceBuffers"></a>, then run the following steps:
            </dt>
            <dd>
	      <ol>
	        <li>Add the <a>SourceBuffer</a> associated with the text track to <a def-id="activeSourceBuffers"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a>
                </li>
	      </ol>
            </dd>
          </dl>
        </section>

        <section id="duration-change-algorithm">
          <h4>Duration change</h4>
          <p>Follow these steps when <a def-id="duration"></a> needs to change to a <var>new duration</var>.</p>
          <ol>
            <li>If the current value of <a def-id="duration"></a> is equal to <var>new duration</var>, then abort these steps.</li>
            <li>Set <var>old duration</var> to the current value of <a def-id="duration"></a>.
            <li>Update <a def-id="duration"></a> to <var>new duration</var>.</li>
            <li>If the <var>new duration</var> is less than <var>old duration</var>, then call <code><a href="#widl-SourceBuffer-remove-void-double-start-double-end">remove</a>(<var>new duration</var>, <var>old duration</var>)</code> on all objects in <a def-id="sourceBuffers"></a>.
              <p class="note">This preserves audio frames that start before and end after the <a def-id="duration"></a>. The user agent must end playback at <a def-id="duration"></a> even if the audio frame extends beyond this time.</p>
            </li>

            <li>Update the <a def-id="hme-duration"></a> to <var>new duration</var> and run the <a def-id="hme-duration-change-algorithm"></a>.</li>
          </ol>
        </section>
      </section>
    </section>

    <section id="sourcebuffer">
      <h2>SourceBuffer Object</h2>


      <dl title="enum AbortMode" class="idl">
        <dt>continuation</dt>
        <dd>
          <p>The next <a def-id="append-sequence"></a> will be placed immediately after the <a def-id="append-sequence"></a> that was just aborted.</p>
        </dd>
        <dt>timestampOffset</dt>
        <dd>
          <p>The next <a def-id="append-sequence"></a> will be inserted at the presentation time specified by the <a def-id="timestampOffset"></a>
            attribute instead of the time computed from the <a def-id="timestampOffset"></a> attribute and coded frame timestamps.
          </p>
        </dd>
      </dl>
      <p class="note">
        These abort modes cause the <a def-id="timestampOffset"></a> attribute to get updated when the first <a def-id="coded-frame"></a> of the new
        <a def-id="append-sequence"></a> is appended. This allows the rest of the  <a def-id="coded-frames"></a> in the sequence to follow the normal
        presentation &amp; decode timestamp computation rules and provides a way for the application to observe what offset is being applied to these
        timestamps.
      </p>

      <dl title="interface SourceBuffer : EventTarget" class="idl">
        <dt>readonly attribute boolean updating</dt>
        <dd>
          <p>Indicates whether an <a def-id="appendBuffer"></a>, <a def-id="appendStream"></a>, or <a def-id="remove"></a> operation is still being
            processed.</p>
        </dd>

        <dt>readonly attribute TimeRanges buffered</dt>
        <dd>
          <p>Indicates what <a def-id="timeranges"></a> are buffered in the <a>SourceBuffer</a>.</p>
          <p>When the attribute is read the following steps must occur:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Return a new static <a def-id="normalized-timeranges-object"></a> for the <a def-id="media-segments"></a> buffered.</li>
          </ol>
        </dd>

        <dt>attribute double timestampOffset</dt>
        <dd>
          <p>Controls the offset applied to timestamps inside subsequent <a def-id="media-segments"></a> that are appended to this <a>SourceBuffer</a>. The <a def-id="timestampOffset"></a> is initially set to 0 which indicates that no offset is being applied.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a></li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a>.</li>
              </ol>
            </li>
            <li>If this object is waiting for the end of a <a def-id="media-segment"></a> to be appended, then throw an <a def-id="invalid-state-err"></a> and abort these steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>

        <dt>readonly attribute AudioTrackList audioTracks</dt>
        <dd>
          The list of <a def-id="audio-track"></a> objects created by this object.
        </dd>

        <dt>readonly attribute VideoTrackList videoTracks</dt>
        <dd>
          The list of <a def-id="video-track"></a> objects created by this object.
        </dd>

        <dt>readonly attribute TextTrackList textTracks</dt>
        <dd>
          The list of <a def-id="text-track"></a> objects created by this object.
        </dd>

        <dt>attribute double appendWindowStart</dt>
        <dd>
          <p>The presentation timestamp for the start of the <a def-id="append-window"></a>. This attribute is initially set to 0.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an
              <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the new value is less than 0 or greater than or equal to <a def-id="appendWindowEnd"></a> then throw an <a def-id="invalid-access-err"></a> exception
              and abort these steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>

        <dt>attribute unrestricted double appendWindowEnd</dt>
        <dd>
          <p>The presentation timestamp for the end of the <a def-id="append-window"></a>. This attribute is initially set to positive Infinity.</p>
          <p>On getting, Return the initial value or the last value that was successfully set.</p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a>, then throw an
              <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the new value is less than or equal to <a def-id="appendWindowStart"></a> then throw an <a def-id="invalid-access-err"></a> exception and abort these
              steps.</li>
            <li>Update the attribute to the new value.</li>
          </ol>
        </dd>

        <dt>void appendBuffer(ArrayBuffer data)</dt>
        <dd>
          <p>Appends the segment data in an ArrayBuffer to the source buffer.</p>
          <p>The steps for this method are the same as the ArrayBufferView version of <a def-id="appendBuffer"></a>.</p>
        </dd>

        <dt>void appendBuffer(ArrayBufferView data)</dt>
        <dd>
          <p>Appends the segment data in an ArrayBufferView to the source buffer.</p>

          <ol class="method-algorithm">
            <li>If <var>data</var> is null then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a>
                </li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a> .</li>
              </ol>
            </li>
            <li>Run the <a def-id="coded-frame-eviction-algorithm"></a>.</li>
            <li>
              <p>If the <a def-id="buffer-full-flag"></a> equals true, then throw a <a def-id="quota-exceeded-err"></a> exception and abort these step.</p>
              <p class="note">This is the signal that the implementation was unable to evict enough data to accomodate the append or the append is too big. The web
                application must use <a def-id="remove"></a> to explicitly free up space and/or reduce the size of the append.</p>
            </li>
            <li>Add <var>data</var> to the end of the <a def-id="input-buffer"></a>.</li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Asynchronously run the <a def-id="buffer-append"></a> algorithm.</li>
          </ol>
        </dd>

        <dt>void appendStream(Stream stream, optional unsigned long long maxSize)</dt>
        <dd>
          <p>Appends segment data to the source buffer from a <a def-id="Stream"></a>[[STREAMS-API]].</p>

          <ol class="method-algorithm">
            <li>If <var>stream</var> is null then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw
              an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these
              steps.</li>
            <li>
              <p>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is in the <a def-id="ended"></a> state then run
                the following steps:</p>
              <ol>
	        <li>Set the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> to <a def-id="open"></a></li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="sourceopen"></a> at the <a def-id="parent-media-source"></a> .</li>
              </ol>
            </li>
            <li>Run the <a def-id="coded-frame-eviction-algorithm"></a>.</li>
            <li>
              <p>If the <a def-id="buffer-full-flag"></a> equals true, then throw a <a def-id="quota-exceeded-err"></a> exception and abort these step.</p>
              <p class="note">This is the signal that the implementation was unable to evict enough data to accomodate the append or the append is too big. The web
                application must use <a def-id="remove"></a> to explicitly free up space and/or reduce the size of the append.</p>
            </li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Asynchronously run the <a def-id="stream-append-loop"></a> algorithm with <var>stream</var> and <var>maxSize</var>.</li>
          </ol>
        </dd>

        <dt>void abort(optional AbortMode mode)</dt>
        <dd>
          <p>Aborts the current segment and resets the segment parser.</p>

          <ol class="method-algorithm">
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If <var>mode</var> is set and does not equal null, an empty string, or a valid <a>AbortMode</a>, then throw an 
              <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="continuation-timestamp"></a> is unset, then run the following steps:
              <ol>
                <li>If <var>mode</var> equals <a def-id="AbortMode-continuation"></a> and the <a def-id="highest-presentation-end-timestamp"></a> is unset,
                  then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
                <li>If the <a def-id="highest-presentation-end-timestamp"></a> is set, then update the <a def-id="continuation-timestamp"></a> to
                  equal the <a def-id="highest-presentation-end-timestamp"></a>.</li>
              </ol>
            </li>
            <li>If the <a def-id="updating"></a> attribute equals true, then run the following steps:
              <ol>
                <li>Abort the <a def-id="segment-parser-loop"></a>, <a def-id="buffer-append"></a>, and <a def-id="stream-append-loop"></a> algorithms if
                  they are running.</li>
                <li>Set the <a def-id="updating"></a> attribute to false.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateabort"></a> at this <a>SourceBuffer</a> object.</li>
                <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
              </ol>
            </li>
            <li>Run the <a def-id="reset-parser-state-algorithm"></a>.</li>
            <li>
              <dl class="switch">
                <dt>If <var>mode</var> is not set, null, or an empty string:</dt>
                <dd>Unset the <a def-id="abort-mode"></a>.</dd>
                <dt>Otherwise:</dt>
                <dd>Update the <a def-id="abort-mode"></a> to equal <var>mode</var>.</dd>
              </dl>
            </li>
            <li>Set <a def-id="appendWindowStart"></a> to 0.</li>
            <li>Set <a def-id="appendWindowEnd"></a> to positive Infinity.</li>
          </ol>
        </dd>

        <dt>void remove(double start, double end)</dt>
        <dd>
          <p>Removes media for a specific time range.</p>

          <ol class="method-algorithm">
            <li>If <var>start</var> is negative or greater than <a def-id="duration"></a>, then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If <var>end</var> is less than or equal to <var>start</var>, then throw an <a def-id="invalid-access-err"></a> exception and abort these steps.</li>
            <li>If this object has been removed from the <a def-id="sourceBuffers"></a> attribute of the <a def-id="parent-media-source"></a> then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="updating"></a> attribute equals true, then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>If the <a def-id="readyState"></a> attribute of the <a def-id="parent-media-source"></a> is not in the <a def-id="open"></a> state then throw an <a def-id="invalid-state-err"></a> exception and abort these steps.</li>
            <li>Set the <a def-id="updating"></a> attribute to true.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updatestart"></a> at this <a>SourceBuffer</a> object.</li>
            <li>Return control to the caller and run the rest of the steps asynchronously.</li>
            <li>Run the <a def-id="coded-frame-removal-algorithm"></a> with <var>start</var> and <var>end</var> as the start and end of the removal range.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
       </ol>

        </dd>
      </dl>

      <section id="track-buffers">
        <h3>Track Buffers</h3>
        <p>A <dfn id="track-buffer">track buffer</dfn> stores the <a def-id="track-descriptions"></a> and <a def-id="coded-frames"></a> for an individual
          track. The track buffer is updated as <a def-id="init-segments"></a> and <a def-id="media-segments"></a> are appended to the 
          <a>SourceBuffer</a>.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="last-decode-timestamp">last decode timestamp</dfn> variable that stores
          the decode timestamp of the last <a def-id="coded-frame"></a> appended in the current <a def-id="append-sequence"></a>. The variable is initially
          unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="last-frame-duration">last frame duration</dfn> variable that stores
          the frame duration of the last <a def-id="coded-frame"></a> appended in the current <a def-id="append-sequence"></a>. The variable is initially
          unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="highest-presentation-timestamp">highest presentation timestamp</dfn> variable that stores
          the highest presentation timestamp encountered in a <a def-id="coded-frame"></a> appended in the current <a def-id="append-sequence"></a>.
          The variable is initially unset to indicate that no <a def-id="coded-frames"></a> have been appended yet.</p>

        <p>Each <a def-id="track-buffer"></a> has a <dfn id="need-RAP-flag">need random access point flag</dfn> variable that keeps track of whether
          the track buffer is waiting for a <a def-id="random-access-point"></a> <a def-id="coded-frame"></a>. The variable is initially set to true to
          indicate that <a def-id="random-access-point"></a> <a def-id="coded-frame"></a> is needed before anything can be added to the
          <a def-id="track-buffer"></a>.</p>
      </section>

      <section id="sourcebuffer-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">updatestart</a></td>
              <td><code>Event</code></td>
              <td><a def-id="updating"></a> transitions from false to true.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">update</a></td>
              <td><code>Event</code></td>
              <td>The append or remove has successfully completed. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">updateend</a></td>
              <td><code>Event</code></td>
              <td>The append or remove has ended.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">error</a></td>
              <td><code>Event</code></td>
              <td>An error occurred during the append. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">abort</a></td>
              <td><code>Event</code></td>
              <td>The append or remove was aborted by an <a def-id="abort"></a> call. <a def-id="updating"></a> transitions from true to false.</td>
            </tr>
          </tbody>
        </table>
      </section>

      <section id="sourcebuffer-algorithms">
        <h3>Algorithms</h3>

        <section id="sourcebuffer-segment-parser-loop">
          <h4>Segment Parser Loop</h4>
          <p>All SourceBuffer objects have an internal <dfn id="sourcebuffer-append-state">append state</dfn> variable that keeps track of the high-level segment parsing state. It is initially set to <a def-id="waiting-for-segment"></a> and can transition to the following states as data is appended.</p>
          <table class="old-table">
            <thead>
	      <tr>
                <th>Append state name</th>
                <th>Description</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td><dfn id="sourcebuffer-waiting-for-segment">WAITING_FOR_SEGMENT</dfn></td>
                <td>Waiting for the start of an <a def-id="init-segment"></a> or <a def-id="media-segment"></a> to be appended.</td>
              </tr>
              <tr>
                <td><dfn id="sourcebuffer-parsing-init-segment">PARSING_INIT_SEGMENT</dfn></td>
                <td>Currently parsing an <a def-id="init-segment"></a>.</td>
              </tr>
	      <tr>
	        <td><dfn id="sourcebuffer-parsing-media-segment">PARSING_MEDIA_SEGMENT</dfn></td>
                <td>Currently parsing a <a def-id="media-segment"></a>.</td>
              </tr>
            </tbody>
          </table>

          <p>The <dfn id="sourcebuffer-input-buffer">input buffer</dfn> is a byte buffer that is used to hold unparsed bytes across <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a> calls. The buffer is empty when the SourceBuffer object is created.</p>

          <p>The <dfn id="sourcebuffer-buffer-full-flag">buffer full flag</dfn> keeps track of whether <a def-id="appendBuffer"></a> or
            <a def-id="appendStream"></a> is allowed to accept more bytes. It is set to false when the SourceBuffer object is created and gets updated
            as data is appended and removed.</p>

          <p>The <dfn id="sourcebuffer-abort-mode">abort mode</dfn> variable keeps track of the <a>AbortMode</a> passed to the last <a def-id="abort"></a>
            call. It is unset when the SourceBuffer object is created and gets updated by <a def-id="abort"></a> and the
            <a def-id="coded-frame-processing-algorithm"></a>.
          </p>

          <p>The <dfn id="sourcebuffer-continuation-timestamp">continuation timestamp</dfn> variable keeps track of the start timestamp for the next
            <a def-id="append-sequence"></a> if <a def-id="abort"></a> is called with <a def-id="AbortMode-continuation"></a>.
            It is unset when the SourceBuffer object is created and gets updated by <a def-id="abort"></a> and the
            <a def-id="coded-frame-processing-algorithm"></a>.
          </p>

          <p>The <dfn id="sourcebuffer-highest-presentation-end-timestamp">highest presentation end timestamp</dfn> variable stores the highest presentation
            end timestamp encountered in the current <a def-id="append-sequence"></a>. It is unset when the SourceBuffer object is created and gets updated
            by the <a def-id="reset-parser-state-algorithm"></a> and the <a def-id="coded-frame-processing-algorithm"></a>.
          </p>

          <p>When this algorithm is invoked, run the following steps:</p>

          <ol>
            <li><i>Loop Top:</i> If the <a def-id="input-buffer"></a> is empty, then jump to the <i>need more data</i> step below.</li>
            <li>If the <a def-id="input-buffer"></a> starts with bytes that violate the <a def-id="byte-stream-format-specs"></a>, then call <a def-id="eos-decode"></a> and abort this algorithm.</li>
            <li>Remove any bytes that the <a def-id="byte-stream-format-specs"></a> say should be ignored from the start of the <a def-id="input-buffer"></a>.</li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="waiting-for-segment"></a>, then run the following steps:</p>
	      <ol>
	        <li>If the beginning of the <a def-id="input-buffer"></a> indicates the start of an <a def-id="init-segment"></a>, set the <a def-id="append-state"></a> to <a def-id="parsing-init-segment"></a>.</li>
	        <li>If the beginning of the <a def-id="input-buffer"></a> indicates the start of an <a def-id="media-segment"></a>, set <a def-id="append-state"></a> to <a def-id="parsing-media-segment"></a>.</li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="parsing-init-segment"></a>, then run the following steps:</p>
	      <ol>
	        <li>If the <a def-id="input-buffer"></a> does not contain a complete <a def-id="init-segment"></a> yet, then jump to the <i>need more data</i> step below.</li>
	        <li>Run the <a def-id="init-segment-received-algorithm"></a>.</li>
	        <li>Remove the <a def-id="init-segment"></a> bytes from the beginning of the <a def-id="input-buffer"></a>.</li>
	        <li>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a>, then run the following steps:</p>
	      <ol>
                <li>If the <a def-id="first-init-segment-flag"></a> is false, then call <a def-id="eos-decode"></a> and abort this algorithm.</li>
	        <li>
	          <p>If the <a def-id="input-buffer"></a> does not contain a complete <a def-id="media-segment"></a> header yet, then jump to the <i>need more data</i> step below.</p>
	        </li>
	        <li>If the <a def-id="input-buffer"></a> contains one or more complete <a def-id="coded-frames"></a>, then run the
                  <a def-id="coded-frame-processing-algorithm"></a>.
                  <p class="note">
                    The frequency at which the coded frame processing algorithm is run is implementation-specific. The coded frame processing algorithm may
                    be called when the input buffer contains the complete media segment or it may be called multiple times as complete coded frames are
                    added to the input buffer.
                  </p>
                </li>
	        <li>Remove the <a def-id="media-segment"></a> bytes from the beginning of the <a def-id="input-buffer"></a>.</li>
                <li>If this <a>SourceBuffer</a> is full and cannot accept more media data, then set the <a def-id="buffer-full-flag"></a> to true.</li>
	        <li>
	          <p>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</p>
	          <p class="note">Incremental parsers should only do this transition after the entire media segment has been received.</p>
	        </li>
	        <li>Jump to the <i>loop top</i> step above.</li>
	      </ol>
            </li>
            <li><i>Need more data:</i> Return control to the calling algorithm.</li>
          </ol>
        </section>

        <section id="sourcebuffer-reset-parser-state">
          <h4>Reset Parser State</h4>
          <p>When the parser state needs to be reset, run the following steps:</p>
          <ol>
            <li>If the <a def-id="append-state"></a> equals <a def-id="parsing-media-segment"></a> and the <a def-id="input-buffer"></a> contains some complete <a def-id="coded-frames"></a>, then run the <a def-id="coded-frame-processing-algorithm"></a> as if the media segment only contained these frames.</li>
            <li>Unset the <a def-id="last-decode-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Unset the <a def-id="last-frame-duration"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Unset the <a def-id="highest-presentation-timestamp"></a> on all <a def-id="track-buffers"></a>.</li>
            <li>Unset the <a def-id="highest-presentation-end-timestamp"></a>.</li>
            <li>Set the <a def-id="need-RAP-flag"></a> on all <a def-id="track-buffers"></a> to true.</li>
            <li>Remove all bytes from the <a def-id="input-buffer"></a>.</li>
            <li>Set <a def-id="append-state"></a> to <a def-id="waiting-for-segment"></a>.</li>
          </ol>
        </section>

        <section id="sourcebuffer-append-error">
          <h4>Append Error</h4>
          <p>When an error occurs during an append, run the following steps:</p>
          <ol>
            <li>Run the <a def-id="reset-parser-state-algorithm"></a>.</li>
            <li>Abort the <a def-id="stream-append-loop"></a> algorithm if it is running.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li>
              <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateerror"></a> at this <a>SourceBuffer</a> object.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section id="sourcebuffer-buffer-append">
          <h4>Buffer Append Algorithm</h4>
          <p>When <a def-id="appendBuffer"></a> is called, the following steps are run to process the appended data.</p>
          <ol>
            <li>Run the <a def-id="segment-parser-loop"></a> algorithm.</li>
            <li>If the <a def-id="segment-parser-loop"></a> algorithm in the previous step was aborted, then abort this algorithm.</li>
            <li>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section id="sourcebuffer-stream-append-loop">
          <h4>Stream Append Loop</h4>
          <p>When a <a def-id="Stream"></a> is passed to <a def-id="appendStream"></a>, the following steps are run to transfer data from the
            <a def-id="Stream"></a> to the <a>SourceBuffer</a>. This algorithm is initialized with the  <var>stream</var> and <var>maxSize</var> parameters
            from the <a def-id="appendStream"></a> call.
          </p>
          <ol>
            <li>If <var>maxSize</var> is set, then let <var>bytesLeft</var> equal <var>maxSize</var>.</li>
            <li><i>Loop Top: </i>If <var>maxSize</var> is set and <var>bytesLeft</var> equals 0, then jump to the <i>loop done</i> step below.</li>
            <li>If <var>stream</var> has been closed, then jump to the <i>loop done</i> step below.</li>
            <li>Read data from <var>stream</var> into <var>data</var>:
              <dl class="switch">
                <dt>If <var>maxSize</var> is set:</dt>
                <dd>
                  <ol>
                    <li>Read up to <var>bytesLeft</var> bytes from <var>stream</var> into <var>data</var>.</li>
                    <li>Subtract the number of bytes in <var>data</var> from <var>bytesLeft</var>.</li>
                </dd>
                <dt>Otherwise:</dt>
                <dd>Read all available bytes in <var>stream</var> into <var>data</var>.</dd>
              </dl>
            </li>
            <li>If an error occured while reading from <var>stream</var>, then run the <a def-id="append-error-algorithm"></a> and abort this algorithm.</li>
            <li>Run the <a def-id="coded-frame-eviction-algorithm"></a>.</li>
            <li>
              <p>If the <a def-id="buffer-full-flag"></a> equals true, then run the <a def-id="append-error-algorithm"></a> and abort this algorithm.</p>
              <p class="note">The web application must use <a def-id="remove"></a> to free up space in the <a>SourceBuffer</a>.</p>
            </li>
            <li>Add <var>data</var> to the end of the <a def-id="input-buffer"></a>.</li>
            <li>Run the <a def-id="segment-parser-loop"></a> algorithm.</li>
            <li>If the <a def-id="segment-parser-loop"></a> algorithm in the previous step was aborted, then abort this algorithm.</li>
            <li>Jump to the <i>loop top</i> step above.</li>
            <li><i>Loop Done: </i>Set the <a def-id="updating"></a> attribute to false.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="update"></a> at this <a>SourceBuffer</a> object.</li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="updateend"></a> at this <a>SourceBuffer</a> object.</li>
          </ol>
        </section>

        <section id="sourcebuffer-init-segment-received">
          <h4>Initialization Segment Received</h4>
          <p>The following steps are run when the <a def-id="segment-parser-loop"></a> successfully parses a complete <a def-id="init-segment"></a>:</p>
          <p>Each SourceBuffer object has an internal <dfn id="first-init-segment-flag">first initialization segment flag</dfn> that tracks whether the first <a def-id="init-segment"></a> has been appended. This flag is set to false when the SourceBuffer is created and updated by the algorithm below.</p>
          <ol>
            <li>Update the <a def-id="duration"></a> attribute if it currently equals NaN:
              <dl class="switch">
	        <dt>If the initialization segment contains a duration:</dt>
	        <dd>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the duration in the initialization segment.</dd>
	        <dt>Otherwise:</dt>
	        <dd>Run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to positive Infinity.</dd>
              </dl>
            </li>
            <li>If the <a def-id="init-segment"></a> has no audio, video, or text tracks, then call <a def-id="eos-decode"></a> and abort these steps.</li>
            <li>If the <a def-id="first-init-segment-flag"></a> is true, then run the following steps:
              <ol>
                <li>Verify the following properties. If any of the checks fail then call <a def-id="eos-decode"></a> and abort these steps.
                  <ul>
                    <li>The number of audio, video, and text tracks match what was in the first <a def-id="init-segment"></a>.</li>
                    <li>The codecs for each track, match what was specified in the first <a def-id="init-segment"></a>.</li>
                    <li>If more than one track for a single type are present (ie 2 audio tracks), then the <a def-id="track-ids"></a> match the ones in the
                      first <a def-id="init-segment"></a>.</li>
                  </ul>
                </li>
                <li>Add the appropriate <a def-id="track-descriptions"></a> from this <a def-id="init-segment"></a> to each of the 
                  <a def-id="track-buffers"></a>.</li>
              </ol>
            </li>
            <li>Let <var>active track flag</var> equal false.</li>
            <li>
              <p>If the <a def-id="first-init-segment-flag"></a> is false, then run the following steps:</p>
              <ol>
                <li>
                  <p>For each audio track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>Let <var>new audio track</var> be a new <a def-id="audio-track"></a> object.</li>
                    <li>Generate a unique ID and assign it to the <a def-id="audiotrack-id"></a> property on <var>new audio track</var>.</li>
                    <li>
                      <p>
                        If <a def-id="audiotracks"></a>.<a def-id="audiotracklist-length"></a> equals 0, then run
                          the following steps:
                      </p>
                      <ol>
                        <li>Set the <a def-id="audiotrack-enabled"></a> property on <var>new audio track</var> to true.</li>
                        <li>Set <var>active track flag</var> to true.</li>
                      </ol>
                    </li>
                    <li>Add <var>new audio track</var> to the <a def-id="sourcebuffer-audioTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at 
                      <a def-id="sourcebuffer-audioTracks"></a> attribute 
                      on this <a>SourceBuffer</a> object.</li>
                    <li>Add <var>new audio track</var> to the <a def-id="audiotracks"></a> attribute on the HTMLMediaElement.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at the <a def-id="audiotracks"></a> 
                      attribute on the HTMLMediaElement.</li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>
                  <p>For each video track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>Let <var>new video track</var> be a new <a def-id="video-track"></a> object.</li>
                    <li>Generate a unique ID and assign it to the <a def-id="videotrack-id"></a> property on <var>new video track</var>.</li>
                    <li>
                      <p>
                        If <a def-id="videotracks"></a>.<a def-id="videotracklist-length"></a> equals 0, then run
                          the following steps:
                      </p>
                      <ol>
                        <li>Set the <a def-id="videotrack-selected"></a> property on <var>new video track</var> to true.</li>
                        <li>Set <var>active track flag</var> to true.</li>
                      </ol>
                    </li>
                    <li>Add <var>new video track</var> to the <a def-id="sourcebuffer-videoTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at <a def-id="sourcebuffer-videoTracks"></a> attribute 
                      on this <a>SourceBuffer</a> object.</li>
                    <li>Add <var>new video track</var> to the <a def-id="videotracks"></a> attribute on the HTMLMediaElement.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at the <a def-id="videotracks"></a> attribute on the 
                      HTMLMediaElement.</li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>
                  <p>For each text track in the <a def-id="init-segment"></a>, run following steps:</p>
                  <ol>
                    <li>
                      Let <var>new text track</var> be a new <a def-id="text-track"></a> object with its properties populated with the appropriate
                      information from the <a def-id="init-segment"></a>.</li>
                    <li>
                      If the <a def-id="texttrack-mode"></a> property on <var>new text track</var> equals <a def-id="texttrack-showing"></a> or
                      <a def-id="texttrack-hidden"></a>, then set <var>active track flag</var> to true.
                    </li>
                    <li>Add <var>new text track</var> to the <a def-id="sourcebuffer-textTracks"></a> attribute on this <a>SourceBuffer</a> object.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at <a def-id="sourcebuffer-textTracks"></a> attribute 
                      on this <a>SourceBuffer</a> object.</li>
                    <li>Add <var>new text track</var> to the <a def-id="texttracks"></a> attribute on the HTMLMediaElement.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-addtrack"></a> at the <a def-id="texttracks"></a> attribute on the 
                      HTMLMediaElement.</li>
                    <li>Create a new <a def-id="track-buffer"></a> to store <a def-id="coded-frames"></a> for this track.</li>
                    <li>Add the <a def-id="track-description"></a> for this track to the <a def-id="track-buffer"></a>.</li>
                  </ol>
                </li>
                <li>If <var>active track flag</var> equals true, then run the following steps:
                  <ol>
                    <li>Add this <a>SourceBuffer</a> to <a def-id="activeSourceBuffers"></a>.</li>
                    <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="addsourcebuffer"></a> at <a def-id="activeSourceBuffers"></a></li>
                  </ol>
                </li>
                <li>Set <a def-id="first-init-segment-flag"></a> to true.</li>
              </ol>
            </li>
            <li>
              <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-nothing"></a>, then run the following steps:</p>
              <ol>
                <li>
                  If one or more objects in <a def-id="sourceBuffers"></a> have <a def-id="first-init-segment-flag"></a> set to false, then abort
                  these steps.</li>
                <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.</li>
	        <li><a def-id="Queue-a-task-to-fire-an-event-named"></a>  <a def-id="loadedmetadata"></a> at the media element.</li>
              </ol>
            </li>
            <li>
              If the <var>active track flag</var> equals true and the <a def-id="ready-state"></a> attribute is greater than
              <a def-id="have-current-data"></a>, then set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a>.
            </li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-processing">
          <h4>Coded Frame Processing</h4>
          <p>When complete <a def-id="coded-frames"></a> have been parsed by the <a def-id="segment-parser-loop"></a> then the following steps are run:</p>
          <ol>
            <li>
	      <p>For each <a def-id="coded-frame"></a> in the <a def-id="media-segment"></a> run the following steps:</p>
	      <ol>
	        <li>Let <var>presentation timestamp</var> be a double precision floating point representation of the coded frame's presentation timestamp in seconds.</li>
	        <li>Let <var>decode timestamp</var> be a double precision floating point representation of the coded frame's decode timestamp in seconds.
                  <p class="note">Implementations don't have to internally store timestamps in a double precision floating point representation. This
                    representation is used here because it is the represention for timestamps in the HTML spec. The intention here is to make the
                    behavior clear without adding unnecessary complexity to the algorithm to deal with the fact that adding a timestampOffset may
                    cause a timestamp rollover in the underlying timestamp representation used by the bytestream format. Implementations can use any
                    internal timestamp representation they wish, but the addition of timestampOffset should behave in a similar manner to what would happen
                    if a double precision floating point representation was used.
                  </p>
                </li>
                <li>Let <var>frame duration</var> be a double precision floating point representation of the coded frame's duration in seconds.</li>

                <li> If <a def-id="abort-mode"></a> is set, then run the following steps:
                  <ol>
                    <li>
                      <dl class="switch">
                        <dt>If <a def-id="abort-mode"></a> equals <a def-id="AbortMode-continuation"></a>:</dt>
                        <dd>Set <a def-id="timestampOffset"></a> equal to <a def-id="continuation-timestamp"></a> - <var>presentation timestamp</var>.</dd>
                        <dt>If <a def-id="abort-mode"></a> equals <a def-id="AbortMode-timestampOffset"></a>:</dt>
                        <dd>
                          <ol>
                            <li>Let <var>old timestampOffset</var> equal the current value of <a def-id="timestampOffset"></a>.</li>
                            <li>Set <a def-id="timestampOffset"></a> equal to <var>old timestampOffset</var> - <var>presentation timestamp</var>.</li>
                          </ol>
                        </dd>
                      </dl>
                    </li>
                    <li>Unset <a def-id="continuation-timestamp"></a>.</li>
                    <li>Unset <a def-id="abort-mode"></a>.</li>
                  </ol>
                </li>

	        <li>
	          <p>If <a def-id="timestampOffset"></a> is not 0, then run the following steps:</p>
	          <ol>
	            <li>Add <a def-id="timestampOffset"></a> to the <var>presentation timestamp</var>.</li>
	            <li>Add <a def-id="timestampOffset"></a> to the <var>decode timestamp</var>.</li>
	            <li>If the <var>presentation timestamp</var> or <var>decode timestamp</var> is less than the <a def-id="presentation-start-time"></a>, then call <a def-id="eos-decode"></a>, and abort these steps.</li>
	          </ol>
	        </li>
                <li>Let <var>track buffer</var> equal the <a def-id="track-buffer"></a> that the coded frame should be added to.</li>
                <li>If <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> is set and <var>decode timestamp</var> is less than
                  <a def-id="last-decode-timestamp"></a> or the difference between <var>decode timestamp</var> and <a def-id="last-decode-timestamp"></a>
                  is greater than 2 times <a def-id="last-frame-duration"></a>, then call <a def-id="eos-decode"></a> and abort these steps.
                  <p class="note">These checks trigger an error when the application attempts out-of-order appends without an intervening
                    <a def-id="abort"></a>.</p>
                </li>
                <li>Let <var>frame end timestamp</var> equal the sum of <var>presentation timestamp</var> and <var>frame duration</var>.</li>
                <li>If <var>presentation timestamp</var> is less than <a def-id="appendWindowStart"></a>, then set the <a def-id="need-RAP-flag"></a> to true, drop the
                  coded frame, and jump to the top of the loop to start processing the next coded frame.
                  <p class="note">Some implementations may choose to collect some of these coded frames that are outside the <a def-id="append-window"></a> and use them
                    to generate a splice at the first coded frame that has a presentation timestamp greater than or equal to <a def-id="appendWindowStart"></a> even if
                    that frame is not a <a def-id="random-access-point"></a>. Supporting this requires multiple decoders or faster than real-time decoding so for now
                    this behavior will not be a normative requirement.
                  </p>
                </li>
                <li>If <var>frame end timestamp</var> is greater than <a def-id="appendWindowEnd"></a>, then set the <a def-id="need-RAP-flag"></a> to true, drop the
                  coded frame, and jump to the top of the loop to start processing the next coded frame.
                <li>If the <a def-id="need-RAP-flag"></a> on <var>track buffer</var> equals true, then run the following steps:
                  <ol>
                    <li>If the coded frame is not a <a def-id="random-access-point"></a>, then drop the coded frame and jump to the top of the loop to start
                      processing the next coded frame.</li>
                    <li>Set the <a def-id="need-RAP-flag"></a> on <var>track buffer</var> to false.</li>
                  </ol>
                </li>
                <li>Let <var>spliced frame</var> be an unset variable for holding audio splice information</li>
                <li>If <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> is unset and there is a <a def-id="coded-frame"></a> in
                  <var>track buffer</var> with a presentation timestamp less than or equal to <var>presentation timestamp</var> and
                  <var>presentation timestamp</var> is less than this coded frame's presentation timestamp plus its frame duration, then run the
                  following steps:
                  <ol>
                    <li>Let <var>overlapped frame</var> be the <a def-id="coded-frame"></a> in <var>track buffer</var> that matches the condition above.</li>
                    <li>If <var>track buffer</var> contains audio <a def-id="coded-frames"></a>, then run the <a def-id="audio-splice-frame-algorithm"></a> and if a splice 
                      frame is returned, assign it to <var>spliced frame</var>.</li>
                    <li>Let <var>overlapped frame presentation timestamp</var> equal the presentation timestamp of <var>overlapped frame</var>.</li>
                    <li>Let <var>remove window timestamp</var> equal <var>overlapped frame presentation timestamp</var> plus 1 microsecond.</li>
                    <li>If <var>track buffer</var> contains video <a def-id="coded-frames"></a> and the <var>presentation timestamp</var> is less than the
                      <var>remove window timestamp</var>, then remove <var>overlapped frame</var> and any <a def-id="coded-frames"></a> that depend on it
                      from <var>track buffer</var>.
                      <p class="note">
                        This is to compensate for minor errors in frame timestamp computations that can appear when converting back and forth between double precision
                        floating point numbers and rationals. This tolerance allows a frame to replace an existing one as long as it is within 1 microsecond of the existing
                        frame's start time. Frames that come slightly before an existing frame are handled by the removal step below.
                      </p>
                    </li>
                  </ol>
                </li>
                <li>Remove existing coded frames in <var>track buffer</var>:
                  <dl class="switch">
                    <dt>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is not set:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have a presentation timestamp greater than or equal to
                      <var>presentation timestamp</var> and less than <var>frame end timestamp</var>.</dd>
                    <dt>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is set and less than <var>presentation timestamp</var></dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have a presentation timestamp greater than
                      <a def-id="highest-presentation-timestamp"></a> and less than or equal to <var>frame end timestamp</var>.</dd>
                  </dl>
                </li>
                <li>Remove decoding dependencies of the coded frames removed in the previous step:
                  <dl class="switch">
                    <dt>If detailed information about decoding dependencies is available:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> from <var>track buffer</var> that have decoding dependencies on the coded frames removed in
                      the previous step.
                      <p class="note">For example if an I-frame is removed in the previous step, then all P-frames & B-frames that depend on that I-frame
                        should be removed from <var>track buffer</var>. This makes sure that decode dependencies are properly maintained during overlaps.
                      </p>
                    </dd>
                    <dt>Otherwise:</dt>
                    <dd>Remove all <a def-id="coded-frames"></a> between the coded frames removed in the previous step and the next
                      <a def-id="random-access-point"></a> after those removed frames.
                      <p class="note">Removing all <a def-id="coded-frames"></a> until the next <a def-id="random-access-point"></a> is a conservative
                        estimate of the decoding dependencies since it assumes all frames between the removed frames and the next random access point
                        depended on the frames that were removed.
                      </p>
                    </dd>
                </li>
                <li>
                  <dl class="switch">
                    <dt>If <var>spliced frame</var> is set:</dt>
                    <dd>Add <var>spliced frame</var> to the <var>track buffer</var>.</dd>
                    <dt>Otherwise:</dt>
                    <dd>Add the <a def-id="coded-frame"></a> with the <var>presentation timestamp</var>, <var>decode timestamp</var>, and <var>frame duration</var> to the
                      <var>track buffer</var>.</dd>
                  </dl>
                <li>Set <a def-id="last-decode-timestamp"></a> for <var>track buffer</var> to <var>decode timestamp</var>.</li>
                <li>Set <a def-id="last-frame-duration"></a> for <var>track buffer</var> to <var>frame duration</var>.</li>
                <li>If <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var> is unset or <var>frame end timestamp</var> is greater
                  than <a def-id="highest-presentation-timestamp"></a>, then set <a def-id="highest-presentation-timestamp"></a> for <var>track buffer</var>
                  to <var>frame end timestamp</var>.
                  <p class="note">The greater than check is needed because bidirectional prediction between coded frames can cause
                    <var>presentation timestamp</var> to not be monotonically increasing eventhough the decode timestamps are monotonically increasing.</p>
                </li>
                <li>If <a def-id="highest-presentation-end-timestamp"></a> is unset or <var>frame end timestamp</var> is greater than
                  <a def-id="highest-presentation-end-timestamp"></a>, then set <a def-id="highest-presentation-end-timestamp"></a> equal to
                  <var>frame end timestamp</var>.</li>
	      </ol>
            </li>
            <li>
              <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-metadata"></a> and the new <a def-id="coded-frames"></a> cause all objects in <a def-id="activeSourceBuffers"></a> to have media data for the current playback position, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-current-data"></a>.</li>
	        <li>If this is the first transition to <a def-id="have-current-data"></a>, then <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="loadeddata"></a> at the media element.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-current-data"></a> and the new <a def-id="coded-frames"></a> cause all objects in <a def-id="activeSourceBuffers"></a> to have media data beyond the current playback position, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-future-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplay"></a> at the media element.</li>
	      </ol>
            </li>
            <li>
	      <p>If the <a def-id="ready-state"></a> attribute is <a def-id="have-future-data"></a> and the new <a def-id="coded-frames"></a> cause all objects in <a def-id="activeSourceBuffers"></a> to have <a def-id="enough-data"></a>, then run the following steps:</p>
	      <ol>
	        <li>Set the <a def-id="ready-state"></a> attribute to <a def-id="have-enough-data"></a>.</li>
	        <li>
                  <a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="canplaythrough"></a> at the media element.</li>
	      </ol>
            </li>
            <li>If the <a def-id="media-segment"></a> contains data beyond the current <a def-id="duration"></a>, then run the <a def-id="duration-change-algorithm"></a> with <var>new duration</var> set to the maximum of the current duration and the highest end timestamp reported by <a def-id="hme-buffered"></a>.</li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-removal">
          <h4>Coded Frame Removal Algorithm</h4>
          <p>Follow these steps when <a def-id="coded-frames"></a> for a specific time range need to be removed from the SourceBuffer:</p>
          <ol>
            <li>Let <var>start</var> be the starting presentation timestamp for the removal range.</li>
            <li>Let <var>end</var> be the end presentation timestamp for the removal range. </li>
            <li><p>For each <a def-id="track-buffer"></a> in this source buffer, run the following steps:</p>
              <ol>
	        <li>Let <var>remove end timestamp</var> be the current value of <a def-id="duration"></a></li>
                <li>
                  <p>If this <a def-id="track-buffer"></a> has a <a def-id="random-access-point"></a> timestamp that is greater than or equal to
                    <var>end</var>, then update <var>remove end timestamp</var> to that random access point timestamp.</p>
	          <p class="note">Random access point timestamps can be different across tracks because the dependencies between <a def-id="coded-frames"></a> within a
                    track are usually different than the dependencies in another track.</p>
                </li>
	        <li>Remove all media data, from this <a def-id="track-buffer"></a>, that contain starting timestamps greater than or equal to
                  <var>start</var> and less than the <var>remove end timestamp</var>.</li>
                <li>
                  <p>If this object is in <a def-id="activeSourceBuffers"></a>, the <a def-id="current-playback-position"></a> is greater than or equal to
                    <var>start</var> and less than the <var>remove end timestamp</var>, and <a def-id="ready-state"></a> is greater than
                    <a def-id="have-metadata"></a>, then set the <a def-id="ready-state"></a> attribute to <a def-id="have-metadata"></a> and stall playback.</p>
                  <p class="note">This transition occurs because media data for the current position has been removed. Playback cannot progress until media for the
                    <a def-id="current-playback-position"></a> is appended or the <a href="#active-source-buffer-changes">selected/enabled tracks change</a>.</p>
                </li>
	      </ol>
            </li>
            <li>If <a def-id="buffer-full-flag"></a> equals true and this object is ready to accept more bytes, then set
              the <a def-id="buffer-full-flag"></a> to false.</li>
          </ol>
        </section>

        <section id="sourcebuffer-coded-frame-eviction">
          <h4>Coded Frame Eviction Algorithm</h4>
          <p>This algorithm is run to free up space in this source buffer when new data is appended.</p>
          <ol>
            <li>Let <var>new data</var> equal the data that is about to be appended to this SourceBuffer.</li>
            <li>If the <a def-id="buffer-full-flag"></a> equals false, then abort these steps.</li>
            <li>Let <var>removal ranges</var> equal a list of presentation time ranges that can be evicted from the presentation to make room for the
              <var>new data</var>.
              <p class="note">Implementations may use different methods for selecting <var>removal ranges</var> so web applications must not depend on a
                specific behavior. The web application can use the <a def-id="buffered"></a> attribute to observe whether portions of the buffered data have been evicted.
              </p>
            </li>
            <li>For each range in <var>removal ranges</var>, run the <a def-id="coded-frame-removal-algorithm"></a> with <var>start</var> and <var>end</var> equal to
              the removal range start and end timestamp respectively.</li>
          </ol>
        </section>

        <section id="sourcebuffer-audio-splice-frame-algorithm">
          <h4>Audio Splice Frame Algorithm</h4>
          <p>Follow these steps when the <a def-id="coded-frame-processing-algorithm"></a> needs to generate a splice frame for two overlapping audio
            <a def-id="coded-frames"></a>:</p>
          <ol>
            <li>Let <var>track buffer</var> be the <a def-id="track-buffer"></a> that will contain the splice.</li>
            <li>Let <var>new coded frame</var> be the new <a def-id="coded-frame"></a>, that is being added to <var>track buffer</var>, which triggered the need for a splice.</li>
            <li>Let <var>presentation timestamp</var> be the presentation timestamp for <var>new coded frame</var></li>
            <li>Let <var>decode timestamp</var> be the decode timestamp for <var>new coded frame</var>.</li>
            <li>Let <var>frame duration</var> be the duration of <var>new coded frame</var>.</li>
            <li>Let <var>overlapped frame</var> be the <a def-id="coded-frame"></a> in <var>track buffer</var> with a presentation timestamp less than or equal to 
              <var>presentation timestamp</var> and <var>presentation timestamp</var> is less than this coded frame's presentation timestamp plus its frame duration.
            </li>
            <li>Update <var>presentation timestamp</var> and <var>decode timestamp</var> to the nearest audio sample timestamp based on sample rate of the 
              audio in <var>overlapped frame</var>. If a timestamp is equidistant from both audio sample timestamps, then use the higher timestamp. (eg.
              floor(x * sample_rate + 0.5) / sample_rate).
              <div class="note">
                <p>For example, given the following values:</p>
                <ul>
                  <li>The presentation timestamp of <var>overlapped frame</var> equals 10.</li>
                  <li>The sample rate of <var>overlapped frame</var> equals 8000 Hz</li>
                  <li><var>presentation timestamp</var> equals 10.01255</li>
                  <li><var>decode timestamp</var> equals 10.01255</li>
                </ul>
                <p><var>presentation timestamp</var> and <var>decode timestamp</var> are updated to 10.0125 since 10.01255 is closer to
                10 + 100/8000 (10.0125) than 10 + 101/8000 (10.012625)</p>
              </div>
            </li>
            <li>If the user agent does not support crossfading then run the following steps:
              <ol>
                <li>Remove <var>overlapped frame</var> from <var>track buffer</var>.</li>
                <li>Add a silence frame to <var>track buffer</var> with the following properties:
                  <ul>
                    <li>The presentation time set to the <var>overlapped frame</var> presentation time.</li>
                    <li>The decode time set to the <var>overlapped frame</var> decode time.</li>
                    <li>The frame duration set to difference between <var>presentation timestamp</var> and the <var>overlapped frame</var> presentation time.</li>
                  </ul>
                  <p class="note">
                    Some implementations may apply fades to/from silence to coded frames on either side of the inserted silence to make the transition less
                    jarring.
                  </p>
                </li>
                <li>Return to caller without providing a splice frame.
                  <p class="note">
                    This is intended to allow <var>new coded frame</var> to be added to the <var>track buffer</var> as if
                    <var>overlapped frame</var> had not been in the <var>track buffer</var> to begin with.
                  </p>
                </li>
              </ol>
            </li>
            <li>Let <var>frame end timestamp</var> equal the sum of <var>presentation timestamp</var> and <var>frame duration</var>.</li>
            <li>Let <var>splice end timestamp</var> equal the sum of <var>presentation timestamp</var> and the splice duration of 5 milliseconds.</li>
            <li>Let <var>fade out coded frames</var> equal <var>overlapped frame</var> as well as any additional frames in <var>track buffer</var> that
              have a presentation timestamp greater than <var>presentation timestamp</var> and less than <var>splice end timestamp</var>.</li>
            <li>Remove all the frames included in <var>fade out coded frames</var> from <var>track buffer</var>.
            <li>Return a splice frame with the following properties:
              <ul>
                <li>The presentation time set to the <var>overlapped frame</var> presentation time.</li>
                <li>The decode time set to the <var>overlapped frame</var> decode time.</li>
                <li>The frame duration set to difference between <var>frame end timestamp</var> and the <var>overlapped frame</var> presentation time.</li>
                <li>The fade out coded frames equals <var>fade-out coded frames</var>.</li>
                <li>The fade in coded frame equal <var>new coded frame</var>.
                  <p class="note">If the <var>new coded frame</var> is less than 5 milliseconds in duration, then coded frames that are appended after the
                    <var>new coded frame</var> will be needed to properly render the splice.</p>
                </li>
                <li>The splice timestamp equals <var>presentation timestamp</var>.</li>
              </ul>
              <p class="note">See the <a def-id="audio-splice-rendering-algorithm"></a> for details on how this splice frame is rendered.</p>
            </li>
          </ol>
        </section>
        <section id="sourcebuffer-audio-splice-rendering-algorithm">
          <h4>Audio Splice Rendering Algorithm</h4>
          <p>The following steps are run when a spliced frame, generated by the <a def-id="audio-splice-frame-algorithm"></a>, needs to be rendered by the 
            media element:</p>
          <ol>
            <li>Let <var>fade out coded frames</var> be the <a def-id="coded-frames"></a> that are faded out during the splice.</li>
            <li>Let <var>fade in coded frames</var> be the <a def-id="coded-frames"></a> that are faded in during the splice.</li>
            <li>Let <var>presentation timestamp</var> be the presentation timestamp of the first coded frame in <var>fade out coded frames</var>.</li>
            <li>Let <var>end timestamp</var> be the sum of the presentation timestamp and frame duration in the last frame in <var>fade in coded frames</var>.</li>
            <li>Let <var>splice timestamp</var> be the presentation timestamp where the splice starts. This corresponds with the presentation timestamp of the first frame in
              <var>fade in coded frames</var>.</li>
            <li>Let <var>splice end timestamp</var> equal <var>splice timestamp</var> plus five milliseconds.</li>
            <li>Let <var>fade out samples</var> be the samples generated by decoding <var>fade out coded frames</var>.</li>
            <li>Trim <var>fade out samples</var> so that it only contains samples between <var>presentation timestamp</var> and <var>splice end timestamp</var>.</li>
            <li>Let <var>fade in samples</var> be the samples generated by decoding <var>fade in coded frames</var>.</li>
            <li>If <var>fade out samples</var> and <var>fade in samples</var> do not have a common sample rate and channel layout, then convert
              <var>fade out samples</var> and <var>fade in samples</var> to a common sample rate and channel layout.</li>
            <li>Let <var>output samples</var> be a buffer to hold the output samples.</li>
            <li>Apply a linear gain fade out with a starting gain of 1 and an ending gain of 0 to the samples between
              <var>splice timestamp</var> and <var>splice end timestamp</var> in <var>fade out samples</var>.</li>
            <li>Apply a linear gain fade in with a starting gain of 0 and an ending gain of 1 to the samples between <var>splice timestamp</var> and
              <var>splice end timestamp</var> in <var>fade in samples</var>.</li>
            <li>Copy samples between <var>presentation timestamp</var> to <var>splice timestamp</var> from <var>fade out samples</var> into <var>output samples</var>.</li>
            <li>For each sample between <var>splice timestamp</var> and <var>splice end timestamp</var>, compute the sum of a sample from <var>fade out samples</var> and the
              corresponding sample in <var>fade in samples</var> and store the result in <var>output samples</var>.</li>
            <li>Copy samples between <var>splice end timestamp</var> to <var>end timestamp</var> from <var>fade in samples</var> into <var>output samples</var>.</li>
            <li>Render <var>output samples</var>.</li>
          </ol>
          <div class="note">
            <p>Here is a graphical representation of this algorithm.</p>
            <img src="audio_splice.png" alt="Audio splice diagram">
          </div>
        </section>
      </section>
    </section>

    <section id="sourcebufferlist">
      <h2>SourceBufferList Object</h2>
      <p>SourceBufferList is a simple container object for <a>SourceBuffer</a> objects. It provides read-only array access and fires events when the list is modified.</p>

      <dl title="interface SourceBufferList : EventTarget" class="idl">
        <dt>readonly attribute unsigned long length</dt>
        <dd>
          <p>Indicates the number of <a>SourceBuffer</a> objects in the list.</p>
        </dd>
        <dt>getter SourceBuffer (unsigned long index)</dt>
        <dd>
          <p>Allows the SourceBuffer objects in the list to be accessed with an array operator (i.e. []).</p>

          <ol class="method-algorithm">
            <li>If <var>index</var> is greater than or equal to the <a def-id="length"></a> attribute then return undefined and abort these steps.</li>
            <li>Return the <var>index</var>'th <a>SourceBuffer</a> object in the list.</li>
          </ol>
        </dd>
      </dl>

      <section id="sourcebufferlist-events">
        <h3>Event Summary</h3>
        <table class="old-table">
          <thead>
            <tr>
              <th>Event name</th>
              <th>Interface</th>
              <th>Dispatched when...</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td><a def-id="eventdfn">addsourcebuffer</a></td>
              <td><code>Event</code></td>
              <td>When a <a>SourceBuffer</a> is added to the list.</td>
            </tr>
            <tr>
              <td><a def-id="eventdfn">removesourcebuffer</a></td>
              <td><code>Event</code></td>
              <td>When a <a>SourceBuffer</a> is removed from the list.</td>
            </tr>
          </tbody>
        </table>
      </section>
    </section>

    <section id="mediaplaybackquality">
      <h2>MediaPlaybackQuality Object</h2>
      <dl title="interface MediaPlaybackQuality" class="idl">
        <dt>readonly attribute Date creationTime</dt>
        <dd>
          <p>The local time when this object was created.(i.e. set to new Date()).</p>
        </dd>

        <dt>readonly attribute unsigned long totalVideoFrames</dt>
        <dd>
          <p>The total number of frames that would have been displayed if no frames are dropped.</p>
        </dd>

        <dt>readonly attribute unsigned long droppedVideoFrames</dt>
        <dd>
          <p>The total number of frames dropped predecode or dropped because the frame missed
            its display deadline.</p>
        </dd>
      </dl>
    </section>

    <section id="url">
      <h2>URL Object Extensions</h2>
      <p>This section specifies extensions to the <a def-id="URL"></a>[[FILE-API]] object definition.</p>

      <dl title="partial interface URL" class="idl">
        <dt>static DOMString createObjectURL(MediaSource mediaSource)</dt>
        <dd>
          <p>Creates URLs for <a>MediaSource</a> objects.</p>

          <ol class="method-algorithm">
            <li>If <var>mediaSource</var> is NULL the return null.</li>
            <li>Return a unique <a def-id="MediaSource-object-URL"></a> that can be used to dereference the <var>mediaSource</var> argument, and run the rest of the algorithm asynchronously.</li>
            <li><a def-id="provide-a-stable-state"></a></li>
            <li>Revoke the <a def-id="MediaSource-object-URL"></a> by calling <a def-id="file-revokeObjectURL"></a> on it.</li>
          </ol>
          <p class="note">This algorithm is intended to mirror the behavior of the <a def-id="file-createObjectURL"></a>[[FILE-API]] method with autoRevoke set to true.</p>
        </dd>
      </dl>
    </section>

    <section id="htmlmediaelement-extensions">
      <h2>HTMLMediaElement Extensions</h2>

      <section id="htmlmediaelement-existing-attributes">
        <h2>Modifications to Existing Attribute Behavior</h2>
        <p>This section specifies what existing attributes on the <a def-id="htmlmediaelement"></a> should return when a <a>MediaSource</a> is attached to the element.</p>

        <p>The <a def-id="videoref" name="dom-media-seekable">HTMLMediaElement.seekable</a> attribute returns a new static <a def-id="normalized-timeranges-object"></a> created based on the following steps:</p>
        <dl class="switch">
          <dt>If <a def-id="duration"></a> equals NaN</dt>
          <dd>Return an empty <a def-id="timeranges"></a> object.</dd>
          <dt>If <a def-id="duration"></a> equals positive Infinity</dt>
          <dd>Return a single range with a start time of 0 and an end time equal to the highest end time reported by the <a def-id="hme-buffered"></a> attribute.</dd>
          <dt>Otherwise</dt>
          <dd>Return a single range with a start time of 0 and an end time equal to <a def-id="duration"></a>.</dd>
        </dl>

        <p id="dom-htmlmediaelement.buffered">The <a def-id="hme-buffered"></a> attribute returns a new static <a def-id="normalized-timeranges-object"></a> created based on the following steps:</p>
        <ol>
          <li>If <a def-id="activeSourceBuffers"></a>.length equals 0 then return an empty <a def-id="timeranges"></a> object and abort these steps.</li>
          <li>Let <var>active ranges</var> be the ranges returned by <a def-id="buffered"></a> for each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a>.</li>
          <li>Let <var>highest end time</var> be the largest range end time in the <var>active ranges</var>.</li>
          <li>Let <var>intersection ranges</var> equal a <a def-id="timerange"></a> object containing a single range from 0 to <var>highest end time</var>.</li>
          <li>For each <a>SourceBuffer</a> object in <a def-id="activeSourceBuffers"></a> run the following steps:
            <ol>
              <li>Let <var>source ranges</var> equal the ranges returned by the <a def-id="buffered"></a> attribute on the current <a>SourceBuffer</a>.</li>
              <li>If <a def-id="readyState"></a> is <a def-id="ended"></a>, then set the end time on the last range in <var>source ranges</var> to
                <var>highest end time</var>.</li>
              <li>Let <var>new intersection ranges</var> equal the the intersection between the <var>intersection ranges</var> and the <var>source ranges</var>.</li>
              <li>Replace the ranges in <var>intersection ranges</var> with the <var>new intersection ranges</var>.</li>
            </ol>
          </li>
          <li>Return the <var>intersection ranges</var>.</li>
        </ol>
      </section>
      <section id="htmlmediaelement-new-attributes">
        <h2>New Attributes and Behavior</h2>
        <p>This section specifies new attributes and internal state that are being added to the <a def-id="htmlmediaelement"></a>.</p>

        <p>Each <a def-id="htmlmediaelement"></a> will maintain a <dfn id="total-video-frame-count">total video frame count</dfn> variable that keeps
          track of the total number of frames that have been displayed and dropped. This variable is initialized to 0 when the
          element is created and whenever the <a def-id="media-element-load-algorithm"></a> is invoked. It is incremented when a video frame is displayed
          or when the <a def-id="dropped-video-frame-count"></a> is incremented.</p>

        <p>Each <a def-id="htmlmediaelement"></a> will maintain a <dfn id="dropped-video-frame-count">dropped video frame count</dfn> variable that keeps
          track of the total number of frames that have been dropped. This variable is initialized to 0 when the
          element is created and whenever the <a def-id="media-element-load-algorithm"></a> is invoked. It is incremented when a video frame is dropped
          predecode or when a frame is decoded but dropped because it missed a display deadline.</p>

        <dl title="partial interface HTMLMediaElement" class="idl">
          <dt>readonly attribute MediaPlaybackQuality playbackQuality</dt>
          <dd>
            <p>Provides the current the playback quality metrics.</p>
            <p>On getting, run the following steps:</p>
            <ol>
              <li>Let <var>playbackQuality</var> be a new instance of <a>MediaPlaybackQuality</a>.</li>
              <li>Set <var>playbackQuality</var>.<a def-id="creationTime"></a> to a new Date object that reflects the current local time.</li>
              <li>Set <var>playbackQuality</var>.<a def-id="totalVideoFrames"></a> to the current value of the <a def-id="total-video-frame-count"></a>.</li>
              <li>Set <var>playbackQuality</var>.<a def-id="droppedVideoFrames"></a> to the current value of the <a def-id="dropped-video-frame-count"></a>.</li>
              <li>Return <var>playbackQuality</var>.</li>
            </ol>
          </dd>
        </dl>
      </section>
    </section>

    <section id="audio-track-extensions">
      <h2>AudioTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="audio-track"></a> definition.</p>

      <dl title="partial interface AudioTrack" class="idl">
        <dt>attribute DOMString kind</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="audiotrack-kind"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute does not match one of the <a def-id="videoref" name="dom-TrackList-getKind-categories">kind categories</a>, then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="audiotrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="audiotrack-sourceBuffer"></a>.<a def-id="sourcebuffer-audioTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="audiotracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>attribute DOMString language</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="audiotrack-language"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute is not an empty string or a BCP 47 language tag[[BCP47]], then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="audiotrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="audiotrack-sourceBuffer"></a>.<a def-id="sourcebuffer-audioTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="audiotracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
      </dl>
    </section>

    <section id="video-track-extensions">
      <h2>VideoTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="video-track"></a> definition.</p>

      <dl title="partial interface VideoTrack" class="idl">
        <dt>attribute DOMString kind</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="videotrack-kind"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute does not match one of the <a def-id="videoref" name="dom-TrackList-getKind-categories">kind categories</a>, then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="videotrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="videotrack-sourceBuffer"></a>.<a def-id="sourcebuffer-videoTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="videotracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>attribute DOMString language</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="videotrack-language"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute is not an empty string or a BCP 47 language tag[[BCP47]], then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="videotrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="videotrack-sourceBuffer"></a>.<a def-id="sourcebuffer-videoTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="videotracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
    </section>

    <section id="text-track-extensions">
      <h2>TextTrack Extensions</h2>
      <p>This section specifies extensions to the HTML <a def-id="text-track"></a> definition.</p>

      <dl title="partial interface TextTrack" class="idl">
        <dt>attribute DOMString kind</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="texttrack-kind"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute does not match one of the <a def-id="videoref" name="text-track-kind">text track kinds</a>, then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="texttrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="texttrack-sourceBuffer"></a>.<a def-id="sourcebuffer-textTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="texttracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>attribute DOMString language</dt>
        <dd>
          <p>Allows the web application to get and update the track <a def-id="texttrack-language"></a>.</p>
          <p>On getting, return the current value of the attribute. This is either the value provided when this object was created or the value provided on
            the last successful set operation.<p>
          <p>On setting, run the following steps:</p>
          <ol>
            <li>If the value being assigned to this attribute is not an valid <a def-id="videoref" name="text-track-language">text track language</a>, 
              then abort these steps.</li>
            <li>Update this attribute to the new value.</li>
            <li>If the <a def-id="texttrack-sourceBuffer"></a> attribute on this track is not null, then
              <a def-id="queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at
              <a def-id="texttrack-sourceBuffer"></a>.<a def-id="sourcebuffer-textTracks"></a>.
            </li>
            <li><a def-id="Queue-a-task-to-fire-an-event-named"></a> <a def-id="tracklist-change"></a> at the <a def-id="texttracks"></a> attribute on the
              HTMLMediaElement.
            </li>
          </ol>
        </dd>

        <dt>readonly attribute SourceBuffer? sourceBuffer</dt>
        <dd>
          <p>Returns the <a>SourceBuffer</a> that created this track. Returns null if this track was not created by a <a>SourceBuffer</a> or the <a>SourceBuffer</a> has been removed from the <a def-id="sourceBuffers"></a> attribute of its <a def-id="parent-media-source"></a>.</p>
        </dd>
    </section>

    <section id="byte-stream-formats">
      <h2>Byte Stream Formats</h2>
      <p>The bytes provided through <a def-id="appendBuffer"></a> and <a def-id="appendStream"></a> for a <a>SourceBuffer</a> form a logical byte stream. The format of this byte stream depends on the media container format in use and is defined in a byte stream format specification. Byte stream format specifications based on WebM , the ISO Base Media File Format, and MPEG-2 Transport Streams are provided below. These format specifications are intended to be the authoritative source for how data from these containers is formatted and passed to a <a>SourceBuffer</a>. If a <a>MediaSource</a> implementation claims to support any of these container formats, then it must implement the corresponding byte stream format specification described below.</p>
      <p>This section provides general requirements for all byte stream formats:</p>
      <ul>
        <li>A byte stream format specification must define <a def-id="init-segments"></a> and <a def-id="media-segments"></a>.</li>
        <li>It must be possible to identify segment boundaries and segment type (initialization or media) by examining the byte stream alone.</li>
        <li>The following rules apply to all <a def-id="init-segments"></a> within a byte stream:
          <ol>
            <li>
              <p>The number and type of tracks must be consistent.</p>
              <p>For example, if the first <a def-id="init-segment"></a> has 2 audio tracks and 1 video track, then all <a def-id="init-segments"></a> that follow it in the byte stream must describe 2 audio tracks and 1 video track.</p>
            </li>
	    <li>
              <p><a def-id="track-ids"></a> do not need to be the same across <a def-id="init-segments"></a> if the segment describes only one track of each type.</p>
              <p>For example, if an <a def-id="init-segment"></a> describes a single audio track and a single video track, the internal <a def-id="track-ids"></a> do not need to be the same.</p>
            </li>
            <li><a def-id="track-ids"></a> must be the same across <a def-id="init-segments"></a> if the segment describes multiple tracks of a single type. (e.g. 2 audio tracks).</li>
	    <li>
              <p>Codecs changes are not allowed.</p>
              <p>For example, a byte stream that starts with an <a def-id="init-segment"></a> that specifies a single AAC track and later contains an <a def-id="init-segment"></a> that specifies a single AMR-WB track is not allowed. Support for multiple codecs is handled with multiple <a>SourceBuffer</a> objects.</p>
            </li>
	    <li>
              <p>Video frame size changes are allowed and must be supported seamlessly.</p>
              <p class="note">This will cause the &lt;video&gt; display region to change size if the web application does not use CSS or HTML attributes (width/height) to constrain the element size.</p>
            </li>
	    <li>
              <p>Audio channel count changes are allowed, but they may not be seamless and could trigger downmixing.</p>
              <p class="note">This is a quality of implementation issue because changing the channel count may require reinitializing the audio device, resamplers, and channel mixers which tends to be audible.</p>
            </li>
          </ol>
        </li>
        <li>The following rules apply to all <a def-id="media-segments"></a> within a byte stream:
          <ol>
            <li>All timestamps must be mapped to the same <a def-id="media-timeline"></a>.</li>
	    <li>Gaps between <a def-id="media-segments"></a> that are smaller than the audio frame size are allowed and must not cause playback to stall. Such gaps must not be reflected by <a def-id="buffered"></a>.
	      <p class="note">This is intended to simplify switching between audio streams where the frame boundaries don't always line up across encodings (e.g. Vorbis).</p>
            </li>
          </ol>
        </li>
        <li>The combination of an <a def-id="init-segment"></a> and any contiguous sequence of <a def-id="media-segments"></a> associated with it must:
	  <ol>
	    <li>Identify the number and type (audio, video, text, etc.) of tracks in the Segments</li>
	    <li>Identify the decoding capabilities needed to decode each track (i.e. codec and codec parameters)</li>
	    <li>If a track is encrypted, provide any encryption parameters necessary to decrypt the content (except the encryption key itself)</li>
	    <li>For each track, provide all information necessary to decode and render the earliest <a def-id="random-access-point"></a> in the sequence of Media Segments and all subsequent samples in the sequence (in presentation time). This includes, in particular,
	      <ul>
	        <li>Information that determines the <a def-id="intrinsic-width-and-height"></a> of the video (specifically, this requires either the picture or pixel aspect ratio, together with the encoded resolution).</li>
	        <li>Information necessary to convert the video decoder output to a format suitable for display</li>
	      </ul>
	    </li>
	    <li>Identify the global presentation timestamp of every sample in the sequence of Media Segments</li>
	  </ol>
	  <p>For example, if I1 is associated with M1, M2, M3 then the above must hold for all the combinations I1+M1, I1+M2, I1+M1+M2, I1+M2+M3, etc.</p>
        </li>
      </ul>
      <p>Byte stream specifications must at a minimum define constraints which ensure that the above requirements hold. Additional constraints may be defined, for example to simplify implementation.</p>

      <section id="webm" class="nonnormative">
        <h3>WebM Byte Streams</h3>
        <p>This section defines segment formats for implementations that choose to support WebM.</p>

        <section id="webm-init-segments">
          <h4>Initialization Segments</h4>
          <p>A WebM <a def-id="init-segment"></a> must contain a subset of the elements at the start of a typical WebM file.</p>
          <p>The following rules apply to WebM initialization segments:</p>
          <ol>
	    <li>The <a def-id="init-segment"></a> must start with an <a def-id="webm-ebml-header"></a> element, followed by a <a def-id="webm-segment"></a> header.</li>
	    <li>The size value in the <a def-id="webm-segment"></a> header must signal an "unknown size" or contain a value large enough to include the <a def-id="webm-info"></a> and <a def-id="webm-tracks"></a> elements that follow.</li>
	    <li>A <a def-id="webm-info"></a> element and a <a def-id="webm-tracks"></a> element must appear, in that order, after the <a def-id="webm-segment"></a> header and before any further <a def-id="webm-ebml-header"></a> or <a def-id="webm-cluster"></a> elements.</li>
	    <li>Any elements other than an <a def-id="webm-ebml-header"></a> or a <a def-id="webm-cluster"></a> that occur before, in between, or after the <a def-id="webm-info"></a> and <a def-id="webm-tracks"></a> elements are ignored.</li>
          </ol>
        </section>

        <section id="webm-media-segments">
          <h4>Media Segments</h4>
          <p>A WebM <a def-id="media-segment"></a> is a single <a def-id="webm-cluster"></a> element.</p>
          <p>The following rules apply to WebM media segments:</p>
          <ol>
	    <li>The Timecode element in the <a def-id="webm-cluster"></a> contains a presentation timestamp in TimecodeScale units.</li>
	    <li>The TimecodeScale in the <a def-id="webm-init-segment"></a> most recently appended applies to all timestamps in the <a def-id="webm-cluster"></a>
            </li>
	    <li>The Cluster header may contain an "unknown" size value. If it does then the end of the cluster is reached when another <a def-id="webm-cluster"></a> header or an element header that indicates the start of an <a def-id="webm-init-segment"></a> is encountered.</li>
	    <li>Block &amp; SimpleBlock elements must be in time increasing order consistent with the <a def-id="webm-spec"></a>.</li>
	    <li>If the most recent <a def-id="webm-init-segment"></a> describes multiple tracks, then blocks from all the tracks must be interleaved in time increasing order. At least one block from all audio and video tracks must be present.</li>
	    <li>
              <a def-id="webm-cues"></a> or <a def-id="webm-chapters"></a> elements may follow a <a def-id="webm-cluster"></a> element. These elements must be accepted and ignored by the user agent.</li>
          </ol>
        </section>

        <section id="webm-random-access-points">
          <h4>Random Access Points</h4>
          <p>A SimpleBlock element with its Keyframe flag set signals the location of a <a def-id="random-access-point"></a> for that track. Media segments containing multiple tracks are only considered a random access point if the first SimpleBlock for each track has its Keyframe flag set. The order of the multiplexed blocks must conform to the <a def-id="webm-muxer-guidelines"></a>.</p>
        </section>
      </section>
      
      <section id="iso" class="nonnormative">
        <h3>ISO Base Media File Format Byte Streams</h3>
        <p>This section defines segment formats for implementations that choose to support the ISO Base Media File Format
	  <a def-id="iso-14496-12"></a> (ISO BMFF).</p> 

	<section id="iso-init-segments">
          <h4>Initialization Segments</h4>
          <p>An ISO BMFF <a def-id="init-segment"></a> is defined in this specification as a single Movie Header Box (<span class="iso-box">moov</span>).
            The tracks in the  Movie Header Box must not contain any samples (i.e. the <span class="iso-var">entry_count</span> in the
            <span class="iso-box">stts</span>, <span class="iso-box">stsc</span> and <span class="iso-box">stco</span> boxes must be set to zero). A Movie
            Extends (<span class="iso-box">mvex</span>) box must be contained in the Movie Header Box to indicate that Movie Fragments are to be expected.
          </p>
          <p>The <a def-id="init-segment"></a> may contain Edit Boxes (<span class="iso-box">edts</span>) which provide a mapping of composition times for each track to the global presentation time.</p>
          <p>Valid top-level boxes such as <span class="iso-box">ftyp</span>, <span class="iso-box">styp</span>, and <span class="iso-box">sidx</span> are
            allowed to appear before the <span class="iso-box">moov</span> box. These boxes must be accepted and ignored by the user agent and are not
            considered part of the <a def-id="init-segment"></a> in this specification.</p>
	</section>
        
	<section id="iso-media-segments">
          <h4>Media Segments</h4>
          <p>An ISO BMFF <a def-id="media-segment"></a> is defined in this specification as a single Movie Fragment Box
            (<span class="iso-box">moof</span>) followed by one or more Media Data Boxes (<span class="iso-box">mdat</span>).</p>
          <p>Valid top-level boxes defined in <a def-id="iso-14496-12"></a> other than <span class="iso-box">moov</span>, 
            <span class="iso-box">moof</span>, and <span class="iso-box">mdat</span> are allowed to appear between the end of an
            <a def-id="init-segment"></a> or <a def-id="media-segment"></a> and before the beginning of a new <a def-id="media-segment"></a>.
            These boxes must be accepted and ignored by the user agent and are not considered part of the <a def-id="media-segment"></a> in this
            specification.
          </p>
          <p>The following rules apply to ISO BMFF media segments:</p>
          <ol>
	    <li>The Movie Fragment Box must contain at least one Track Fragment Box (<span class="iso-box">traf</span>).</li>
	    <li>The Movie Fragment Box must use movie-fragment relative addressing and the flag <span class="iso-var">default-base-is-moof</span> must be set; absolute byte-offsets must not be used.</li>
	    <li>External data references must not be used.</li>
	    <li>If the Movie Fragment contains multiple tracks, the duration by which each track extends should be as close to equal as practical.</li>
	    <li>Each Track Fragment Box must contain a Track Fragment Decode Time Box (<span class="iso-box">tfdt</span>)</li>
	    <li>The Media Data Boxes must contain all the samples referenced by the Track Fragment Run Boxes (<span class="iso-box">trun</span>) of the Movie Fragment Box.</li>
          </ol>
	</section>

	<section id="iso-random-access-points">
          <h4>Random Access Points</h4>
          <p>A <a def-id="random-access-point"></a> as defined in this specification corresponds to a Stream Access Point of type 1 or 2 as defined in Annex I of <a def-id="iso-14496-12"></a>.</p>
	</section>
      </section>

      <section id="mpeg2ts" class="nonnormative">
        <h3>MPEG-2 Transport Stream Byte Streams</h3>
        <p>This section defines segment formats for implementations that choose to support MPEG-2 Transport Streams
          (MPEG-2 TS) specified in <a def-id="iso-13818-1"></a>.</p>
        
        <section id="mpeg2ts-general">
          <h4>General</h4>
          <p>MPEG-2 TS media and initialization segments must conform to the MPEG-2 TS Adaptive Profile (ISO/IEC 13818-1:2012 Amd. 2).</p>
          <p>The following rules must apply to all MPEG-2 TS segments:</p>
          <ol>
            <li>Segments must contain complete MPEG-2 TS packets.</li>
            <li>Segments must contain only complete PES packets and sections.</li>
            <li>Segments must contain exactly one program.</li>
            <li>All MPEG-2 TS packets must have the transport_error_indicator set to 0</li>
          </ol>
        </section>
        <section id="mpeg2ts-init-segments">
          <h4>Initialization Segments</h4>
          <p>An MPEG-2 TS initialization segment must contain a single PAT and a single PMT. Other SI, such as CAT, that are invariant for all subsequent
            media segments, may be present.</p>
        </section>
  
        <section id="mpeg2ts-media-segments">
          <h4>Media Segments</h4>
          <p>The following rules apply to all MPEG-2 TS media segments:</p>
          <ol>
            <li>PSI that is identical to the information in the initialization segment may appear repeatedly throughout the segment.</li>
            <li>The media segment will not rely on initialization information in another media segment.</li>
            <li>Media Segments must contain only complete PES packets and sections.</li>
            <li>Each PES packet must have a PTS timestamp.</li>
            <li>PCR must be present in the Segment prior to the first byte of a TS packet payload containing media data.</li>
            <li>The presentation duration of each media component within the Media Segment should be as close to equal as practical.</li>
          </ol>
        </section>

        <section id="mpeg2ts-random-access-points">
          <h4>Random Access Points</h4>
          <p>A random access point as defined in this specification corresponds to Elementary Stream Random Access Point as defined in 
            <a def-id="iso-13818-1"></a>.</p>
        </section>
        <section id="mpeg2ts-discontinuities">
          <h4>Timestamp Rollover &amp; Discontinuities</h4>
          <p>Timestamp rollovers and discontinuities must be handled by the UA. The UA's MPEG-2 TS implementation must maintain an internal offset
          variable, <dfn id="mpeg2ts-timestampOffset">MPEG2TS_timestampOffset</dfn>, to keep track of the offset that needs to be applied to timestamps
          that have rolled over or are part of a discontinuity. <var>MPEG2TS_timestampOffset</var> is initially set to 0 when the <a>SourceBuffer</a> is 
          created.  This offset must be applied to the timestamps as part of the conversion process from MPEG-2 TS packets
          into <a def-id="coded-frames"></a> for the <a def-id="coded-frame-processing-algorithm"></a>. This results in the coded frame timestamps 
          for a packet being computed by the following equations:</p>
          <pre>
Coded Frame Presentation Timestamp = (MPEG-2 TS presentation timestamp) + <var>MPEG2TS_timestampOffset</var>
Coded Frame Decode Timestamp = (MPEG-2 TS decode timestamp) + <var>MPEG2TS_timestampOffset</var></pre>

          <p><a def-id="mpeg2ts-timestampOffset"></a> is updated in the following ways:</p>
          <ul>
            <li>Each time a timestamp rollover is detected, 2^33 must be added to <var>MPEG2TS_timestampOffset</var>.</li>
            <li>When a discontinuity is detected, <var>MPEG2TS_timestampOffset</var> must be adjusted to make the timestamps after the discontinuity appear
              to come immediately after the timestamps before the discontinuity.</li>
            <li>When <a def-id="abort"></a> is called, <var>MPEG2TS_timestampOffset</var> must be set to 0.</li>
            <li>When <a def-id="timestampOffset"></a> is successfully set, <var>MPEG2TS_timestampOffset</var> must be set to 0.</li>
          </ul>
        </section>
      </section>
    </section>



    <section id="examples">
      <h2>Examples</h2>
      <p>Example use of the Media Source Extensions</p>
      <div class="block">
        <div class="blockContent">
          <pre class="code">
&lt;script&gt;
  function onSourceOpen(videoTag, e) {
    var mediaSource = e.target;
    var sourceBuffer = mediaSource.addSourceBuffer('video/webm; codecs="vorbis,vp8"');

    videoTag.addEventListener('seeking', onSeeking.bind(videoTag, mediaSource));
    videoTag.addEventListener('progress', onProgress.bind(videoTag, mediaSource));

    var initSegment = GetInitializationSegment();

    if (initSegment == null) {
      // Error fetching the initialization segment. Signal end of stream with an error.
      mediaSource.endOfStream("network");
      return;
    }

    // Append the initialization segment.
    var firstAppendHandler = function(e) {
      var sourceBuffer = e.target;
      sourceBuffer.removeEventListener('updateend', firstAppendHandler);

      // Append some initial media data.
      appendNextMediaSegment(mediaSource);
    };
    sourceBuffer.addEventListener('updateend', firstAppendHandler);
    sourceBuffer.appendBuffer(initSegment);
  }

  function appendNextMediaSegment(mediaSource) {
    if (mediaSource.readyState == "ended")
      return;

    // If we have run out of stream data, then signal end of stream.
    if (!HaveMoreMediaSegments()) {
      mediaSource.endOfStream();
      return;
    }

    // Make sure the previous append is not still pending.
    if (mediaSource.sourceBuffers[0].updating)
        return;

    var mediaSegment = GetNextMediaSegment();

    if (!mediaSegment) {
      // Error fetching the next media segment.
      mediaSource.endOfStream("network");
      return;
    }

    mediaSource.sourceBuffers[0].appendBuffer(mediaSegment);
  }

  function onSeeking(mediaSource, e) {
    var video = e.target;

    // Abort current segment append.
    mediaSource.sourceBuffers[0].abort();

    // Notify the media segment loading code to start fetching data at the
    // new playback position.
    SeekToMediaSegmentAt(video.currentTime);

    // Append a media segment from the new playback position.
    appendNextMediaSegment(mediaSource);
  }

  function onProgress(mediaSource, e) {
    appendNextMediaSegment(mediaSource);
  }
&lt;/script&gt;

&lt;video id="v" autoplay&gt; &lt;/video&gt;

&lt;script&gt;
  var video = document.getElementById('v');
  var mediaSource = new MediaSource();
  mediaSource.addEventListener('sourceopen', onSourceOpen.bind(this, video));
  video.src = window.URL.createObjectURL(mediaSource);
&lt;/script&gt;
          </pre>
        </div>
      </div>
    </section>

    <section id="revision-history">
      <h2>Revision History</h2>
      <table class="old-table">
        <thead>
          <tr>
            <th>Version</th>
            <th>Comment</th>
          </tr>
        </thead>
        <tbody>
          <td>24 April 2013</td>
            <td>
              <ul>
                <li>Bug 21796 - Removed issue box from 'Append Error' algorithm.</li>
                <li>Bug 21703 - Changed appendWindowEnd to 'unrestricted double'.</li>
                <li>Bug 20760 - Adding MediaPlaybackQuality object.</li>
                <li>Bug 21536 - Specify the origin of media data appended.</li>
              </ul>
            </td>
          </tr>
          <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/f7f2b7226543/media-source/media-source.html">08 April 2013</a></td>
            <td>
              <ul>
                <li>Bug 21327 - Crossfade clarifications.</li>
                <li>Bug 21334 - Clarified seeking behavoir.</li>
                <li>Bug 21326 - Add a note stating some implementations may choose to add fades to/from silence.</li>
                <li>Bug 21375 - Clarified decode dependency removal.</li>
                <li>Bug 21376 - Replace 100ms limit with 2x last frame duration limit.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/rev/1e6898152c5b">26 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21301 - Change timeline references to "media timeline" links.</li>
                <li>Bug 19676 - Clarified "fade out coded frames" definition.</li>
                <li>Bug 21276 - Convert a few append error scenarios to endOfStream('decode') errors.</li>
                <li>Bug 21376 - Changed 'time' to 'decode time' to append sequence definition.</li>
                <li>Bug 21374 - Clarify the abort() behavior.</li>
                <li>Bug 21373 - Clarified incremental parsing text in segment parser loop.</li>
                <li>Bug 21364 - Remove redundant condition from remove overlapped frame step.</li>
                <li>Bug 21327 - Clarify what to do with a splice that starts with an audio frame with a duration less than 5ms.</li>
                <li>Update to ReSpec 3.1.48</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/f0fb58d45f96/media-source/media-source.html">12 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21112 - Add appendWindowStart & appendWindowEnd attributes.</li>
                <li>Bug 19676 - Clarify overlapped frame definitions and splice logic.</li>
                <li>Bug 21172 - Added coded frame removal and eviction algorithms.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/dcd406812201/media-source/media-source.html">05 March 2013</a></td>
            <td>
              <ul>
                <li>Bug 21170 - Remove 'stream aborted' step from stream append loop algorithm.</li>
                <li>Bug 21171 - Added informative note about when addSourceBuffer() might throw an QUOTA_EXCEEDED_ERR exception.</li>
                <li>Bug 20901 - Add support for 'continuation' and 'timestampOffset' abort modes.</li>
                <li>Bug 21159 - Rename appendArrayBuffer to appendBuffer() and add ArrayBufferView overload.</li>
                <li>Bug 21198 - Remove redundant 'closed' readyState checks.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="https://dvcs.w3.org/hg/html-media/raw-file/668a1c82fb88/media-source/media-source.html">25 February 2013</a></td>
            <td>
              <ul>
                 <li>Remove Source Buffer Model section since all the behavior is covered by the algorithms now.</li>
                 <li>Bug 20899 - Remove media segments must start with a random access point requirement.</li>
                 <li>Bug 21065 - Update example code to use updating attribute instead of old appending attribute.</li>
              </ul>
            </td>
          </tr>
          <tr>
            <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/d5956e93b991/media-source/media-source.html">19 February 2013</a></td>
            <td>
              <ul>
                 <li>Bug 19676, 20327 - Provide more detail for audio & video splicing.</li>
                 <li>Bug 20900 - Remove complete access unit constraint.</li>
                 <li>Bug 20948 - Setting timestampOffset in 'ended' triggers a transition to 'open'</li>
                 <li>Bug 20952 - Added update event.</li>
                 <li>Bug 20953 - Move end of append event firing out of segment parser loop.</li>
                 <li>Bug 21034 - Add steps to fire addtrack and removetrack events.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/77975abeec41/media-source/media-source.html">05 February 2013</a></td>
            <td>
              <ul>
                <li>Bug 19676 - Added a note clarifying that the internal timestamp representation doesn't have to be a double.</li>
                <li>Added steps to the coded frame processing algorithm to remove old frames when new ones overlap them.</li>
                <li>Fix isTypeSupported() return type.</li>
                <li>Bug 18933 - Clarify what top-level boxes to ignore for ISO-BMFF.</li>
                <li>Bug 18400 - Add a check to avoid creating huge hidden gaps when out-of-order appends occur w/o calling abort().</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/b35722b0cd8f/media-source/media-source.html">31 January 2013</a></td>
            <td>
              <ul>
                <li>Make remove() asynchronous.</li>
                <li>Added steps to various algorithms to throw an INVALID_STATE_ERR exception when async appends or remove() are pending.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/aae26333e7d1/media-source/media-source.html">30 January 2013</a></td>
            <td>
              <ul>
                <li>Remove early abort step on 0-byte appends so the same events fire as a normal append with bytes.</li>
                <li>Added definition for 'enough data to ensure uninterrupted playback'.</li>
                <li>Updated buffered ranges algorithm to properly compute the ranges for Philip's example.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/fd2a58eec443/media-source/media-source.html">15 January 2013</a></td>
            <td>Replace setTrackInfo() and getSourceBuffer() with AudioTrack, VideoTrack, and TextTrack extensions.</td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/52a85235137b/media-source/media-source.html">04 January 2013</a></td>
            <td>
              <ul>
                <li>Renamed append() to appendArrayBuffer() and made appending asynchronous.</li>
                <li>Added SourceBuffer.appendStream().</li>
                <li>Added SourceBuffer.setTrackInfo() methods.</li>
                <li>Added issue boxes to relevant sections for outstanding bugs.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/53ea7c19edd2/media-source/media-source.html">14 December 2012</a></td>
            <td>
              Pubrules, Link Checker, and Markup Validation fixes.
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/e1c91093dfdc/media-source/media-source.html">13 December 2012</a></td>
            <td>
              <ul>
                <li>Added MPEG-2 Transport Stream section.</li>
                <li>Added text to require abort() for out-of-order appends.</li>
                <li>Renamed "track buffer" to "decoder buffer".</li>
                <li>Redefined "track buffer" to mean the per-track buffers that hold the SourceBuffer media data.</li>
                <li>Editorial fixes.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/ee6e8ae9337c/media-source/media-source.html">08 December 2012</a></td>
            <td>
              <ul>
                <li>Added MediaSource.getSourceBuffer() methods.</li>
                <li>Section 2 cleanup.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/43be42e69533/media-source/media-source.html">06 December 2012</a></td>
            <td>
              <ul>
                <li>append() now throws a QUOTA_EXCEEDED_ERR when the SourceBuffer is full.</li>
                <li>Added unique ID generation text to Initialization Segment Received algorithm.</li>
                <li>Remove 2.x subsections that are already covered by algorithm text.</li>
                <li>Rework byte stream format text so it doesn't imply that the MediaSource implementation must support all formats supported by the
                  HTMLMediaElement.</li>
              </ul>
            </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/0c638da9a67a/media-source/media-source.html">28 November 2012</a></td>
            <td>
              <ul>
                <li>Added transition to HAVE_METADATA when current playback position is removed.</li>
                <li>Added remove() calls to duration change algorithm.</li>
                <li>Added MediaSource.isTypeSupported() method.</li>
                <li>Remove initialization segments are optional text.</li>
              </ul>
            </td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/3e4d27b3a98f/media-source/media-source.html">09 November 2012</a></td>
            <td>Converted document to ReSpec.</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/e029f71aafca/media-source/media-source.html">18 October 2012</a></td>
            <td>Refactored SourceBuffer.append() &amp; added SourceBuffer.remove().</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/6d127e69c9f8/media-source/media-source.html">8 October 2012</a></td>
            <td>
	      <ul>
	        <li>Defined what HTMLMediaElement.seekable and HTMLMediaElement.buffered should return.</li>
	        <li>Updated seeking algorithm to run inside Step 10 of the HTMLMediaElement seeking algorithm.</li>
	        <li>Removed transition from "ended" to "open" in the seeking algorithm.</li>
	        <li>Clarified all the event targets.</li>
	      </ul>
	    </td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/7bab66368f2c/media-source/media-source.html">1 October 2012</a></td>
            <td>Fixed various addsourcebuffer &amp; removesourcebuffer bugs and allow append() in ended state.</td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/349559debcc3/media-source/media-source.html">13 September 2012</a></td>
            <td>Updated endOfStream() behavior to change based on the value of HTMLMediaElement.readyState.</td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/ca093bbbbefb/media-source/media-source.html">24 August 2012</a></td>
            <td>
	      <ul>
	        <li>Added early abort on to duration change algorithm.</li>
	        <li>Added createObjectURL() IDL &amp; algorithm.</li>
                <li>Added Track ID &amp; Track description definitions.</li>
                <li>Rewrote start overlap for audio frames text.</li>
                <li>Removed rendering silence requirement from section 2.5.</li>
	      </ul>
	    </td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/340786fcae83/media-source/media-source.html">22 August 2012</a></td>
            <td>
	      <ul>
	        <li>Clarified WebM byte stream requirements.</li>
	        <li>Clarified SourceBuffer.buffered return value.</li>
	        <li>Clarified addsourcebuffer &amp; removesourcebuffer event targets.</li>
	        <li>Clarified when media source attaches to the HTMLMediaElement.</li>
	        <li>Introduced duration change algorithm and update relevant algorithms to use it.</li>
	      </ul>
	    </td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/032f7b8681d1/media-source/media-source.html">17 August 2012</a></td>
            <td>Minor editorial fixes.</td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/29687c019735/media-source/media-source.html">09 August 2012</a></td>
            <td>Change presentation start time to always be 0 instead of using format specific rules about the first media segment appended.</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/087ea42f59c8/media-source/media-source.html">30 July 2012</a></td>
            <td>Added SourceBuffer.timestampOffset and MediaSource.duration.</td>
          </tr>
          <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/ab36e8e882c6/media-source/media-source.html">17 July 2012</a></td>
            <td>Replaced SourceBufferList.remove() with MediaSource.removeSourceBuffer().</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/b499a199e427/media-source/media-source.html">02 July 2012</a></td>
            <td>Converted to the object-oriented API</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/9bbfe09653e4/media-source/media-source.html">26 June 2012</a></td>
            <td>Converted to Editor's draft.</td>
          </tr>
	  <tr>
	    <td><a href="http://dvcs.w3.org/hg/html-media/raw-file/e433598d22a7/media-source/media-source.html">0.5</a></td>
            <td>Minor updates before proposing to W3C HTML-WG.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.4/draft-spec/mediasource-draft-spec.html">0.4</a></td>
            <td>Major revision. Adding source IDs, defining buffer model, and clarifying byte stream formats.</td>
          </tr>
	  <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.3/draft-spec/mediasource-draft-spec.html">0.3</a></td>
            <td>Minor text updates.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.2/draft-spec/mediasource-draft-spec.html">0.2</a></td>
            <td>Updates to reflect initial WebKit implementation.</td>
          </tr>
          <tr>
            <td><a href="http://html5-mediasource-api.googlecode.com/svn/tags/0.1/draft-spec/mediasource-draft-spec.html">0.1</a></td>
            <td>Initial Proposal</td>
          </tr>
        </tbody>
      </table>
    </section>
  </body>
</html>
